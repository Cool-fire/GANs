{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_celeba_wgan.py  from:\n",
    "\n",
    "https://github.com/LynnHo/DCGAN-LSGAN-WGAN-WGAN-GP-Tensorflow/blob/master/train_celeba_wgan.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models components for 64x64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_fully_connected(inputs,\n",
    "                            num_outputs,\n",
    "                            activation_fn=tf.nn.relu,\n",
    "                            normalizer_fn=None,\n",
    "                            normalizer_params=None,\n",
    "                            weights_initializer=slim.xavier_initializer(),\n",
    "                            weights_regularizer=None,\n",
    "                            biases_initializer=tf.zeros_initializer(),\n",
    "                            biases_regularizer=None,\n",
    "                            reuse=None,\n",
    "                            variables_collections=None,\n",
    "                            outputs_collections=None,\n",
    "                            trainable=True,\n",
    "                            scope=None):\n",
    "    with tf.variable_scope(scope, 'flatten_fully_connected', [inputs]):\n",
    "        if inputs.shape.ndims > 2:\n",
    "            inputs = slim.flatten(inputs)\n",
    "        return slim.fully_connected(inputs,\n",
    "                                    num_outputs,\n",
    "                                    activation_fn,\n",
    "                                    normalizer_fn,\n",
    "                                    normalizer_params,\n",
    "                                    weights_initializer,\n",
    "                                    weights_regularizer,\n",
    "                                    biases_initializer,\n",
    "                                    biases_regularizer,\n",
    "                                    reuse,\n",
    "                                    variables_collections,\n",
    "                                    outputs_collections,\n",
    "                                    trainable,\n",
    "                                    scope)\n",
    "\n",
    "\n",
    "def leak_relu(x, leak, scope=None):\n",
    "    with tf.name_scope(scope, 'leak_relu', [x, leak]):\n",
    "        if leak < 1:\n",
    "            y = tf.maximum(x, leak * x)\n",
    "        else:\n",
    "            y = tf.minimum(x, leak * x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "slim layers:\n",
    "\n",
    "    conv2d(args):\n",
    "        inputs: \n",
    "            A 4-D tensor with dimensions [batch_size, height, width, channels]\n",
    "        kernel_size:\n",
    "            Can be an int if both values are the same.\n",
    "        stride: \n",
    "            default=1\n",
    "        ...\n",
    "    \n",
    "    conv2d_transpose(args):\n",
    "        inputs:\n",
    "        num_outputs: \n",
    "            Integer, the number of output filters.\n",
    "        kernel_size:\n",
    "        stride: \n",
    "            default=1\n",
    "        ...\n",
    "        \n",
    "    batch_norm(args):\n",
    "        is_training: \n",
    "            Whether or not the layer is in training mode. In training mode\n",
    "            it would accumulate the statistics of the moments into `moving_mean` and\n",
    "            `moving_variance` using an exponential moving average with the given\n",
    "            `decay`. When it is not in training mode then it would use the values of\n",
    "            the `moving_mean` and the `moving_variance`.\n",
    "            \n",
    "'''\n",
    "\n",
    "conv = partial(slim.conv2d, activation_fn=None, weights_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "dconv = partial(slim.conv2d_transpose, activation_fn=None, weights_initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "fc = partial(flatten_fully_connected, activation_fn=None, weights_initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "relu = tf.nn.relu\n",
    "lrelu = partial(leak_relu, leak=0.2)\n",
    "batch_norm = partial(slim.batch_norm, decay=0.9, scale=True, epsilon=1e-5, updates_collections=None)\n",
    "ln = slim.layer_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, dim=64, reuse=True, training=True):\n",
    "    bn = partial(batch_norm, is_training=training)\n",
    "    dconv_bn_relu = partial(dconv, normalizer_fn=bn, activation_fn=relu, biases_initializer=None)\n",
    "    fc_bn_relu = partial(fc, normalizer_fn=bn, activation_fn=relu, biases_initializer=None)\n",
    "\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        y = fc_bn_relu(z, 4 * 4 * dim * 8)\n",
    "        y = tf.reshape(y, [-1, 4, 4, dim * 8])\n",
    "        y = dconv_bn_relu(y, dim * 4, 5, 2)\n",
    "        y = dconv_bn_relu(y, dim * 2, 5, 2)\n",
    "        y = dconv_bn_relu(y, dim * 1, 5, 2)\n",
    "        img = tf.tanh(dconv(y, 1, 5, 2)) # Change number of out channels\n",
    "        return img\n",
    "\n",
    "\n",
    "def discriminator(img, dim=64, reuse=True, training=True):\n",
    "    bn = partial(batch_norm, is_training=training)\n",
    "    conv_bn_lrelu = partial(conv, normalizer_fn=bn, activation_fn=lrelu, biases_initializer=None)\n",
    "\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        y = lrelu(conv(img, dim, 5, 2))\n",
    "        y = conv_bn_lrelu(y, dim * 2, 5, 2)\n",
    "        y = conv_bn_lrelu(y, dim * 4, 5, 2)\n",
    "        y = conv_bn_lrelu(y, dim * 8, 5, 2)\n",
    "        logit = fc(y, 1)\n",
    "        return logit\n",
    "\n",
    "\n",
    "def discriminator_wgan_gp(img, dim=64, reuse=True, training=True):\n",
    "    conv_ln_lrelu = partial(conv, normalizer_fn=ln, activation_fn=lrelu, biases_initializer=None)\n",
    "\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        y = lrelu(conv(img, dim, 5, 2))\n",
    "        y = conv_ln_lrelu(y, dim * 2, 5, 2)\n",
    "        y = conv_ln_lrelu(y, dim * 4, 5, 2)\n",
    "        y = conv_ln_lrelu(y, dim * 8, 5, 2)\n",
    "        logit = fc(y, 1)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(paths):\n",
    "    if not isinstance(paths, (list, tuple)):\n",
    "        paths = [paths]\n",
    "    for path in paths:\n",
    "        path_dir, _ = os.path.split(path)\n",
    "        if not os.path.isdir(path_dir):\n",
    "            os.makedirs(path_dir)\n",
    "\n",
    "\n",
    "def session(graph=None, allow_soft_placement=True,\n",
    "            log_device_placement=False, allow_growth=True):\n",
    "    \"\"\" return a Session with simple config \"\"\"\n",
    "\n",
    "    config = tf.ConfigProto(allow_soft_placement=allow_soft_placement,\n",
    "                            log_device_placement=log_device_placement)\n",
    "    config.gpu_options.allow_growth = allow_growth\n",
    "    return tf.Session(graph=graph, config=config)\n",
    "\n",
    "\n",
    "def tensors_filter(tensors, filters, combine_type='or'):\n",
    "    assert isinstance(tensors, (list, tuple)), '`tensors` shoule be a list or tuple!'\n",
    "    assert isinstance(filters, (str, list, tuple)), \\\n",
    "        '`filters` should be a string or a list(tuple) of strings!'\n",
    "    assert combine_type == 'or' or combine_type == 'and', \"`combine_type` should be 'or' or 'and'!\"\n",
    "\n",
    "    if isinstance(filters, str):\n",
    "        filters = [filters]\n",
    "\n",
    "    f_tens = []\n",
    "    for ten in tensors:\n",
    "        if combine_type == 'or':\n",
    "            for filt in filters:\n",
    "                if filt in ten.name:\n",
    "                    f_tens.append(ten)\n",
    "                    break\n",
    "        elif combine_type == 'and':\n",
    "            all_pass = True\n",
    "            for filt in filters:\n",
    "                if filt not in ten.name:\n",
    "                    all_pass = False\n",
    "                    break\n",
    "            if all_pass:\n",
    "                f_tens.append(ten)\n",
    "    return f_tens\n",
    "\n",
    "\n",
    "def trainable_variables(filters=None, combine_type='or'):\n",
    "    t_var = tf.trainable_variables()\n",
    "    if filters is None:\n",
    "        return t_var\n",
    "    else:\n",
    "        return tensors_filter(t_var, filters, combine_type)\n",
    "\n",
    "\n",
    "def summary(tensor_collection, summary_type=['mean', 'stddev', 'max', 'min', 'sparsity', 'histogram']):\n",
    "    \"\"\"\n",
    "    usage:\n",
    "    1. summary(tensor)\n",
    "    2. summary([tensor_a, tensor_b])\n",
    "    3. summary({tensor_a: 'a', tensor_b: 'b})\n",
    "    \"\"\"\n",
    "\n",
    "    def _summary(tensor, name, summary_type=['mean', 'stddev', 'max', 'min', 'sparsity', 'histogram']):\n",
    "        \"\"\" Attach a lot of summaries to a Tensor. \"\"\"\n",
    "\n",
    "        if name is None:\n",
    "            # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n",
    "            # session. This helps the clarity of presentation on tensorboard.\n",
    "            name = re.sub('%s_[0-9]*/' % 'tower', '', tensor.name)\n",
    "            name = re.sub(':', '-', name)\n",
    "\n",
    "        with tf.name_scope('summary_' + name):\n",
    "            summaries = []\n",
    "            if len(tensor._shape) == 0:\n",
    "                summaries.append(tf.summary.scalar(name, tensor))\n",
    "            else:\n",
    "                if 'mean' in summary_type:\n",
    "                    mean = tf.reduce_mean(tensor)\n",
    "                    summaries.append(tf.summary.scalar(name + '/mean', mean))\n",
    "                if 'stddev' in summary_type:\n",
    "                    mean = tf.reduce_mean(tensor)\n",
    "                    stddev = tf.sqrt(tf.reduce_mean(tf.square(tensor - mean)))\n",
    "                    summaries.append(tf.summary.scalar(name + '/stddev', stddev))\n",
    "                if 'max' in summary_type:\n",
    "                    summaries.append(tf.summary.scalar(name + '/max', tf.reduce_max(tensor)))\n",
    "                if 'min' in summary_type:\n",
    "                    summaries.append(tf.summary.scalar(name + '/min', tf.reduce_min(tensor)))\n",
    "                if 'sparsity' in summary_type:\n",
    "                    summaries.append(tf.summary.scalar(name + '/sparsity', tf.nn.zero_fraction(tensor)))\n",
    "                if 'histogram' in summary_type:\n",
    "                    summaries.append(tf.summary.histogram(name, tensor))\n",
    "            return tf.summary.merge(summaries)\n",
    "\n",
    "    if not isinstance(tensor_collection, (list, tuple, dict)):\n",
    "        tensor_collection = [tensor_collection]\n",
    "    with tf.name_scope('summaries'):\n",
    "        summaries = []\n",
    "        if isinstance(tensor_collection, (list, tuple)):\n",
    "            for tensor in tensor_collection:\n",
    "                summaries.append(_summary(tensor, None, summary_type))\n",
    "        else:\n",
    "            for tensor, name in tensor_collection.items():\n",
    "                summaries.append(_summary(tensor, name, summary_type))\n",
    "        return tf.summary.merge(summaries)\n",
    "\n",
    "\n",
    "def counter(scope='counter'):\n",
    "    with tf.variable_scope(scope):\n",
    "        counter = tf.Variable(0, dtype=tf.int32, name='counter')\n",
    "        update_cnt = tf.assign(counter, tf.add(counter, 1))\n",
    "        return counter, update_cnt\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_dir, session, var_list=None):\n",
    "    print(' [*] Loading checkpoint...')\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        ckpt_path = os.path.join(checkpoint_dir, ckpt_name)\n",
    "    try:\n",
    "        restorer = tf.train.Saver(var_list)\n",
    "        restorer.restore(session, ckpt_path)\n",
    "        print(' [*] Loading successful! Copy variables from % s' % ckpt_path)\n",
    "        return True\n",
    "    except:\n",
    "        print(' [*] No suitable checkpoint!')\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def disk_image_batch(image_paths, batch_size, shape, preprocess_fn=None, shuffle=True, num_threads=16,\n",
    "                     min_after_dequeue=100, allow_smaller_final_batch=False, scope=None):\n",
    "    \"\"\"\n",
    "    This function is suitable for bmp, jpg, png and gif files\n",
    "    image_paths: string list or 1-D tensor, each of which is an iamge path\n",
    "    preprocess_fn: single image preprocessing function\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope(scope, 'disk_image_batch'):\n",
    "        data_num = len(image_paths)\n",
    "\n",
    "        # dequeue a single image path and read the image bytes; enqueue the whole file list\n",
    "        _, img = tf.WholeFileReader().read(tf.train.string_input_producer(image_paths, shuffle=shuffle, capacity=data_num))\n",
    "        img = tf.image.decode_image(img)\n",
    "\n",
    "        # preprocessing\n",
    "        img.set_shape(shape)\n",
    "        if preprocess_fn is not None:\n",
    "            img = preprocess_fn(img)\n",
    "\n",
    "        # batch datas\n",
    "        if shuffle:\n",
    "            capacity = min_after_dequeue + (num_threads + 1) * batch_size\n",
    "            img_batch = tf.train.shuffle_batch([img],\n",
    "                                               batch_size=batch_size,\n",
    "                                               capacity=capacity,\n",
    "                                               min_after_dequeue=min_after_dequeue,\n",
    "                                               num_threads=num_threads,\n",
    "                                               allow_smaller_final_batch=allow_smaller_final_batch)\n",
    "        else:\n",
    "            img_batch = tf.train.batch([img],\n",
    "                                       batch_size=batch_size,\n",
    "                                       allow_smaller_final_batch=allow_smaller_final_batch)\n",
    "\n",
    "        return img_batch, data_num\n",
    "\n",
    "\n",
    "class DiskImageData:\n",
    "\n",
    "    def __init__(self, image_paths, batch_size, shape, preprocess_fn=None, shuffle=True, num_threads=16,\n",
    "                 min_after_dequeue=100, allow_smaller_final_batch=False, scope=None):\n",
    "        \"\"\"\n",
    "        This function is suitable for bmp, jpg, png and gif files\n",
    "        image_paths: string list or 1-D tensor, each of which is an iamge path\n",
    "        preprocess_fn: single image preprocessing function\n",
    "        \"\"\"\n",
    "\n",
    "        self.graph = tf.Graph()  # declare ops in a separated graph\n",
    "        with self.graph.as_default():\n",
    "            # @TODO\n",
    "            # There are some strange errors if the gpu device is the\n",
    "            # same with the main graph, but cpu device is ok. I don't know why...\n",
    "            with tf.device('/cpu:0'):\n",
    "                self._batch_ops, self._data_num = disk_image_batch(image_paths, batch_size, shape, preprocess_fn, shuffle, num_threads,\n",
    "                                                                   min_after_dequeue, allow_smaller_final_batch, scope)\n",
    "\n",
    "        print(' [*] DiskImageData: create session!')\n",
    "        self.sess = session(graph=self.graph)\n",
    "        self.coord = tf.train.Coordinator()\n",
    "        self.threads = tf.train.start_queue_runners(sess=self.sess, coord=self.coord)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._data_num\n",
    "\n",
    "    def batch(self):\n",
    "        return self.sess.run(self._batch_ops)\n",
    "\n",
    "    def __del__(self):\n",
    "        print(' [*] DiskImageData: stop threads and close session!')\n",
    "        self.coord.request_stop()\n",
    "        self.coord.join(self.threads)\n",
    "        self.sess.close()\n",
    "\n",
    "\n",
    "def to_range(images, min_value=0.0, max_value=1.0, dtype=None):\n",
    "    \"\"\"\n",
    "    transform images from [-1.0, 1.0] to [min_value, max_value] of dtype\n",
    "    \"\"\"\n",
    "    assert \\\n",
    "        np.min(images) >= -1.0 - 1e-5 and np.max(images) <= 1.0 + 1e-5 \\\n",
    "        and (images.dtype == np.float32 or images.dtype == np.float64), \\\n",
    "        'The input images should be float64(32) and in the range of [-1.0, 1.0]!'\n",
    "    if dtype is None:\n",
    "        dtype = images.dtype\n",
    "    return ((images + 1.) / 2. * (max_value - min_value) + min_value).astype(dtype)\n",
    "\n",
    "\n",
    "def imwrite(image, path):\n",
    "    \"\"\" save an [-1.0, 1.0] image \"\"\"\n",
    "\n",
    "    if image.ndim == 3 and image.shape[2] == 1:  # for gray image\n",
    "        image = np.array(image, copy=True)\n",
    "        image.shape = image.shape[0:2]\n",
    "    return scipy.misc.imsave(path, to_range(image, 0, 255, np.uint8))\n",
    "\n",
    "\n",
    "def immerge(images, row, col):\n",
    "    \"\"\"\n",
    "    merge images into an image with (row * h) * (col * w)\n",
    "    `images` is in shape of N * H * W(* C=1 or 3)\n",
    "    \"\"\"\n",
    "\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    if images.ndim == 4:\n",
    "        img = np.zeros((h * row, w * col, images.shape[3]))\n",
    "    elif images.ndim == 3:\n",
    "        img = np.zeros((h * row, w * col))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % col\n",
    "        j = idx // col\n",
    "        img[j * h:j * h + h, i * w:i * w + w, ...] = image\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import glob\n",
    "import traceback\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\"\"\" param \"\"\"\n",
    "epoch = 50000\n",
    "batch_size = 32\n",
    "lr = 0.0002\n",
    "z_dim = 100\n",
    "clip = 0.01\n",
    "n_critic = 5\n",
    "gpu_id = 0\n",
    "\n",
    "''' data '''\n",
    "# you should prepare your own data in ./data/img_align_celeba\n",
    "# celeba original size is [218, 178, 3]\n",
    "\n",
    "\n",
    "def preprocess_fn(img):\n",
    "    #Transform it to be between -1 and 1\n",
    "    img = tf.to_float(img) / 127.5 - 1\n",
    "\n",
    "#     crop_size = 108\n",
    "#     re_size = 64\n",
    "#     img = tf.image.crop_to_bounding_box(img, (218 - crop_size) // 2, (178 - crop_size) // 2, crop_size, crop_size)\n",
    "#     img = tf.to_float(tf.image.resize_images(img, [re_size, re_size], method=tf.image.ResizeMethod.BICUBIC)) / 127.5 - 1\n",
    "    return img\n",
    "\n",
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"] #Define emotions\n",
    "file_paths = []\n",
    "for emotion in emotions:\n",
    "            file_paths.extend(glob.glob(\"./dataset_64x64/%s/*\" %emotion))\n",
    "data_pool = DiskImageData(file_paths, batch_size, shape=[64, 64, 1], preprocess_fn=preprocess_fn)\n",
    "\n",
    "\n",
    "\"\"\" graphs \"\"\"\n",
    "with tf.device('/gpu:%d' % gpu_id):\n",
    "\n",
    "    ''' graph '''\n",
    "    # inputs\n",
    "    real = tf.placeholder(tf.float32, shape=[None, 64, 64, 1])\n",
    "    z = tf.placeholder(tf.float32, shape=[None, z_dim])\n",
    "\n",
    "    # generate\n",
    "    fake = generator(z, reuse=False)\n",
    "\n",
    "    # dicriminate\n",
    "    r_logit = discriminator(real, reuse=False)\n",
    "    f_logit = discriminator(fake)\n",
    "\n",
    "    # losses\n",
    "    wd = tf.reduce_mean(r_logit) - tf.reduce_mean(f_logit)\n",
    "    d_loss = -wd\n",
    "    g_loss = -tf.reduce_mean(f_logit)\n",
    "\n",
    "    # otpims\n",
    "    d_var = trainable_variables('discriminator')\n",
    "    g_var = trainable_variables('generator')\n",
    "    d_step_ = tf.train.RMSPropOptimizer(learning_rate=lr).minimize(d_loss, var_list=d_var)\n",
    "    with tf.control_dependencies([d_step_]):\n",
    "        d_step = tf.group(*(tf.assign(var, tf.clip_by_value(var, -clip, clip)) for var in d_var))\n",
    "    g_step = tf.train.RMSPropOptimizer(learning_rate=lr).minimize(g_loss, var_list=g_var)\n",
    "\n",
    "    # summaries\n",
    "    d_summary = summary({wd: 'wd'})\n",
    "    g_summary = summary({g_loss: 'g_loss'})\n",
    "\n",
    "    # sample\n",
    "    f_sample = generator(z, training=False)\n",
    "\n",
    "\n",
    "\"\"\" train \"\"\"\n",
    "''' init '''\n",
    "# session\n",
    "sess = session()\n",
    "# saver\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "# summary writer\n",
    "summary_writer = tf.summary.FileWriter('./WGAN/summaries/run1', sess.graph)\n",
    "\n",
    "''' initialization '''\n",
    "ckpt_dir = './WGAN/checkpoints/run1'\n",
    "mkdir(ckpt_dir + '/')\n",
    "if not load_checkpoint(ckpt_dir, sess):\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "''' train '''\n",
    "try:\n",
    "    z_ipt_sample = np.random.normal(size=[100, z_dim])\n",
    "\n",
    "    batch_epoch = len(data_pool) // (batch_size * n_critic)\n",
    "    max_it = epoch * batch_epoch\n",
    "\n",
    "    for it in range(max_it):\n",
    "\n",
    "        # which epoch\n",
    "        epoch = it // batch_epoch\n",
    "        it_epoch = it % batch_epoch + 1\n",
    "\n",
    "        # train D\n",
    "        for i in range(n_critic):\n",
    "            # batch data\n",
    "            real_ipt = data_pool.batch()\n",
    "            z_ipt = np.random.normal(size=[batch_size, z_dim])\n",
    "            d_summary_opt, _ = sess.run([d_summary, d_step], feed_dict={real: real_ipt, z: z_ipt})\n",
    "        summary_writer.add_summary(d_summary_opt, it)\n",
    "\n",
    "        # train G\n",
    "        z_ipt = np.random.normal(size=[batch_size, z_dim])\n",
    "        g_summary_opt, _ = sess.run([g_summary, g_step], feed_dict={z: z_ipt})\n",
    "        summary_writer.add_summary(g_summary_opt, it)\n",
    "\n",
    "        # display\n",
    "        if it % 1 == 0:\n",
    "            print(\"Epoch: (%3d) (%5d/%5d)\" % (epoch, it_epoch, batch_epoch))\n",
    "\n",
    "        # save\n",
    "        if (it + 1) % 1000 == 0:\n",
    "            save_path = saver.save(sess, '%s/Epoch_(%d)_(%dof%d).ckpt' % (ckpt_dir, epoch, it_epoch, batch_epoch))\n",
    "            print('Model saved in file: % s' % save_path)\n",
    "\n",
    "        # sample\n",
    "        if (it + 1) % 100 == 0:\n",
    "            f_sample_opt = sess.run(f_sample, feed_dict={z: z_ipt_sample})\n",
    "\n",
    "            save_dir = './WGAN/sample_images_while_training/run1'\n",
    "            mkdir(save_dir + '/')\n",
    "            imwrite(immerge(f_sample_opt, 10, 10), '%s/Epoch_(%d)_(%dof%d).jpg' % (save_dir, epoch, it_epoch, batch_epoch))\n",
    "\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    print(\" [*] Close main session!\")\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
