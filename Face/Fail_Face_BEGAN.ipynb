{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying BEGAN in Faces image\n",
    "\n",
    "https://www.reddit.com/r/MachineLearning/comments/633jal/r170310717_began_boundary_equilibrium_generative/\n",
    "\n",
    "https://arxiv.org/pdf/1703.10717.pdf\n",
    "\n",
    "1. The generator wins by generating images that the discriminator can successfully autoencode with small loss.\n",
    "\n",
    "2. The discriminator wins by autoencoding real images well and by autoencoding the generated images poorly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-Encoder\n",
    "\n",
    "https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/autoencoder.ipynb\n",
    "\n",
    "awesome python library\n",
    "https://pypi.python.org/pypi/tqdm\n",
    "\n",
    "https://github.com/carpedm20/BEGAN-tensorflow/blob/master/models.py\n",
    "\n",
    "https://arxiv.org/pdf/1703.10717.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library and Utils / Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries we will need.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.contrib.slim as slim\n",
    "import os\n",
    "import re\n",
    "import scipy.misc\n",
    "import scipy\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(paths):\n",
    "    if not isinstance(paths, (list, tuple)):\n",
    "        paths = [paths]\n",
    "    for path in paths:\n",
    "        path_dir, _ = os.path.split(path)\n",
    "        if not os.path.isdir(path_dir):\n",
    "            os.makedirs(path_dir)\n",
    "\n",
    "\n",
    "def session(graph=None, allow_soft_placement=True,\n",
    "            log_device_placement=False, allow_growth=True):\n",
    "    \"\"\" return a Session with simple config \"\"\"\n",
    "\n",
    "    config = tf.ConfigProto(allow_soft_placement=allow_soft_placement,\n",
    "                            log_device_placement=log_device_placement)\n",
    "    config.gpu_options.allow_growth = allow_growth\n",
    "    return tf.Session(graph=graph, config=config)\n",
    "\n",
    "\n",
    "def tensors_filter(tensors, filters, combine_type='or'):\n",
    "    assert isinstance(tensors, (list, tuple)), '`tensors` shoule be a list or tuple!'\n",
    "    assert isinstance(filters, (str, list, tuple)), \\\n",
    "        '`filters` should be a string or a list(tuple) of strings!'\n",
    "    assert combine_type == 'or' or combine_type == 'and', \"`combine_type` should be 'or' or 'and'!\"\n",
    "\n",
    "    if isinstance(filters, str):\n",
    "        filters = [filters]\n",
    "\n",
    "    f_tens = []\n",
    "    for ten in tensors:\n",
    "        if combine_type == 'or':\n",
    "            for filt in filters:\n",
    "                if filt in ten.name:\n",
    "                    f_tens.append(ten)\n",
    "                    break\n",
    "        elif combine_type == 'and':\n",
    "            all_pass = True\n",
    "            for filt in filters:\n",
    "                if filt not in ten.name:\n",
    "                    all_pass = False\n",
    "                    break\n",
    "            if all_pass:\n",
    "                f_tens.append(ten)\n",
    "    return f_tens\n",
    "\n",
    "\n",
    "def trainable_variables(filters=None, combine_type='or'):\n",
    "    t_var = tf.trainable_variables()\n",
    "    if filters is None:\n",
    "        return t_var\n",
    "    else:\n",
    "        return tensors_filter(t_var, filters, combine_type)\n",
    "\n",
    "\n",
    "def summary(tensor_collection, summary_type=['mean', 'stddev', 'max', 'min', 'sparsity', 'histogram']):\n",
    "    \"\"\"\n",
    "    usage:\n",
    "    1. summary(tensor)\n",
    "    2. summary([tensor_a, tensor_b])\n",
    "    3. summary({tensor_a: 'a', tensor_b: 'b})\n",
    "    \"\"\"\n",
    "\n",
    "    def _summary(tensor, name, summary_type=['mean', 'stddev', 'max', 'min', 'sparsity', 'histogram']):\n",
    "        \"\"\" Attach a lot of summaries to a Tensor. \"\"\"\n",
    "\n",
    "        if name is None:\n",
    "            # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n",
    "            # session. This helps the clarity of presentation on tensorboard.\n",
    "            name = re.sub('%s_[0-9]*/' % 'tower', '', tensor.name)\n",
    "            name = re.sub(':', '-', name)\n",
    "\n",
    "        with tf.name_scope('summary_' + name):\n",
    "            summaries = []\n",
    "            if len(tensor._shape) == 0:\n",
    "                summaries.append(tf.summary.scalar(name, tensor))\n",
    "            else:\n",
    "                if 'mean' in summary_type:\n",
    "                    mean = tf.reduce_mean(tensor)\n",
    "                    summaries.append(tf.summary.scalar(name + '/mean', mean))\n",
    "                if 'stddev' in summary_type:\n",
    "                    mean = tf.reduce_mean(tensor)\n",
    "                    stddev = tf.sqrt(tf.reduce_mean(tf.square(tensor - mean)))\n",
    "                    summaries.append(tf.summary.scalar(name + '/stddev', stddev))\n",
    "                if 'max' in summary_type:\n",
    "                    summaries.append(tf.summary.scalar(name + '/max', tf.reduce_max(tensor)))\n",
    "                if 'min' in summary_type:\n",
    "                    summaries.append(tf.summary.scalar(name + '/min', tf.reduce_min(tensor)))\n",
    "                if 'sparsity' in summary_type:\n",
    "                    summaries.append(tf.summary.scalar(name + '/sparsity', tf.nn.zero_fraction(tensor)))\n",
    "                if 'histogram' in summary_type:\n",
    "                    summaries.append(tf.summary.histogram(name, tensor))\n",
    "            return tf.summary.merge(summaries)\n",
    "\n",
    "    if not isinstance(tensor_collection, (list, tuple, dict)):\n",
    "        tensor_collection = [tensor_collection]\n",
    "    with tf.name_scope('summaries'):\n",
    "        summaries = []\n",
    "        if isinstance(tensor_collection, (list, tuple)):\n",
    "            for tensor in tensor_collection:\n",
    "                summaries.append(_summary(tensor, None, summary_type))\n",
    "        else:\n",
    "            for tensor, name in tensor_collection.items():\n",
    "                summaries.append(_summary(tensor, name, summary_type))\n",
    "        return tf.summary.merge(summaries)\n",
    "\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_dir, session, var_list=None):\n",
    "    print(' [*] Loading checkpoint...')\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        ckpt_path = os.path.join(checkpoint_dir, ckpt_name)\n",
    "    try:\n",
    "        restorer = tf.train.Saver(var_list)\n",
    "        restorer.restore(session, ckpt_path)\n",
    "        print(' [*] Loading successful! Copy variables from % s' % ckpt_path)\n",
    "        return True\n",
    "    except:\n",
    "        print(' [*] No suitable checkpoint!')\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def disk_image_batch(image_paths, batch_size, shape, preprocess_fn=None, shuffle=True, num_threads=16,\n",
    "                     min_after_dequeue=100, allow_smaller_final_batch=False, scope=None):\n",
    "    \"\"\"\n",
    "    This function is suitable for bmp, jpg, png and gif files\n",
    "    image_paths: string list or 1-D tensor, each of which is an iamge path\n",
    "    preprocess_fn: single image preprocessing function\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope(scope, 'disk_image_batch'):\n",
    "        data_num = len(image_paths)\n",
    "\n",
    "        # dequeue a single image path and read the image bytes; enqueue the whole file list\n",
    "        _, img = tf.WholeFileReader().read(tf.train.string_input_producer(image_paths, shuffle=shuffle, capacity=data_num))\n",
    "        img = tf.image.decode_image(img)\n",
    "\n",
    "        # preprocessing\n",
    "        img.set_shape(shape)\n",
    "        if preprocess_fn is not None:\n",
    "            img = preprocess_fn(img)\n",
    "\n",
    "        # batch datas\n",
    "        if shuffle:\n",
    "            capacity = min_after_dequeue + (num_threads + 1) * batch_size\n",
    "            img_batch = tf.train.shuffle_batch([img],\n",
    "                                               batch_size=batch_size,\n",
    "                                               capacity=capacity,\n",
    "                                               min_after_dequeue=min_after_dequeue,\n",
    "                                               num_threads=num_threads,\n",
    "                                               allow_smaller_final_batch=allow_smaller_final_batch)\n",
    "        else:\n",
    "            img_batch = tf.train.batch([img],\n",
    "                                       batch_size=batch_size,\n",
    "                                       allow_smaller_final_batch=allow_smaller_final_batch)\n",
    "\n",
    "        return img_batch, data_num\n",
    "\n",
    "\n",
    "class DiskImageData:\n",
    "\n",
    "    def __init__(self, image_paths, batch_size, shape, preprocess_fn=None, shuffle=True, num_threads=16,\n",
    "                 min_after_dequeue=100, allow_smaller_final_batch=False, scope=None):\n",
    "        \"\"\"\n",
    "        This function is suitable for bmp, jpg, png and gif files\n",
    "        image_paths: string list or 1-D tensor, each of which is an iamge path\n",
    "        preprocess_fn: single image preprocessing function\n",
    "        \"\"\"\n",
    "\n",
    "        self.graph = tf.Graph()  # declare ops in a separated graph\n",
    "        with self.graph.as_default():\n",
    "            # @TODO\n",
    "            # There are some strange errors if the gpu device is the\n",
    "            # same with the main graph, but cpu device is ok. I don't know why...\n",
    "            with tf.device('/cpu:0'):\n",
    "                self._batch_ops, self._data_num = disk_image_batch(image_paths, batch_size, shape, preprocess_fn, shuffle, num_threads,\n",
    "                                                                   min_after_dequeue, allow_smaller_final_batch, scope)\n",
    "\n",
    "        print(' [*] DiskImageData: create session!')\n",
    "        self.sess = session(graph=self.graph)\n",
    "        self.coord = tf.train.Coordinator()\n",
    "        self.threads = tf.train.start_queue_runners(sess=self.sess, coord=self.coord)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._data_num\n",
    "\n",
    "    def batch(self):\n",
    "        return self.sess.run(self._batch_ops)\n",
    "\n",
    "    def __del__(self):\n",
    "        print(' [*] DiskImageData: stop threads and close session!')\n",
    "        self.coord.request_stop()\n",
    "        self.coord.join(self.threads)\n",
    "        self.sess.close()\n",
    "\n",
    "\n",
    "def to_range(images, min_value=0.0, max_value=1.0, dtype=None):\n",
    "    \"\"\"\n",
    "    transform images from [-1.0, 1.0] to [min_value, max_value] of dtype\n",
    "    \"\"\"\n",
    "    assert \\\n",
    "        np.min(images) >= -1.0 - 1e-5 and np.max(images) <= 1.0 + 1e-5 \\\n",
    "        and (images.dtype == np.float32 or images.dtype == np.float64), \\\n",
    "        'The input images should be float64(32) and in the range of [-1.0, 1.0]!'\n",
    "    if dtype is None:\n",
    "        dtype = images.dtype\n",
    "    return ((images + 1.) / 2. * (max_value - min_value) + min_value).astype(dtype)\n",
    "\n",
    "\n",
    "def imwrite(image, path):\n",
    "    \"\"\" save an [-1.0, 1.0] image \"\"\"\n",
    "\n",
    "    if image.ndim == 3 and image.shape[2] == 1:  # for gray image\n",
    "        image = np.array(image, copy=True)\n",
    "        image.shape = image.shape[0:2]\n",
    "    return scipy.misc.imsave(path, to_range(image, 0, 255, np.uint8))\n",
    "\n",
    "\n",
    "def immerge(images, row, col):\n",
    "    \"\"\"\n",
    "    merge images into an image with (row * h) * (col * w)\n",
    "    `images` is in shape of N * H * W(* C=1 or 3)\n",
    "    \"\"\"\n",
    "\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    if images.ndim == 4:\n",
    "        img = np.zeros((h * row, w * col, images.shape[3]))\n",
    "    elif images.ndim == 3:\n",
    "        img = np.zeros((h * row, w * col))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % col\n",
    "        j = idx // col\n",
    "        img[j * h:j * h + h, i * w:i * w + w, ...] = image\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_fully_connected(inputs,\n",
    "                            num_outputs,\n",
    "                            activation_fn=tf.nn.relu,\n",
    "                            normalizer_fn=None,\n",
    "                            normalizer_params=None,\n",
    "                            weights_initializer=slim.xavier_initializer(),\n",
    "                            weights_regularizer=None,\n",
    "                            biases_initializer=tf.zeros_initializer(),\n",
    "                            biases_regularizer=None,\n",
    "                            reuse=None,\n",
    "                            variables_collections=None,\n",
    "                            outputs_collections=None,\n",
    "                            trainable=True,\n",
    "                            scope=None):\n",
    "    with tf.variable_scope(scope, 'flatten_fully_connected', [inputs]):\n",
    "        if inputs.shape.ndims > 2:\n",
    "            inputs = slim.flatten(inputs)\n",
    "        return slim.fully_connected(inputs,\n",
    "                                    num_outputs,\n",
    "                                    activation_fn,\n",
    "                                    normalizer_fn,\n",
    "                                    normalizer_params,\n",
    "                                    weights_initializer,\n",
    "                                    weights_regularizer,\n",
    "                                    biases_initializer,\n",
    "                                    biases_regularizer,\n",
    "                                    reuse,\n",
    "                                    variables_collections,\n",
    "                                    outputs_collections,\n",
    "                                    trainable,\n",
    "                                    scope)\n",
    "\n",
    "\n",
    "def leak_relu(x, leak, scope=None):\n",
    "    with tf.name_scope(scope, 'leak_relu', [x, leak]):\n",
    "        if leak < 1:\n",
    "            y = tf.maximum(x, leak * x)\n",
    "        else:\n",
    "            y = tf.minimum(x, leak * x)\n",
    "        return y\n",
    "    \n",
    "def l1_loss(x, y):\n",
    "    return tf.reduce_mean(tf.abs(x - y))\n",
    "\n",
    "def resize_nn(x, size):\n",
    "    return tf.image.resize_nearest_neighbor(x, size=(int(size), int(size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "slim layers:\n",
    "\n",
    "    conv2d(args):\n",
    "        inputs: \n",
    "            A 4-D tensor with dimensions [batch_size, height, width, channels]\n",
    "        num_outputs:\n",
    "            Integer, the number of output filters.\n",
    "        kernel_size:\n",
    "            Can be an int if both values are the same.\n",
    "        stride: \n",
    "            default=1\n",
    "        ...\n",
    "    \n",
    "    conv2d_transpose(args):\n",
    "        inputs:\n",
    "        num_outputs: \n",
    "            Integer, the number of output filters.\n",
    "        kernel_size:\n",
    "        stride: \n",
    "            default=1\n",
    "        ...\n",
    "        \n",
    "    batch_norm(args):\n",
    "        is_training: \n",
    "            Whether or not the layer is in training mode. In training mode\n",
    "            it would accumulate the statistics of the moments into `moving_mean` and\n",
    "            `moving_variance` using an exponential moving average with the given\n",
    "            `decay`. When it is not in training mode then it would use the values of\n",
    "            the `moving_mean` and the `moving_variance`.\n",
    "            \n",
    "'''\n",
    "\n",
    "# conv = partial(slim.conv2d, activation_fn=None, weights_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "# dconv = partial(slim.conv2d_transpose, activation_fn=None, weights_initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "# fc = partial(flatten_fully_connected, activation_fn=None, weights_initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "\n",
    "conv = partial(slim.conv2d, activation_fn=None)\n",
    "dconv = partial(slim.conv2d_transpose, activation_fn=None)\n",
    "fc = partial(flatten_fully_connected, activation_fn=None)\n",
    "\n",
    "\n",
    "relu = tf.nn.relu\n",
    "elu = tf.nn.elu\n",
    "lrelu = partial(leak_relu, leak=0.2)\n",
    "batch_norm = partial(slim.batch_norm, decay=0.9, scale=True, epsilon=1e-5, updates_collections=None)\n",
    "ln = slim.layer_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, data_size=64, filter_num=64, reuse=True, training=True):\n",
    "    bn = partial(batch_norm, is_training=training)\n",
    "    conv_bn_elu = partial(conv, normalizer_fn=bn, activation_fn=elu, biases_initializer=None)\n",
    "\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        y = fc(z, 8 * 8 * filter_num)\n",
    "        y = tf.reshape(y, [-1, 8, 8, filter_num])\n",
    "        \n",
    "        y = conv_bn_elu(y, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        y = conv_bn_elu(y, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        \n",
    "        y = resize_nn(y, data_size / 4)\n",
    "        \n",
    "        y = conv_bn_elu(y, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        y = conv_bn_elu(y, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        \n",
    "        y = resize_nn(y, data_size / 2)\n",
    "        \n",
    "        y = conv_bn_elu(y, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        y = conv_bn_elu(y, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        \n",
    "        y = resize_nn(y, data_size)\n",
    "        \n",
    "        y = conv_bn_elu(y, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        y = conv_bn_elu(y, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        \n",
    "        img = tf.tanh(conv(y, num_outputs=3, kernel_size=3, stride=1)) # Change number of out channels\n",
    "        return img\n",
    "\n",
    "\n",
    "def discriminator(img, data_size=64, filter_num=64, reuse=True, training=True):\n",
    "    bn = partial(batch_norm, is_training=training)\n",
    "    conv_bn_elu = partial(conv, normalizer_fn=bn, activation_fn=elu, biases_initializer=None)\n",
    "    h = 64 # or 128\n",
    "    \n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        encoder = conv_bn_elu(img, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        \n",
    "        encoder = conv_bn_elu(encoder, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        encoder = conv_bn_elu(encoder, num_outputs=filter_num * 2, kernel_size=3, stride=2)\n",
    "        \n",
    "        encoder = conv_bn_elu(encoder, num_outputs=filter_num * 2, kernel_size=3, stride=1)\n",
    "        encoder = conv_bn_elu(encoder, num_outputs=filter_num * 3, kernel_size=3, stride=2)\n",
    "        \n",
    "        encoder = conv_bn_elu(encoder, num_outputs=filter_num * 3, kernel_size=3, stride=1)\n",
    "        encoder = conv_bn_elu(encoder, num_outputs=filter_num * 4, kernel_size=3, stride=2)\n",
    "        \n",
    "        encoder = conv_bn_elu(encoder, num_outputs=filter_num * 4, kernel_size=3, stride=1)\n",
    "        encoder = conv_bn_elu(encoder, num_outputs=filter_num * 4, kernel_size=3, stride=1)\n",
    "\n",
    "        latent_space = fc(encoder, h)\n",
    "        \n",
    "        decoder = fc(latent_space, 8 * 8 * filter_num)\n",
    "        decoder = tf.reshape(decoder, [-1, 8, 8, filter_num])\n",
    "        \n",
    "        decoder = conv_bn_elu(decoder, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        decoder = conv_bn_elu(decoder, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        \n",
    "        decoder = resize_nn(decoder, data_size / 4)\n",
    "        \n",
    "        decoder = conv_bn_elu(decoder, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        decoder = conv_bn_elu(decoder, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        \n",
    "        decoder = resize_nn(decoder, data_size / 2)\n",
    "        \n",
    "        decoder = conv_bn_elu(decoder, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        decoder = conv_bn_elu(decoder, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        \n",
    "        decoder = resize_nn(decoder, data_size)\n",
    "        \n",
    "        decoder = conv_bn_elu(decoder, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        decoder = conv_bn_elu(decoder, num_outputs=filter_num, kernel_size=3, stride=1)\n",
    "        \n",
    "        reconst = tf.tanh(conv(decoder, num_outputs=3, kernel_size=3, stride=1))\n",
    "        return reconst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] DiskImageData: create session!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" param \"\"\"\n",
    "epoch = 50000\n",
    "batch_size = 32 # 16 from paper\n",
    "lr_in = 0.0001\n",
    "z_dim = 64\n",
    "clip = 0.01\n",
    "n_critic = 5\n",
    "gpu_id = 0\n",
    "\n",
    "lamda = 0.001\n",
    "gamma = 0.5\n",
    "beta1 = 0.5 #0.9\n",
    "\n",
    "# The number of run\n",
    "run_num = 10\n",
    "\n",
    "''' data '''\n",
    "\n",
    "\n",
    "def preprocess_fn(img):\n",
    "    #Transform it to be between -1 and 1\n",
    "    img = tf.to_float(img) / 127.5 - 1\n",
    "\n",
    "    return img\n",
    "\n",
    "file_paths = glob.glob(\"./Face_data/Celeba/dataset_64x64/*\")\n",
    "data_pool = DiskImageData(file_paths, batch_size, shape=[64, 64, 3], preprocess_fn=preprocess_fn)\n",
    "\n",
    "\n",
    "\"\"\" graphs \"\"\"\n",
    "with tf.device('/gpu:%d' % gpu_id):\n",
    "\n",
    "    ''' graph '''\n",
    "    # inputs\n",
    "    real = tf.placeholder(tf.float32, shape=[None, 64, 64, 3])\n",
    "    z = tf.placeholder(tf.float32, shape=[None, z_dim])\n",
    "    k_t = tf.placeholder(tf.float32, shape=(), name='kt') # shape of a scalar = ()\n",
    "    lr = tf.placeholder(tf.float32, name='lr')\n",
    "\n",
    "    # generate\n",
    "    fake = generator(z, reuse=False)\n",
    "\n",
    "    # discriminate\n",
    "    reconst_r = discriminator(real, reuse=False)\n",
    "    reconst_f = discriminator(fake)\n",
    "\n",
    "    # losses\n",
    "    AE_loss_r = l1_loss(real, reconst_r)\n",
    "    AE_loss_f = l1_loss(fake, reconst_f)\n",
    "    d_loss = AE_loss_r - k_t * AE_loss_f\n",
    "    g_loss = AE_loss_f\n",
    "    M_global = AE_loss_r + tf.abs(gamma * AE_loss_r - AE_loss_f)\n",
    "\n",
    "    # vars\n",
    "    d_vars = trainable_variables('discriminator')\n",
    "    g_vars = trainable_variables('generator')\n",
    "    \n",
    "    # optimizers\n",
    "    d_opt = tf.train.AdamOptimizer(lr, beta1).minimize(d_loss, var_list=d_vars)\n",
    "    g_opt = tf.train.AdamOptimizer(lr, beta1).minimize(g_loss, var_list=g_vars)\n",
    "    \n",
    "    # summaries\n",
    "    d_summary = summary({AE_loss_r: 'AE_real_reconst_loss', d_loss: 'd_loss'})\n",
    "    g_summary = summary({g_loss: 'g_loss'})\n",
    "    m_summary = summary({M_global: 'M_global'})\n",
    "\n",
    "    # sample\n",
    "    f_sample = generator(z, training=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Loading checkpoint...\n",
      " [*] No suitable checkpoint!\n",
      "Epoch: (  0) (    1/ 1208) -- g_loss: 0.7356, d_loss: 0.6701 AE_r: 0.6701, AE_f: 0.7356, kt: 0.00000000, M: 1.07066715\n",
      "Epoch: (  0) (  101/ 1208) -- g_loss: 0.1442, d_loss: 0.2052 AE_r: 0.2052, AE_f: 0.1442, kt: 0.00000000, M: 0.24682634\n",
      "Epoch: (  0) (  201/ 1208) -- g_loss: 0.1058, d_loss: 0.1794 AE_r: 0.1794, AE_f: 0.1058, kt: 0.00000000, M: 0.19556177\n",
      "Epoch: (  0) (  301/ 1208) -- g_loss: 0.0778, d_loss: 0.1651 AE_r: 0.1651, AE_f: 0.0778, kt: 0.00000545, M: 0.16981589\n",
      "Epoch: (  0) (  401/ 1208) -- g_loss: 0.0760, d_loss: 0.1574 AE_r: 0.1574, AE_f: 0.0760, kt: 0.00002277, M: 0.16007054\n",
      "Epoch: (  0) (  501/ 1208) -- g_loss: 0.0720, d_loss: 0.1534 AE_r: 0.1534, AE_f: 0.0720, kt: 0.00026636, M: 0.15809718\n",
      "Epoch: (  0) (  601/ 1208) -- g_loss: 0.0761, d_loss: 0.1595 AE_r: 0.1595, AE_f: 0.0761, kt: 0.00095698, M: 0.16317688\n",
      "Epoch: (  0) (  701/ 1208) -- g_loss: 0.0839, d_loss: 0.1572 AE_r: 0.1573, AE_f: 0.0839, kt: 0.00181920, M: 0.16249144\n",
      "Epoch: (  0) (  801/ 1208) -- g_loss: 0.0750, d_loss: 0.1518 AE_r: 0.1520, AE_f: 0.0750, kt: 0.00272633, M: 0.15288477\n",
      "Epoch: (  0) (  901/ 1208) -- g_loss: 0.0631, d_loss: 0.1527 AE_r: 0.1530, AE_f: 0.0631, kt: 0.00362761, M: 0.16632685\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(0)_(1000of1208).ckpt\n",
      "Epoch: (  0) ( 1001/ 1208) -- g_loss: 0.0548, d_loss: 0.1359 AE_r: 0.1362, AE_f: 0.0548, kt: 0.00465458, M: 0.14950217\n",
      "Epoch: (  0) ( 1101/ 1208) -- g_loss: 0.0608, d_loss: 0.1394 AE_r: 0.1397, AE_f: 0.0608, kt: 0.00572781, M: 0.14875783\n",
      "Epoch: (  0) ( 1201/ 1208) -- g_loss: 0.0515, d_loss: 0.1330 AE_r: 0.1333, AE_f: 0.0515, kt: 0.00675319, M: 0.14855998\n",
      "Epoch: (  1) (   93/ 1208) -- g_loss: 0.0502, d_loss: 0.1492 AE_r: 0.1496, AE_f: 0.0502, kt: 0.00789430, M: 0.17419349\n",
      "Epoch: (  1) (  193/ 1208) -- g_loss: 0.0675, d_loss: 0.1332 AE_r: 0.1337, AE_f: 0.0675, kt: 0.00906287, M: 0.13440406\n",
      "Epoch: (  1) (  293/ 1208) -- g_loss: 0.0577, d_loss: 0.1305 AE_r: 0.1310, AE_f: 0.0577, kt: 0.01008090, M: 0.13877660\n",
      "Epoch: (  1) (  393/ 1208) -- g_loss: 0.0740, d_loss: 0.1469 AE_r: 0.1476, AE_f: 0.0740, kt: 0.01087289, M: 0.14784763\n",
      "Epoch: (  1) (  493/ 1208) -- g_loss: 0.0693, d_loss: 0.1371 AE_r: 0.1378, AE_f: 0.0693, kt: 0.01145673, M: 0.13820951\n",
      "Epoch: (  1) (  593/ 1208) -- g_loss: 0.0644, d_loss: 0.1313 AE_r: 0.1320, AE_f: 0.0644, kt: 0.01202960, M: 0.13360751\n",
      "Epoch: (  1) (  693/ 1208) -- g_loss: 0.0656, d_loss: 0.1350 AE_r: 0.1358, AE_f: 0.0656, kt: 0.01254267, M: 0.13810296\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(1)_(792of1208).ckpt\n",
      "Epoch: (  1) (  793/ 1208) -- g_loss: 0.0632, d_loss: 0.1343 AE_r: 0.1350, AE_f: 0.0632, kt: 0.01309584, M: 0.13927558\n",
      "Epoch: (  1) (  893/ 1208) -- g_loss: 0.0558, d_loss: 0.1235 AE_r: 0.1242, AE_f: 0.0558, kt: 0.01374717, M: 0.13043277\n",
      "Epoch: (  1) (  993/ 1208) -- g_loss: 0.0578, d_loss: 0.1395 AE_r: 0.1402, AE_f: 0.0578, kt: 0.01436909, M: 0.15250370\n",
      "Epoch: (  1) ( 1093/ 1208) -- g_loss: 0.0531, d_loss: 0.1251 AE_r: 0.1258, AE_f: 0.0531, kt: 0.01501854, M: 0.13564096\n",
      "Epoch: (  1) ( 1193/ 1208) -- g_loss: 0.0589, d_loss: 0.1252 AE_r: 0.1261, AE_f: 0.0589, kt: 0.01562042, M: 0.13025576\n",
      "Epoch: (  2) (   85/ 1208) -- g_loss: 0.0611, d_loss: 0.1254 AE_r: 0.1263, AE_f: 0.0611, kt: 0.01623364, M: 0.12828942\n",
      "Epoch: (  2) (  185/ 1208) -- g_loss: 0.0546, d_loss: 0.1154 AE_r: 0.1163, AE_f: 0.0546, kt: 0.01674868, M: 0.11983940\n",
      "Epoch: (  2) (  285/ 1208) -- g_loss: 0.0610, d_loss: 0.1312 AE_r: 0.1322, AE_f: 0.0610, kt: 0.01725723, M: 0.13723339\n",
      "Epoch: (  2) (  385/ 1208) -- g_loss: 0.0621, d_loss: 0.1279 AE_r: 0.1289, AE_f: 0.0621, kt: 0.01776479, M: 0.13129715\n",
      "Epoch: (  2) (  485/ 1208) -- g_loss: 0.0539, d_loss: 0.1236 AE_r: 0.1245, AE_f: 0.0539, kt: 0.01839212, M: 0.13292465\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(2)_(584of1208).ckpt\n",
      "Epoch: (  2) (  585/ 1208) -- g_loss: 0.0552, d_loss: 0.1242 AE_r: 0.1251, AE_f: 0.0552, kt: 0.01891953, M: 0.13246394\n",
      "Epoch: (  2) (  685/ 1208) -- g_loss: 0.0661, d_loss: 0.1403 AE_r: 0.1415, AE_f: 0.0661, kt: 0.01920272, M: 0.14609405\n",
      "Epoch: (  2) (  785/ 1208) -- g_loss: 0.0613, d_loss: 0.1308 AE_r: 0.1319, AE_f: 0.0613, kt: 0.01944338, M: 0.13657783\n",
      "Epoch: (  2) (  885/ 1208) -- g_loss: 0.0547, d_loss: 0.1221 AE_r: 0.1231, AE_f: 0.0547, kt: 0.01966575, M: 0.12990941\n",
      "Epoch: (  2) (  985/ 1208) -- g_loss: 0.0640, d_loss: 0.1263 AE_r: 0.1274, AE_f: 0.0640, kt: 0.01983797, M: 0.12776292\n",
      "Epoch: (  2) ( 1085/ 1208) -- g_loss: 0.0582, d_loss: 0.1237 AE_r: 0.1248, AE_f: 0.0582, kt: 0.01990912, M: 0.12900671\n",
      "Epoch: (  2) ( 1185/ 1208) -- g_loss: 0.0609, d_loss: 0.1448 AE_r: 0.1459, AE_f: 0.0609, kt: 0.01988678, M: 0.15805923\n",
      "Epoch: (  3) (   77/ 1208) -- g_loss: 0.0598, d_loss: 0.1235 AE_r: 0.1247, AE_f: 0.0598, kt: 0.01996486, M: 0.12719201\n",
      "Epoch: (  3) (  177/ 1208) -- g_loss: 0.0643, d_loss: 0.1130 AE_r: 0.1142, AE_f: 0.0643, kt: 0.01985439, M: 0.12144053\n",
      "Epoch: (  3) (  277/ 1208) -- g_loss: 0.0667, d_loss: 0.1136 AE_r: 0.1148, AE_f: 0.0667, kt: 0.01950869, M: 0.12413687\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(3)_(376of1208).ckpt\n",
      "Epoch: (  3) (  377/ 1208) -- g_loss: 0.0601, d_loss: 0.1244 AE_r: 0.1256, AE_f: 0.0601, kt: 0.01925463, M: 0.12826909\n",
      "Epoch: (  3) (  477/ 1208) -- g_loss: 0.0568, d_loss: 0.1125 AE_r: 0.1136, AE_f: 0.0568, kt: 0.01916593, M: 0.11362384\n",
      "Epoch: (  3) (  577/ 1208) -- g_loss: 0.0615, d_loss: 0.1141 AE_r: 0.1152, AE_f: 0.0615, kt: 0.01898058, M: 0.11912324\n",
      "Epoch: (  3) (  677/ 1208) -- g_loss: 0.0630, d_loss: 0.1250 AE_r: 0.1261, AE_f: 0.0630, kt: 0.01886495, M: 0.12613305\n",
      "Epoch: (  3) (  777/ 1208) -- g_loss: 0.0581, d_loss: 0.1130 AE_r: 0.1140, AE_f: 0.0581, kt: 0.01860038, M: 0.11511079\n",
      "Epoch: (  3) (  877/ 1208) -- g_loss: 0.0599, d_loss: 0.1182 AE_r: 0.1193, AE_f: 0.0599, kt: 0.01824653, M: 0.11957527\n",
      "Epoch: (  3) (  977/ 1208) -- g_loss: 0.0577, d_loss: 0.1222 AE_r: 0.1232, AE_f: 0.0577, kt: 0.01804920, M: 0.12714380\n",
      "Epoch: (  3) ( 1077/ 1208) -- g_loss: 0.0653, d_loss: 0.1215 AE_r: 0.1226, AE_f: 0.0653, kt: 0.01779165, M: 0.12658431\n",
      "Epoch: (  3) ( 1177/ 1208) -- g_loss: 0.0605, d_loss: 0.1121 AE_r: 0.1131, AE_f: 0.0605, kt: 0.01746233, M: 0.11700378\n",
      "Epoch: (  4) (   69/ 1208) -- g_loss: 0.0608, d_loss: 0.1164 AE_r: 0.1174, AE_f: 0.0608, kt: 0.01716720, M: 0.11948794\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(4)_(168of1208).ckpt\n",
      "Epoch: (  4) (  169/ 1208) -- g_loss: 0.0634, d_loss: 0.1127 AE_r: 0.1138, AE_f: 0.0634, kt: 0.01684674, M: 0.12026756\n",
      "Epoch: (  4) (  269/ 1208) -- g_loss: 0.0673, d_loss: 0.1203 AE_r: 0.1214, AE_f: 0.0673, kt: 0.01670279, M: 0.12798188\n",
      "Epoch: (  4) (  369/ 1208) -- g_loss: 0.0597, d_loss: 0.1193 AE_r: 0.1202, AE_f: 0.0597, kt: 0.01649572, M: 0.12057865\n",
      "Epoch: (  4) (  469/ 1208) -- g_loss: 0.0612, d_loss: 0.1181 AE_r: 0.1191, AE_f: 0.0612, kt: 0.01627950, M: 0.12079329\n",
      "Epoch: (  4) (  569/ 1208) -- g_loss: 0.0595, d_loss: 0.1239 AE_r: 0.1248, AE_f: 0.0595, kt: 0.01603765, M: 0.12778880\n",
      "Epoch: (  4) (  669/ 1208) -- g_loss: 0.0621, d_loss: 0.1166 AE_r: 0.1175, AE_f: 0.0621, kt: 0.01581322, M: 0.12084568\n",
      "Epoch: (  4) (  769/ 1208) -- g_loss: 0.0591, d_loss: 0.1170 AE_r: 0.1179, AE_f: 0.0591, kt: 0.01565531, M: 0.11804534\n",
      "Epoch: (  4) (  869/ 1208) -- g_loss: 0.0630, d_loss: 0.1113 AE_r: 0.1122, AE_f: 0.0630, kt: 0.01545308, M: 0.11906982\n",
      "Epoch: (  4) (  969/ 1208) -- g_loss: 0.0675, d_loss: 0.1225 AE_r: 0.1234, AE_f: 0.0675, kt: 0.01521585, M: 0.12925958\n",
      "Epoch: (  4) ( 1069/ 1208) -- g_loss: 0.0629, d_loss: 0.1153 AE_r: 0.1162, AE_f: 0.0629, kt: 0.01499980, M: 0.12098197\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(4)_(1168of1208).ckpt\n",
      "Epoch: (  4) ( 1169/ 1208) -- g_loss: 0.0595, d_loss: 0.1302 AE_r: 0.1310, AE_f: 0.0595, kt: 0.01470628, M: 0.13701519\n",
      "Epoch: (  5) (   61/ 1208) -- g_loss: 0.0651, d_loss: 0.1164 AE_r: 0.1173, AE_f: 0.0651, kt: 0.01450731, M: 0.12380280\n",
      "Epoch: (  5) (  161/ 1208) -- g_loss: 0.0606, d_loss: 0.1179 AE_r: 0.1188, AE_f: 0.0606, kt: 0.01432020, M: 0.12002330\n",
      "Epoch: (  5) (  261/ 1208) -- g_loss: 0.0609, d_loss: 0.1168 AE_r: 0.1176, AE_f: 0.0609, kt: 0.01414121, M: 0.11969529\n",
      "Epoch: (  5) (  361/ 1208) -- g_loss: 0.0624, d_loss: 0.1242 AE_r: 0.1250, AE_f: 0.0624, kt: 0.01395443, M: 0.12515621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: (  5) (  461/ 1208) -- g_loss: 0.0568, d_loss: 0.1168 AE_r: 0.1175, AE_f: 0.0568, kt: 0.01381732, M: 0.11948251\n",
      "Epoch: (  5) (  561/ 1208) -- g_loss: 0.0646, d_loss: 0.1198 AE_r: 0.1207, AE_f: 0.0646, kt: 0.01363286, M: 0.12489434\n",
      "Epoch: (  5) (  661/ 1208) -- g_loss: 0.0750, d_loss: 0.1099 AE_r: 0.1108, AE_f: 0.0750, kt: 0.01336300, M: 0.13043889\n",
      "Epoch: (  5) (  761/ 1208) -- g_loss: 0.0595, d_loss: 0.1163 AE_r: 0.1170, AE_f: 0.0595, kt: 0.01316805, M: 0.11798152\n",
      "Epoch: (  5) (  861/ 1208) -- g_loss: 0.0647, d_loss: 0.1048 AE_r: 0.1056, AE_f: 0.0647, kt: 0.01309334, M: 0.11746248\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(5)_(960of1208).ckpt\n",
      "Epoch: (  5) (  961/ 1208) -- g_loss: 0.0625, d_loss: 0.1197 AE_r: 0.1204, AE_f: 0.0625, kt: 0.01305000, M: 0.12276014\n",
      "Epoch: (  5) ( 1061/ 1208) -- g_loss: 0.0601, d_loss: 0.1097 AE_r: 0.1105, AE_f: 0.0601, kt: 0.01296868, M: 0.11537825\n",
      "Epoch: (  5) ( 1161/ 1208) -- g_loss: 0.0576, d_loss: 0.1038 AE_r: 0.1045, AE_f: 0.0576, kt: 0.01285109, M: 0.10986338\n",
      "Epoch: (  6) (   53/ 1208) -- g_loss: 0.0629, d_loss: 0.1052 AE_r: 0.1060, AE_f: 0.0629, kt: 0.01270258, M: 0.11587856\n",
      "Epoch: (  6) (  153/ 1208) -- g_loss: 0.0569, d_loss: 0.1095 AE_r: 0.1102, AE_f: 0.0569, kt: 0.01259172, M: 0.11196890\n",
      "Epoch: (  6) (  253/ 1208) -- g_loss: 0.0603, d_loss: 0.1108 AE_r: 0.1115, AE_f: 0.0603, kt: 0.01248703, M: 0.11602775\n",
      "Epoch: (  6) (  353/ 1208) -- g_loss: 0.0582, d_loss: 0.1196 AE_r: 0.1203, AE_f: 0.0582, kt: 0.01239192, M: 0.12222664\n",
      "Epoch: (  6) (  453/ 1208) -- g_loss: 0.0582, d_loss: 0.1154 AE_r: 0.1161, AE_f: 0.0582, kt: 0.01238878, M: 0.11619352\n",
      "Epoch: (  6) (  553/ 1208) -- g_loss: 0.0647, d_loss: 0.1118 AE_r: 0.1126, AE_f: 0.0647, kt: 0.01231751, M: 0.12097713\n",
      "Epoch: (  6) (  653/ 1208) -- g_loss: 0.0559, d_loss: 0.1193 AE_r: 0.1199, AE_f: 0.0559, kt: 0.01223376, M: 0.12403751\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(6)_(752of1208).ckpt\n",
      "Epoch: (  6) (  753/ 1208) -- g_loss: 0.0557, d_loss: 0.1162 AE_r: 0.1168, AE_f: 0.0557, kt: 0.01212416, M: 0.11958829\n",
      "Epoch: (  6) (  853/ 1208) -- g_loss: 0.0531, d_loss: 0.1251 AE_r: 0.1257, AE_f: 0.0531, kt: 0.01211182, M: 0.13546108\n",
      "Epoch: (  6) (  953/ 1208) -- g_loss: 0.0521, d_loss: 0.1109 AE_r: 0.1115, AE_f: 0.0521, kt: 0.01208449, M: 0.11515890\n",
      "Epoch: (  6) ( 1053/ 1208) -- g_loss: 0.0570, d_loss: 0.1153 AE_r: 0.1160, AE_f: 0.0570, kt: 0.01206800, M: 0.11705071\n",
      "Epoch: (  6) ( 1153/ 1208) -- g_loss: 0.0578, d_loss: 0.1153 AE_r: 0.1160, AE_f: 0.0578, kt: 0.01199902, M: 0.11617393\n",
      "Epoch: (  7) (   45/ 1208) -- g_loss: 0.0547, d_loss: 0.1130 AE_r: 0.1136, AE_f: 0.0547, kt: 0.01185742, M: 0.11571093\n",
      "Epoch: (  7) (  145/ 1208) -- g_loss: 0.0598, d_loss: 0.1097 AE_r: 0.1103, AE_f: 0.0598, kt: 0.01173119, M: 0.11499935\n",
      "Epoch: (  7) (  245/ 1208) -- g_loss: 0.0584, d_loss: 0.1101 AE_r: 0.1107, AE_f: 0.0584, kt: 0.01160023, M: 0.11373483\n",
      "Epoch: (  7) (  345/ 1208) -- g_loss: 0.0550, d_loss: 0.1100 AE_r: 0.1106, AE_f: 0.0550, kt: 0.01156221, M: 0.11096337\n",
      "Epoch: (  7) (  445/ 1208) -- g_loss: 0.0574, d_loss: 0.1155 AE_r: 0.1162, AE_f: 0.0574, kt: 0.01155340, M: 0.11681846\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(7)_(544of1208).ckpt\n",
      "Epoch: (  7) (  545/ 1208) -- g_loss: 0.0536, d_loss: 0.1122 AE_r: 0.1128, AE_f: 0.0536, kt: 0.01143685, M: 0.11554470\n",
      "Epoch: (  7) (  645/ 1208) -- g_loss: 0.0568, d_loss: 0.0994 AE_r: 0.1000, AE_f: 0.0568, kt: 0.01132260, M: 0.10675003\n",
      "Epoch: (  7) (  745/ 1208) -- g_loss: 0.0611, d_loss: 0.1120 AE_r: 0.1126, AE_f: 0.0611, kt: 0.01126850, M: 0.11742089\n",
      "Epoch: (  7) (  845/ 1208) -- g_loss: 0.0543, d_loss: 0.1149 AE_r: 0.1155, AE_f: 0.0543, kt: 0.01118411, M: 0.11889261\n",
      "Epoch: (  7) (  945/ 1208) -- g_loss: 0.0579, d_loss: 0.1086 AE_r: 0.1092, AE_f: 0.0579, kt: 0.01109549, M: 0.11254088\n",
      "Epoch: (  7) ( 1045/ 1208) -- g_loss: 0.0573, d_loss: 0.1142 AE_r: 0.1148, AE_f: 0.0573, kt: 0.01101070, M: 0.11487553\n",
      "Epoch: (  7) ( 1145/ 1208) -- g_loss: 0.0576, d_loss: 0.1063 AE_r: 0.1069, AE_f: 0.0576, kt: 0.01080961, M: 0.11107228\n",
      "Epoch: (  8) (   37/ 1208) -- g_loss: 0.0559, d_loss: 0.1048 AE_r: 0.1054, AE_f: 0.0559, kt: 0.01059292, M: 0.10855489\n",
      "Epoch: (  8) (  137/ 1208) -- g_loss: 0.0574, d_loss: 0.1178 AE_r: 0.1184, AE_f: 0.0574, kt: 0.01041533, M: 0.12024204\n",
      "Epoch: (  8) (  237/ 1208) -- g_loss: 0.0542, d_loss: 0.1189 AE_r: 0.1194, AE_f: 0.0542, kt: 0.01035094, M: 0.12490961\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(8)_(336of1208).ckpt\n",
      "Epoch: (  8) (  337/ 1208) -- g_loss: 0.0536, d_loss: 0.1187 AE_r: 0.1192, AE_f: 0.0536, kt: 0.01023713, M: 0.12527164\n",
      "Epoch: (  8) (  437/ 1208) -- g_loss: 0.0578, d_loss: 0.1083 AE_r: 0.1089, AE_f: 0.0578, kt: 0.01023755, M: 0.11221565\n",
      "Epoch: (  8) (  537/ 1208) -- g_loss: 0.0545, d_loss: 0.1145 AE_r: 0.1150, AE_f: 0.0545, kt: 0.01007944, M: 0.11806693\n",
      "Epoch: (  8) (  637/ 1208) -- g_loss: 0.0545, d_loss: 0.1065 AE_r: 0.1070, AE_f: 0.0545, kt: 0.01010758, M: 0.10799586\n",
      "Epoch: (  8) (  737/ 1208) -- g_loss: 0.0531, d_loss: 0.1097 AE_r: 0.1102, AE_f: 0.0531, kt: 0.01017562, M: 0.11226550\n",
      "Epoch: (  8) (  837/ 1208) -- g_loss: 0.0502, d_loss: 0.1073 AE_r: 0.1078, AE_f: 0.0502, kt: 0.01030808, M: 0.11156266\n",
      "Epoch: (  8) (  937/ 1208) -- g_loss: 0.0587, d_loss: 0.1154 AE_r: 0.1160, AE_f: 0.0587, kt: 0.01038447, M: 0.11666439\n",
      "Epoch: (  8) ( 1037/ 1208) -- g_loss: 0.0516, d_loss: 0.0990 AE_r: 0.0995, AE_f: 0.0516, kt: 0.01051175, M: 0.10135689\n",
      "Epoch: (  8) ( 1137/ 1208) -- g_loss: 0.0575, d_loss: 0.1148 AE_r: 0.1154, AE_f: 0.0575, kt: 0.01061428, M: 0.11562870\n",
      "Epoch: (  9) (   29/ 1208) -- g_loss: 0.0526, d_loss: 0.1102 AE_r: 0.1108, AE_f: 0.0526, kt: 0.01069331, M: 0.11356072\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(9)_(128of1208).ckpt\n",
      "Epoch: (  9) (  129/ 1208) -- g_loss: 0.0542, d_loss: 0.1065 AE_r: 0.1071, AE_f: 0.0542, kt: 0.01086561, M: 0.10776805\n",
      "Epoch: (  9) (  229/ 1208) -- g_loss: 0.0570, d_loss: 0.1105 AE_r: 0.1111, AE_f: 0.0570, kt: 0.01093392, M: 0.11257198\n",
      "Epoch: (  9) (  329/ 1208) -- g_loss: 0.0545, d_loss: 0.1106 AE_r: 0.1112, AE_f: 0.0545, kt: 0.01092884, M: 0.11221638\n",
      "Epoch: (  9) (  429/ 1208) -- g_loss: 0.0551, d_loss: 0.1028 AE_r: 0.1034, AE_f: 0.0551, kt: 0.01086563, M: 0.10676457\n",
      "Epoch: (  9) (  529/ 1208) -- g_loss: 0.0536, d_loss: 0.1136 AE_r: 0.1142, AE_f: 0.0536, kt: 0.01075945, M: 0.11763348\n",
      "Epoch: (  9) (  629/ 1208) -- g_loss: 0.0575, d_loss: 0.1099 AE_r: 0.1105, AE_f: 0.0575, kt: 0.01065335, M: 0.11268771\n",
      "Epoch: (  9) (  729/ 1208) -- g_loss: 0.0533, d_loss: 0.1177 AE_r: 0.1183, AE_f: 0.0533, kt: 0.01050746, M: 0.12408429\n",
      "Epoch: (  9) (  829/ 1208) -- g_loss: 0.0595, d_loss: 0.1094 AE_r: 0.1100, AE_f: 0.0595, kt: 0.01031443, M: 0.11448319\n",
      "Epoch: (  9) (  929/ 1208) -- g_loss: 0.0525, d_loss: 0.0995 AE_r: 0.1000, AE_f: 0.0525, kt: 0.01015432, M: 0.10247868\n",
      "Epoch: (  9) ( 1029/ 1208) -- g_loss: 0.0522, d_loss: 0.1108 AE_r: 0.1113, AE_f: 0.0522, kt: 0.01001930, M: 0.11476966\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(9)_(1128of1208).ckpt\n",
      "Epoch: (  9) ( 1129/ 1208) -- g_loss: 0.0631, d_loss: 0.1187 AE_r: 0.1192, AE_f: 0.0631, kt: 0.00987119, M: 0.12273121\n",
      "Epoch: ( 10) (   21/ 1208) -- g_loss: 0.0557, d_loss: 0.1087 AE_r: 0.1092, AE_f: 0.0557, kt: 0.00969145, M: 0.11033215\n",
      "Epoch: ( 10) (  121/ 1208) -- g_loss: 0.0604, d_loss: 0.1119 AE_r: 0.1124, AE_f: 0.0604, kt: 0.00948028, M: 0.11660288\n",
      "Epoch: ( 10) (  221/ 1208) -- g_loss: 0.0592, d_loss: 0.1040 AE_r: 0.1046, AE_f: 0.0592, kt: 0.00926225, M: 0.11151660\n",
      "Epoch: ( 10) (  321/ 1208) -- g_loss: 0.0522, d_loss: 0.1043 AE_r: 0.1048, AE_f: 0.0522, kt: 0.00917758, M: 0.10500550\n",
      "Epoch: ( 10) (  421/ 1208) -- g_loss: 0.0543, d_loss: 0.1122 AE_r: 0.1127, AE_f: 0.0543, kt: 0.00927391, M: 0.11468302\n",
      "Epoch: ( 10) (  521/ 1208) -- g_loss: 0.0499, d_loss: 0.1044 AE_r: 0.1049, AE_f: 0.0499, kt: 0.00941888, M: 0.10744274\n",
      "Epoch: ( 10) (  621/ 1208) -- g_loss: 0.0623, d_loss: 0.1104 AE_r: 0.1109, AE_f: 0.0623, kt: 0.00946625, M: 0.11773524\n",
      "Epoch: ( 10) (  721/ 1208) -- g_loss: 0.0504, d_loss: 0.1077 AE_r: 0.1082, AE_f: 0.0504, kt: 0.00945633, M: 0.11186698\n",
      "Epoch: ( 10) (  821/ 1208) -- g_loss: 0.0502, d_loss: 0.1003 AE_r: 0.1007, AE_f: 0.0502, kt: 0.00951952, M: 0.10087482\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(10)_(920of1208).ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: ( 10) (  921/ 1208) -- g_loss: 0.0530, d_loss: 0.1095 AE_r: 0.1100, AE_f: 0.0530, kt: 0.00948696, M: 0.11200358\n",
      "Epoch: ( 10) ( 1021/ 1208) -- g_loss: 0.0609, d_loss: 0.1065 AE_r: 0.1071, AE_f: 0.0609, kt: 0.00933726, M: 0.11446221\n",
      "Epoch: ( 10) ( 1121/ 1208) -- g_loss: 0.0562, d_loss: 0.1068 AE_r: 0.1073, AE_f: 0.0562, kt: 0.00917866, M: 0.10987800\n",
      "Epoch: ( 11) (   13/ 1208) -- g_loss: 0.0632, d_loss: 0.1074 AE_r: 0.1079, AE_f: 0.0632, kt: 0.00897975, M: 0.11712861\n",
      "Epoch: ( 11) (  113/ 1208) -- g_loss: 0.0599, d_loss: 0.1099 AE_r: 0.1104, AE_f: 0.0599, kt: 0.00888414, M: 0.11511378\n",
      "Epoch: ( 11) (  213/ 1208) -- g_loss: 0.0555, d_loss: 0.1105 AE_r: 0.1110, AE_f: 0.0555, kt: 0.00864284, M: 0.11100149\n",
      "Epoch: ( 11) (  313/ 1208) -- g_loss: 0.0538, d_loss: 0.1106 AE_r: 0.1110, AE_f: 0.0538, kt: 0.00856094, M: 0.11272662\n",
      "Epoch: ( 11) (  413/ 1208) -- g_loss: 0.0602, d_loss: 0.1037 AE_r: 0.1042, AE_f: 0.0602, kt: 0.00836671, M: 0.11233125\n",
      "Epoch: ( 11) (  513/ 1208) -- g_loss: 0.0595, d_loss: 0.1038 AE_r: 0.1043, AE_f: 0.0595, kt: 0.00808184, M: 0.11162741\n",
      "Epoch: ( 11) (  613/ 1208) -- g_loss: 0.0577, d_loss: 0.1103 AE_r: 0.1107, AE_f: 0.0577, kt: 0.00788027, M: 0.11303616\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(11)_(712of1208).ckpt\n",
      "Epoch: ( 11) (  713/ 1208) -- g_loss: 0.0571, d_loss: 0.1057 AE_r: 0.1061, AE_f: 0.0571, kt: 0.00772796, M: 0.11020191\n",
      "Epoch: ( 11) (  813/ 1208) -- g_loss: 0.0502, d_loss: 0.1021 AE_r: 0.1025, AE_f: 0.0502, kt: 0.00762969, M: 0.10344695\n",
      "Epoch: ( 11) (  913/ 1208) -- g_loss: 0.0530, d_loss: 0.1009 AE_r: 0.1013, AE_f: 0.0530, kt: 0.00768217, M: 0.10366070\n",
      "Epoch: ( 11) ( 1013/ 1208) -- g_loss: 0.0542, d_loss: 0.1122 AE_r: 0.1126, AE_f: 0.0542, kt: 0.00760500, M: 0.11466988\n",
      "Epoch: ( 11) ( 1113/ 1208) -- g_loss: 0.0556, d_loss: 0.1023 AE_r: 0.1027, AE_f: 0.0556, kt: 0.00739334, M: 0.10697705\n",
      "Epoch: ( 12) (    5/ 1208) -- g_loss: 0.0578, d_loss: 0.0964 AE_r: 0.0968, AE_f: 0.0578, kt: 0.00700462, M: 0.10616292\n",
      "Epoch: ( 12) (  105/ 1208) -- g_loss: 0.0578, d_loss: 0.1035 AE_r: 0.1039, AE_f: 0.0578, kt: 0.00670390, M: 0.10975713\n",
      "Epoch: ( 12) (  205/ 1208) -- g_loss: 0.0538, d_loss: 0.1156 AE_r: 0.1160, AE_f: 0.0538, kt: 0.00642383, M: 0.12017680\n",
      "Epoch: ( 12) (  305/ 1208) -- g_loss: 0.0619, d_loss: 0.1062 AE_r: 0.1066, AE_f: 0.0619, kt: 0.00603300, M: 0.11515520\n",
      "Epoch: ( 12) (  405/ 1208) -- g_loss: 0.0532, d_loss: 0.1113 AE_r: 0.1116, AE_f: 0.0532, kt: 0.00575407, M: 0.11421173\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(12)_(504of1208).ckpt\n",
      "Epoch: ( 12) (  505/ 1208) -- g_loss: 0.0567, d_loss: 0.1070 AE_r: 0.1073, AE_f: 0.0567, kt: 0.00564264, M: 0.11040376\n",
      "Epoch: ( 12) (  605/ 1208) -- g_loss: 0.0531, d_loss: 0.1051 AE_r: 0.1054, AE_f: 0.0531, kt: 0.00584954, M: 0.10582703\n",
      "Epoch: ( 12) (  705/ 1208) -- g_loss: 0.0505, d_loss: 0.1058 AE_r: 0.1061, AE_f: 0.0505, kt: 0.00611154, M: 0.10859275\n",
      "Epoch: ( 12) (  805/ 1208) -- g_loss: 0.0503, d_loss: 0.1026 AE_r: 0.1029, AE_f: 0.0503, kt: 0.00636149, M: 0.10402573\n",
      "Epoch: ( 12) (  905/ 1208) -- g_loss: 0.0582, d_loss: 0.1043 AE_r: 0.1046, AE_f: 0.0582, kt: 0.00628411, M: 0.11050026\n",
      "Epoch: ( 12) ( 1005/ 1208) -- g_loss: 0.0608, d_loss: 0.0998 AE_r: 0.1002, AE_f: 0.0608, kt: 0.00618484, M: 0.11091131\n",
      "Epoch: ( 12) ( 1105/ 1208) -- g_loss: 0.0591, d_loss: 0.1119 AE_r: 0.1123, AE_f: 0.0591, kt: 0.00609897, M: 0.11523905\n",
      "Epoch: ( 12) ( 1205/ 1208) -- g_loss: 0.0520, d_loss: 0.1028 AE_r: 0.1031, AE_f: 0.0520, kt: 0.00600863, M: 0.10353334\n",
      "Epoch: ( 13) (   97/ 1208) -- g_loss: 0.0575, d_loss: 0.1050 AE_r: 0.1053, AE_f: 0.0575, kt: 0.00604240, M: 0.11012322\n",
      "Epoch: ( 13) (  197/ 1208) -- g_loss: 0.0602, d_loss: 0.1079 AE_r: 0.1082, AE_f: 0.0602, kt: 0.00616147, M: 0.11427765\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(13)_(296of1208).ckpt\n",
      "Epoch: ( 13) (  297/ 1208) -- g_loss: 0.0510, d_loss: 0.1133 AE_r: 0.1136, AE_f: 0.0510, kt: 0.00624310, M: 0.11939975\n",
      "Epoch: ( 13) (  397/ 1208) -- g_loss: 0.0514, d_loss: 0.1089 AE_r: 0.1092, AE_f: 0.0514, kt: 0.00641812, M: 0.11247721\n",
      "Epoch: ( 13) (  497/ 1208) -- g_loss: 0.0489, d_loss: 0.1069 AE_r: 0.1072, AE_f: 0.0489, kt: 0.00648037, M: 0.11189366\n",
      "Epoch: ( 13) (  597/ 1208) -- g_loss: 0.0538, d_loss: 0.1059 AE_r: 0.1062, AE_f: 0.0538, kt: 0.00647494, M: 0.10690907\n",
      "Epoch: ( 13) (  697/ 1208) -- g_loss: 0.0536, d_loss: 0.1149 AE_r: 0.1152, AE_f: 0.0536, kt: 0.00644769, M: 0.11927450\n",
      "Epoch: ( 13) (  797/ 1208) -- g_loss: 0.0507, d_loss: 0.1141 AE_r: 0.1144, AE_f: 0.0507, kt: 0.00638189, M: 0.12083276\n",
      "Epoch: ( 13) (  897/ 1208) -- g_loss: 0.0500, d_loss: 0.1058 AE_r: 0.1061, AE_f: 0.0500, kt: 0.00652945, M: 0.10913824\n",
      "Epoch: ( 13) (  997/ 1208) -- g_loss: 0.0532, d_loss: 0.1083 AE_r: 0.1086, AE_f: 0.0532, kt: 0.00676386, M: 0.10968638\n",
      "Epoch: ( 13) ( 1097/ 1208) -- g_loss: 0.0551, d_loss: 0.1094 AE_r: 0.1097, AE_f: 0.0551, kt: 0.00696096, M: 0.10996675\n",
      "Epoch: ( 13) ( 1197/ 1208) -- g_loss: 0.0489, d_loss: 0.1054 AE_r: 0.1057, AE_f: 0.0489, kt: 0.00707131, M: 0.10965491\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(14)_(88of1208).ckpt\n",
      "Epoch: ( 14) (   89/ 1208) -- g_loss: 0.0510, d_loss: 0.1090 AE_r: 0.1094, AE_f: 0.0510, kt: 0.00724552, M: 0.11305944\n",
      "Epoch: ( 14) (  189/ 1208) -- g_loss: 0.0510, d_loss: 0.1015 AE_r: 0.1019, AE_f: 0.0510, kt: 0.00731464, M: 0.10192686\n",
      "Epoch: ( 14) (  289/ 1208) -- g_loss: 0.0565, d_loss: 0.1151 AE_r: 0.1155, AE_f: 0.0565, kt: 0.00732702, M: 0.11670926\n",
      "Epoch: ( 14) (  389/ 1208) -- g_loss: 0.0550, d_loss: 0.1078 AE_r: 0.1082, AE_f: 0.0550, kt: 0.00733298, M: 0.10912610\n",
      "Epoch: ( 14) (  489/ 1208) -- g_loss: 0.0520, d_loss: 0.1152 AE_r: 0.1156, AE_f: 0.0520, kt: 0.00718729, M: 0.12142219\n",
      "Epoch: ( 14) (  589/ 1208) -- g_loss: 0.0556, d_loss: 0.1035 AE_r: 0.1038, AE_f: 0.0556, kt: 0.00711755, M: 0.10748791\n",
      "Epoch: ( 14) (  689/ 1208) -- g_loss: 0.0526, d_loss: 0.1039 AE_r: 0.1043, AE_f: 0.0526, kt: 0.00703723, M: 0.10470043\n",
      "Epoch: ( 14) (  789/ 1208) -- g_loss: 0.0552, d_loss: 0.1036 AE_r: 0.1040, AE_f: 0.0552, kt: 0.00689163, M: 0.10720848\n",
      "Epoch: ( 14) (  889/ 1208) -- g_loss: 0.0621, d_loss: 0.1042 AE_r: 0.1046, AE_f: 0.0621, kt: 0.00645743, M: 0.11443197\n",
      "Epoch: ( 14) (  989/ 1208) -- g_loss: 0.0590, d_loss: 0.1054 AE_r: 0.1058, AE_f: 0.0590, kt: 0.00576669, M: 0.11183701\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(14)_(1088of1208).ckpt\n",
      "Epoch: ( 14) ( 1089/ 1208) -- g_loss: 0.0557, d_loss: 0.1058 AE_r: 0.1061, AE_f: 0.0557, kt: 0.00518314, M: 0.10875675\n",
      "Epoch: ( 14) ( 1189/ 1208) -- g_loss: 0.0585, d_loss: 0.1117 AE_r: 0.1120, AE_f: 0.0585, kt: 0.00474739, M: 0.11451881\n",
      "Epoch: ( 15) (   81/ 1208) -- g_loss: 0.0516, d_loss: 0.0977 AE_r: 0.0979, AE_f: 0.0516, kt: 0.00455124, M: 0.10051092\n",
      "Epoch: ( 15) (  181/ 1208) -- g_loss: 0.0530, d_loss: 0.1045 AE_r: 0.1048, AE_f: 0.0530, kt: 0.00462640, M: 0.10538637\n",
      "Epoch: ( 15) (  281/ 1208) -- g_loss: 0.0492, d_loss: 0.0997 AE_r: 0.1000, AE_f: 0.0492, kt: 0.00462121, M: 0.10077041\n",
      "Epoch: ( 15) (  381/ 1208) -- g_loss: 0.0496, d_loss: 0.1100 AE_r: 0.1102, AE_f: 0.0496, kt: 0.00467077, M: 0.11577697\n",
      "Epoch: ( 15) (  481/ 1208) -- g_loss: 0.0525, d_loss: 0.0976 AE_r: 0.0978, AE_f: 0.0525, kt: 0.00496367, M: 0.10137258\n",
      "Epoch: ( 15) (  581/ 1208) -- g_loss: 0.0501, d_loss: 0.1080 AE_r: 0.1083, AE_f: 0.0501, kt: 0.00539800, M: 0.11234800\n",
      "Epoch: ( 15) (  681/ 1208) -- g_loss: 0.0492, d_loss: 0.1041 AE_r: 0.1044, AE_f: 0.0492, kt: 0.00562456, M: 0.10746465\n",
      "Epoch: ( 15) (  781/ 1208) -- g_loss: 0.0524, d_loss: 0.1000 AE_r: 0.1003, AE_f: 0.0524, kt: 0.00582047, M: 0.10256466\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(15)_(880of1208).ckpt\n",
      "Epoch: ( 15) (  881/ 1208) -- g_loss: 0.0537, d_loss: 0.1190 AE_r: 0.1192, AE_f: 0.0537, kt: 0.00582761, M: 0.12512344\n",
      "Epoch: ( 15) (  981/ 1208) -- g_loss: 0.0503, d_loss: 0.1098 AE_r: 0.1101, AE_f: 0.0503, kt: 0.00576612, M: 0.11488219\n",
      "Epoch: ( 15) ( 1081/ 1208) -- g_loss: 0.0537, d_loss: 0.1049 AE_r: 0.1052, AE_f: 0.0537, kt: 0.00572102, M: 0.10627194\n",
      "Epoch: ( 15) ( 1181/ 1208) -- g_loss: 0.0551, d_loss: 0.1068 AE_r: 0.1071, AE_f: 0.0551, kt: 0.00567942, M: 0.10862704\n",
      "Epoch: ( 16) (   73/ 1208) -- g_loss: 0.0510, d_loss: 0.1018 AE_r: 0.1021, AE_f: 0.0510, kt: 0.00559260, M: 0.10215909\n",
      "Epoch: ( 16) (  173/ 1208) -- g_loss: 0.0552, d_loss: 0.1014 AE_r: 0.1017, AE_f: 0.0552, kt: 0.00555215, M: 0.10607049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: ( 16) (  273/ 1208) -- g_loss: 0.0547, d_loss: 0.1078 AE_r: 0.1081, AE_f: 0.0547, kt: 0.00543232, M: 0.10876576\n",
      "Epoch: ( 16) (  373/ 1208) -- g_loss: 0.0543, d_loss: 0.1113 AE_r: 0.1115, AE_f: 0.0543, kt: 0.00520339, M: 0.11295637\n",
      "Epoch: ( 16) (  473/ 1208) -- g_loss: 0.0583, d_loss: 0.1023 AE_r: 0.1026, AE_f: 0.0583, kt: 0.00502361, M: 0.10954330\n",
      "Epoch: ( 16) (  573/ 1208) -- g_loss: 0.0551, d_loss: 0.1103 AE_r: 0.1106, AE_f: 0.0551, kt: 0.00472448, M: 0.11076194\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(16)_(672of1208).ckpt\n",
      "Epoch: ( 16) (  673/ 1208) -- g_loss: 0.0535, d_loss: 0.1007 AE_r: 0.1009, AE_f: 0.0535, kt: 0.00444984, M: 0.10392333\n",
      "Epoch: ( 16) (  773/ 1208) -- g_loss: 0.0557, d_loss: 0.1032 AE_r: 0.1035, AE_f: 0.0557, kt: 0.00426398, M: 0.10740943\n",
      "Epoch: ( 16) (  873/ 1208) -- g_loss: 0.0513, d_loss: 0.1029 AE_r: 0.1031, AE_f: 0.0513, kt: 0.00409791, M: 0.10346049\n",
      "Epoch: ( 16) (  973/ 1208) -- g_loss: 0.0518, d_loss: 0.1048 AE_r: 0.1050, AE_f: 0.0518, kt: 0.00388611, M: 0.10567526\n",
      "Epoch: ( 16) ( 1073/ 1208) -- g_loss: 0.0547, d_loss: 0.0995 AE_r: 0.0997, AE_f: 0.0547, kt: 0.00364057, M: 0.10458566\n",
      "Epoch: ( 16) ( 1173/ 1208) -- g_loss: 0.0490, d_loss: 0.1021 AE_r: 0.1023, AE_f: 0.0490, kt: 0.00379031, M: 0.10449494\n",
      "Epoch: ( 17) (   65/ 1208) -- g_loss: 0.0458, d_loss: 0.1084 AE_r: 0.1086, AE_f: 0.0458, kt: 0.00410991, M: 0.11707850\n",
      "Epoch: ( 17) (  165/ 1208) -- g_loss: 0.0479, d_loss: 0.1028 AE_r: 0.1030, AE_f: 0.0479, kt: 0.00458263, M: 0.10658327\n",
      "Epoch: ( 17) (  265/ 1208) -- g_loss: 0.0517, d_loss: 0.1055 AE_r: 0.1058, AE_f: 0.0517, kt: 0.00496282, M: 0.10700021\n",
      "Epoch: ( 17) (  365/ 1208) -- g_loss: 0.0594, d_loss: 0.1020 AE_r: 0.1023, AE_f: 0.0594, kt: 0.00489160, M: 0.11052939\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(17)_(464of1208).ckpt\n",
      "Epoch: ( 17) (  465/ 1208) -- g_loss: 0.0582, d_loss: 0.1054 AE_r: 0.1056, AE_f: 0.0582, kt: 0.00444217, M: 0.11100223\n",
      "Epoch: ( 17) (  565/ 1208) -- g_loss: 0.0598, d_loss: 0.1077 AE_r: 0.1079, AE_f: 0.0598, kt: 0.00399238, M: 0.11372716\n",
      "Epoch: ( 17) (  665/ 1208) -- g_loss: 0.0506, d_loss: 0.1063 AE_r: 0.1065, AE_f: 0.0506, kt: 0.00406472, M: 0.10914947\n",
      "Epoch: ( 17) (  765/ 1208) -- g_loss: 0.0484, d_loss: 0.1067 AE_r: 0.1069, AE_f: 0.0484, kt: 0.00423927, M: 0.11197435\n",
      "Epoch: ( 17) (  865/ 1208) -- g_loss: 0.0560, d_loss: 0.1155 AE_r: 0.1157, AE_f: 0.0560, kt: 0.00426190, M: 0.11754707\n",
      "Epoch: ( 17) (  965/ 1208) -- g_loss: 0.0528, d_loss: 0.1035 AE_r: 0.1037, AE_f: 0.0528, kt: 0.00407957, M: 0.10465129\n",
      "Epoch: ( 17) ( 1065/ 1208) -- g_loss: 0.0515, d_loss: 0.1093 AE_r: 0.1095, AE_f: 0.0515, kt: 0.00412376, M: 0.11279060\n",
      "Epoch: ( 17) ( 1165/ 1208) -- g_loss: 0.0510, d_loss: 0.1048 AE_r: 0.1050, AE_f: 0.0510, kt: 0.00395155, M: 0.10657858\n",
      "Epoch: ( 18) (   57/ 1208) -- g_loss: 0.0540, d_loss: 0.1134 AE_r: 0.1136, AE_f: 0.0540, kt: 0.00400449, M: 0.11640763\n",
      "Epoch: ( 18) (  157/ 1208) -- g_loss: 0.0497, d_loss: 0.1021 AE_r: 0.1023, AE_f: 0.0497, kt: 0.00410403, M: 0.10367689\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(18)_(256of1208).ckpt\n",
      "Epoch: ( 18) (  257/ 1208) -- g_loss: 0.0506, d_loss: 0.1004 AE_r: 0.1006, AE_f: 0.0506, kt: 0.00408724, M: 0.10088688\n",
      "Epoch: ( 18) (  357/ 1208) -- g_loss: 0.0577, d_loss: 0.1067 AE_r: 0.1069, AE_f: 0.0577, kt: 0.00398243, M: 0.11117191\n",
      "Epoch: ( 18) (  457/ 1208) -- g_loss: 0.0465, d_loss: 0.0981 AE_r: 0.0983, AE_f: 0.0465, kt: 0.00411312, M: 0.10087888\n",
      "Epoch: ( 18) (  557/ 1208) -- g_loss: 0.0518, d_loss: 0.1052 AE_r: 0.1054, AE_f: 0.0518, kt: 0.00461674, M: 0.10637117\n",
      "Epoch: ( 18) (  657/ 1208) -- g_loss: 0.0489, d_loss: 0.1004 AE_r: 0.1006, AE_f: 0.0489, kt: 0.00502104, M: 0.10206129\n",
      "Epoch: ( 18) (  757/ 1208) -- g_loss: 0.0481, d_loss: 0.1089 AE_r: 0.1091, AE_f: 0.0481, kt: 0.00530148, M: 0.11559859\n",
      "Epoch: ( 18) (  857/ 1208) -- g_loss: 0.0514, d_loss: 0.0985 AE_r: 0.0988, AE_f: 0.0514, kt: 0.00552425, M: 0.10076701\n",
      "Epoch: ( 18) (  957/ 1208) -- g_loss: 0.0477, d_loss: 0.1024 AE_r: 0.1027, AE_f: 0.0477, kt: 0.00579476, M: 0.10627102\n",
      "Epoch: ( 18) ( 1057/ 1208) -- g_loss: 0.0506, d_loss: 0.1102 AE_r: 0.1105, AE_f: 0.0506, kt: 0.00602932, M: 0.11508447\n",
      "Epoch: ( 18) ( 1157/ 1208) -- g_loss: 0.0520, d_loss: 0.1052 AE_r: 0.1055, AE_f: 0.0520, kt: 0.00620920, M: 0.10626697\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(19)_(48of1208).ckpt\n",
      "Epoch: ( 19) (   49/ 1208) -- g_loss: 0.0466, d_loss: 0.1030 AE_r: 0.1033, AE_f: 0.0466, kt: 0.00641650, M: 0.10838822\n",
      "Epoch: ( 19) (  149/ 1208) -- g_loss: 0.0535, d_loss: 0.1065 AE_r: 0.1069, AE_f: 0.0535, kt: 0.00635694, M: 0.10692069\n",
      "Epoch: ( 19) (  249/ 1208) -- g_loss: 0.0560, d_loss: 0.1087 AE_r: 0.1090, AE_f: 0.0560, kt: 0.00624872, M: 0.11050746\n",
      "Epoch: ( 19) (  349/ 1208) -- g_loss: 0.0534, d_loss: 0.1062 AE_r: 0.1065, AE_f: 0.0534, kt: 0.00608297, M: 0.10669630\n",
      "Epoch: ( 19) (  449/ 1208) -- g_loss: 0.0489, d_loss: 0.0998 AE_r: 0.1001, AE_f: 0.0489, kt: 0.00615320, M: 0.10127258\n",
      "Epoch: ( 19) (  549/ 1208) -- g_loss: 0.0507, d_loss: 0.0969 AE_r: 0.0972, AE_f: 0.0507, kt: 0.00628871, M: 0.09933113\n",
      "Epoch: ( 19) (  649/ 1208) -- g_loss: 0.0495, d_loss: 0.1088 AE_r: 0.1091, AE_f: 0.0495, kt: 0.00632017, M: 0.11411716\n",
      "Epoch: ( 19) (  749/ 1208) -- g_loss: 0.0508, d_loss: 0.1035 AE_r: 0.1038, AE_f: 0.0508, kt: 0.00635358, M: 0.10494759\n",
      "Epoch: ( 19) (  849/ 1208) -- g_loss: 0.0473, d_loss: 0.1016 AE_r: 0.1019, AE_f: 0.0473, kt: 0.00643088, M: 0.10553540\n",
      "Epoch: ( 19) (  949/ 1208) -- g_loss: 0.0487, d_loss: 0.1096 AE_r: 0.1099, AE_f: 0.0487, kt: 0.00654008, M: 0.11621543\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(19)_(1048of1208).ckpt\n",
      "Epoch: ( 19) ( 1049/ 1208) -- g_loss: 0.0483, d_loss: 0.1074 AE_r: 0.1077, AE_f: 0.0483, kt: 0.00667206, M: 0.11332060\n",
      "Epoch: ( 19) ( 1149/ 1208) -- g_loss: 0.0568, d_loss: 0.1093 AE_r: 0.1097, AE_f: 0.0568, kt: 0.00662575, M: 0.11165513\n",
      "Epoch: ( 20) (   41/ 1208) -- g_loss: 0.0539, d_loss: 0.1005 AE_r: 0.1008, AE_f: 0.0539, kt: 0.00634881, M: 0.10432074\n",
      "Epoch: ( 20) (  141/ 1208) -- g_loss: 0.0532, d_loss: 0.1007 AE_r: 0.1010, AE_f: 0.0532, kt: 0.00614905, M: 0.10367228\n",
      "Epoch: ( 20) (  241/ 1208) -- g_loss: 0.0506, d_loss: 0.0985 AE_r: 0.0988, AE_f: 0.0506, kt: 0.00621997, M: 0.09998840\n",
      "Epoch: ( 20) (  341/ 1208) -- g_loss: 0.0557, d_loss: 0.1073 AE_r: 0.1076, AE_f: 0.0557, kt: 0.00608465, M: 0.10948883\n",
      "Epoch: ( 20) (  441/ 1208) -- g_loss: 0.0527, d_loss: 0.1052 AE_r: 0.1055, AE_f: 0.0527, kt: 0.00584763, M: 0.10550218\n",
      "Epoch: ( 20) (  541/ 1208) -- g_loss: 0.0526, d_loss: 0.1018 AE_r: 0.1021, AE_f: 0.0526, kt: 0.00580112, M: 0.10358731\n",
      "Epoch: ( 20) (  641/ 1208) -- g_loss: 0.0530, d_loss: 0.1038 AE_r: 0.1041, AE_f: 0.0530, kt: 0.00565763, M: 0.10507308\n",
      "Epoch: ( 20) (  741/ 1208) -- g_loss: 0.0521, d_loss: 0.1043 AE_r: 0.1046, AE_f: 0.0521, kt: 0.00536949, M: 0.10481848\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(20)_(840of1208).ckpt\n",
      "Epoch: ( 20) (  841/ 1208) -- g_loss: 0.0506, d_loss: 0.1008 AE_r: 0.1011, AE_f: 0.0506, kt: 0.00523365, M: 0.10110911\n",
      "Epoch: ( 20) (  941/ 1208) -- g_loss: 0.0507, d_loss: 0.1026 AE_r: 0.1029, AE_f: 0.0507, kt: 0.00524688, M: 0.10356649\n",
      "Epoch: ( 20) ( 1041/ 1208) -- g_loss: 0.0604, d_loss: 0.1048 AE_r: 0.1051, AE_f: 0.0604, kt: 0.00521565, M: 0.11296168\n",
      "Epoch: ( 20) ( 1141/ 1208) -- g_loss: 0.0524, d_loss: 0.0967 AE_r: 0.0970, AE_f: 0.0524, kt: 0.00500133, M: 0.10089092\n",
      "Epoch: ( 21) (   33/ 1208) -- g_loss: 0.0494, d_loss: 0.0971 AE_r: 0.0973, AE_f: 0.0494, kt: 0.00491790, M: 0.09803013\n",
      "Epoch: ( 21) (  133/ 1208) -- g_loss: 0.0502, d_loss: 0.1016 AE_r: 0.1018, AE_f: 0.0502, kt: 0.00499281, M: 0.10256525\n",
      "Epoch: ( 21) (  233/ 1208) -- g_loss: 0.0538, d_loss: 0.0992 AE_r: 0.0995, AE_f: 0.0538, kt: 0.00490028, M: 0.10354213\n",
      "Epoch: ( 21) (  333/ 1208) -- g_loss: 0.0487, d_loss: 0.1121 AE_r: 0.1123, AE_f: 0.0487, kt: 0.00477971, M: 0.11976530\n",
      "Epoch: ( 21) (  433/ 1208) -- g_loss: 0.0539, d_loss: 0.1041 AE_r: 0.1043, AE_f: 0.0539, kt: 0.00463148, M: 0.10609097\n",
      "Epoch: ( 21) (  533/ 1208) -- g_loss: 0.0484, d_loss: 0.1031 AE_r: 0.1033, AE_f: 0.0484, kt: 0.00448995, M: 0.10654274\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(21)_(632of1208).ckpt\n",
      "Epoch: ( 21) (  633/ 1208) -- g_loss: 0.0530, d_loss: 0.1066 AE_r: 0.1068, AE_f: 0.0530, kt: 0.00429933, M: 0.10715552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: ( 21) (  733/ 1208) -- g_loss: 0.0508, d_loss: 0.1087 AE_r: 0.1090, AE_f: 0.0508, kt: 0.00419077, M: 0.11265823\n",
      "Epoch: ( 21) (  833/ 1208) -- g_loss: 0.0553, d_loss: 0.1024 AE_r: 0.1026, AE_f: 0.0553, kt: 0.00414052, M: 0.10657070\n",
      "Epoch: ( 21) (  933/ 1208) -- g_loss: 0.0488, d_loss: 0.1060 AE_r: 0.1062, AE_f: 0.0488, kt: 0.00429953, M: 0.11042653\n",
      "Epoch: ( 21) ( 1033/ 1208) -- g_loss: 0.0540, d_loss: 0.1020 AE_r: 0.1022, AE_f: 0.0540, kt: 0.00460392, M: 0.10506559\n",
      "Epoch: ( 21) ( 1133/ 1208) -- g_loss: 0.0459, d_loss: 0.1021 AE_r: 0.1023, AE_f: 0.0459, kt: 0.00485342, M: 0.10754471\n",
      "Epoch: ( 22) (   25/ 1208) -- g_loss: 0.0504, d_loss: 0.0963 AE_r: 0.0965, AE_f: 0.0504, kt: 0.00490580, M: 0.09864666\n",
      "Epoch: ( 22) (  125/ 1208) -- g_loss: 0.0510, d_loss: 0.0973 AE_r: 0.0975, AE_f: 0.0510, kt: 0.00490580, M: 0.09980148\n",
      "Epoch: ( 22) (  225/ 1208) -- g_loss: 0.0504, d_loss: 0.1026 AE_r: 0.1028, AE_f: 0.0504, kt: 0.00485028, M: 0.10383901\n",
      "Epoch: ( 22) (  325/ 1208) -- g_loss: 0.0511, d_loss: 0.1065 AE_r: 0.1067, AE_f: 0.0511, kt: 0.00488891, M: 0.10901885\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(22)_(424of1208).ckpt\n",
      "Epoch: ( 22) (  425/ 1208) -- g_loss: 0.0502, d_loss: 0.0998 AE_r: 0.1000, AE_f: 0.0502, kt: 0.00481376, M: 0.10019481\n",
      "Epoch: ( 22) (  525/ 1208) -- g_loss: 0.0480, d_loss: 0.1050 AE_r: 0.1053, AE_f: 0.0480, kt: 0.00474248, M: 0.10988383\n",
      "Epoch: ( 22) (  625/ 1208) -- g_loss: 0.0484, d_loss: 0.1022 AE_r: 0.1024, AE_f: 0.0484, kt: 0.00473513, M: 0.10526093\n",
      "Epoch: ( 22) (  725/ 1208) -- g_loss: 0.0505, d_loss: 0.0973 AE_r: 0.0976, AE_f: 0.0505, kt: 0.00473943, M: 0.09932670\n",
      "Epoch: ( 22) (  825/ 1208) -- g_loss: 0.0491, d_loss: 0.0961 AE_r: 0.0963, AE_f: 0.0491, kt: 0.00457658, M: 0.09727081\n",
      "Epoch: ( 22) (  925/ 1208) -- g_loss: 0.0519, d_loss: 0.1038 AE_r: 0.1041, AE_f: 0.0519, kt: 0.00484230, M: 0.10415720\n",
      "Epoch: ( 22) ( 1025/ 1208) -- g_loss: 0.0497, d_loss: 0.0984 AE_r: 0.0986, AE_f: 0.0497, kt: 0.00511424, M: 0.09896674\n",
      "Epoch: ( 22) ( 1125/ 1208) -- g_loss: 0.0464, d_loss: 0.1075 AE_r: 0.1077, AE_f: 0.0464, kt: 0.00534267, M: 0.11520843\n",
      "Epoch: ( 23) (   17/ 1208) -- g_loss: 0.0488, d_loss: 0.1036 AE_r: 0.1039, AE_f: 0.0488, kt: 0.00554339, M: 0.10698375\n",
      "Epoch: ( 23) (  117/ 1208) -- g_loss: 0.0536, d_loss: 0.1004 AE_r: 0.1007, AE_f: 0.0536, kt: 0.00570676, M: 0.10397202\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(23)_(216of1208).ckpt\n",
      "Epoch: ( 23) (  217/ 1208) -- g_loss: 0.0525, d_loss: 0.0994 AE_r: 0.0997, AE_f: 0.0525, kt: 0.00571604, M: 0.10231360\n",
      "Epoch: ( 23) (  317/ 1208) -- g_loss: 0.0490, d_loss: 0.1045 AE_r: 0.1048, AE_f: 0.0490, kt: 0.00561967, M: 0.10809795\n",
      "Epoch: ( 23) (  417/ 1208) -- g_loss: 0.0536, d_loss: 0.1003 AE_r: 0.1006, AE_f: 0.0536, kt: 0.00561705, M: 0.10390104\n",
      "Epoch: ( 23) (  517/ 1208) -- g_loss: 0.0520, d_loss: 0.1073 AE_r: 0.1076, AE_f: 0.0520, kt: 0.00552977, M: 0.10934668\n",
      "Epoch: ( 23) (  617/ 1208) -- g_loss: 0.0538, d_loss: 0.1036 AE_r: 0.1038, AE_f: 0.0538, kt: 0.00549230, M: 0.10575761\n",
      "Epoch: ( 23) (  717/ 1208) -- g_loss: 0.0467, d_loss: 0.0971 AE_r: 0.0974, AE_f: 0.0467, kt: 0.00562611, M: 0.09940434\n",
      "Epoch: ( 23) (  817/ 1208) -- g_loss: 0.0458, d_loss: 0.1010 AE_r: 0.1013, AE_f: 0.0458, kt: 0.00584539, M: 0.10615152\n",
      "Epoch: ( 23) (  917/ 1208) -- g_loss: 0.0490, d_loss: 0.1013 AE_r: 0.1016, AE_f: 0.0490, kt: 0.00600861, M: 0.10337779\n",
      "Epoch: ( 23) ( 1017/ 1208) -- g_loss: 0.0508, d_loss: 0.0985 AE_r: 0.0988, AE_f: 0.0508, kt: 0.00603170, M: 0.10022580\n",
      "Epoch: ( 23) ( 1117/ 1208) -- g_loss: 0.0537, d_loss: 0.0980 AE_r: 0.0983, AE_f: 0.0537, kt: 0.00599436, M: 0.10282888\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(24)_(8of1208).ckpt\n",
      "Epoch: ( 24) (    9/ 1208) -- g_loss: 0.0536, d_loss: 0.0941 AE_r: 0.0944, AE_f: 0.0536, kt: 0.00568145, M: 0.10081869\n",
      "Epoch: ( 24) (  109/ 1208) -- g_loss: 0.0582, d_loss: 0.1035 AE_r: 0.1038, AE_f: 0.0582, kt: 0.00524524, M: 0.11008677\n",
      "Epoch: ( 24) (  209/ 1208) -- g_loss: 0.0518, d_loss: 0.0994 AE_r: 0.0997, AE_f: 0.0518, kt: 0.00518744, M: 0.10160630\n",
      "Epoch: ( 24) (  309/ 1208) -- g_loss: 0.0502, d_loss: 0.1093 AE_r: 0.1095, AE_f: 0.0502, kt: 0.00509980, M: 0.11411295\n",
      "Epoch: ( 24) (  409/ 1208) -- g_loss: 0.0487, d_loss: 0.0959 AE_r: 0.0962, AE_f: 0.0487, kt: 0.00528307, M: 0.09678020\n",
      "Epoch: ( 24) (  509/ 1208) -- g_loss: 0.0533, d_loss: 0.1026 AE_r: 0.1028, AE_f: 0.0533, kt: 0.00512275, M: 0.10471547\n",
      "Epoch: ( 24) (  609/ 1208) -- g_loss: 0.0588, d_loss: 0.0985 AE_r: 0.0988, AE_f: 0.0588, kt: 0.00458542, M: 0.10818036\n",
      "Epoch: ( 24) (  709/ 1208) -- g_loss: 0.0553, d_loss: 0.0966 AE_r: 0.0969, AE_f: 0.0553, kt: 0.00409880, M: 0.10369401\n",
      "Epoch: ( 24) (  809/ 1208) -- g_loss: 0.0496, d_loss: 0.1128 AE_r: 0.1130, AE_f: 0.0496, kt: 0.00395085, M: 0.11981990\n",
      "Epoch: ( 24) (  909/ 1208) -- g_loss: 0.0480, d_loss: 0.1001 AE_r: 0.1002, AE_f: 0.0480, kt: 0.00404725, M: 0.10236678\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(24)_(1008of1208).ckpt\n",
      "Epoch: ( 24) ( 1009/ 1208) -- g_loss: 0.0513, d_loss: 0.1028 AE_r: 0.1031, AE_f: 0.0513, kt: 0.00421357, M: 0.10331700\n",
      "Epoch: ( 24) ( 1109/ 1208) -- g_loss: 0.0495, d_loss: 0.0971 AE_r: 0.0973, AE_f: 0.0495, kt: 0.00427740, M: 0.09817786\n",
      "Epoch: ( 25) (    1/ 1208) -- g_loss: 0.0513, d_loss: 0.1002 AE_r: 0.1004, AE_f: 0.0513, kt: 0.00418745, M: 0.10154110\n",
      "Epoch: ( 25) (  101/ 1208) -- g_loss: 0.0500, d_loss: 0.0988 AE_r: 0.0990, AE_f: 0.0500, kt: 0.00412413, M: 0.09949165\n",
      "Epoch: ( 25) (  201/ 1208) -- g_loss: 0.0528, d_loss: 0.1017 AE_r: 0.1019, AE_f: 0.0528, kt: 0.00390195, M: 0.10368048\n",
      "Epoch: ( 25) (  301/ 1208) -- g_loss: 0.0483, d_loss: 0.1064 AE_r: 0.1066, AE_f: 0.0483, kt: 0.00371187, M: 0.11152640\n",
      "Epoch: ( 25) (  401/ 1208) -- g_loss: 0.0545, d_loss: 0.1003 AE_r: 0.1005, AE_f: 0.0545, kt: 0.00372479, M: 0.10472075\n",
      "Epoch: ( 25) (  501/ 1208) -- g_loss: 0.0492, d_loss: 0.1112 AE_r: 0.1114, AE_f: 0.0492, kt: 0.00375095, M: 0.11791525\n",
      "Epoch: ( 25) (  601/ 1208) -- g_loss: 0.0464, d_loss: 0.0958 AE_r: 0.0960, AE_f: 0.0464, kt: 0.00387998, M: 0.09763957\n",
      "Epoch: ( 25) (  701/ 1208) -- g_loss: 0.0482, d_loss: 0.1010 AE_r: 0.1012, AE_f: 0.0482, kt: 0.00407688, M: 0.10357840\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(25)_(800of1208).ckpt\n",
      "Epoch: ( 25) (  801/ 1208) -- g_loss: 0.0516, d_loss: 0.0991 AE_r: 0.0993, AE_f: 0.0516, kt: 0.00416993, M: 0.10125365\n",
      "Epoch: ( 25) (  901/ 1208) -- g_loss: 0.0538, d_loss: 0.1004 AE_r: 0.1007, AE_f: 0.0538, kt: 0.00412597, M: 0.10416807\n",
      "Epoch: ( 25) ( 1001/ 1208) -- g_loss: 0.0531, d_loss: 0.1070 AE_r: 0.1073, AE_f: 0.0531, kt: 0.00418378, M: 0.10778593\n",
      "Epoch: ( 25) ( 1101/ 1208) -- g_loss: 0.0485, d_loss: 0.0973 AE_r: 0.0975, AE_f: 0.0485, kt: 0.00430204, M: 0.09767285\n",
      "Epoch: ( 25) ( 1201/ 1208) -- g_loss: 0.0495, d_loss: 0.1054 AE_r: 0.1056, AE_f: 0.0495, kt: 0.00444090, M: 0.10883274\n",
      "Epoch: ( 26) (   93/ 1208) -- g_loss: 0.0485, d_loss: 0.0956 AE_r: 0.0958, AE_f: 0.0485, kt: 0.00481470, M: 0.09641858\n",
      "Epoch: ( 26) (  193/ 1208) -- g_loss: 0.0513, d_loss: 0.0966 AE_r: 0.0969, AE_f: 0.0513, kt: 0.00491078, M: 0.09974712\n",
      "Epoch: ( 26) (  293/ 1208) -- g_loss: 0.0521, d_loss: 0.0979 AE_r: 0.0981, AE_f: 0.0521, kt: 0.00479575, M: 0.10117370\n",
      "Epoch: ( 26) (  393/ 1208) -- g_loss: 0.0565, d_loss: 0.1027 AE_r: 0.1030, AE_f: 0.0565, kt: 0.00464299, M: 0.10802002\n",
      "Epoch: ( 26) (  493/ 1208) -- g_loss: 0.0580, d_loss: 0.1108 AE_r: 0.1110, AE_f: 0.0580, kt: 0.00422501, M: 0.11351672\n",
      "Model saved in file: ./BEGAN/checkpoints/run9/Epoch_(26)_(592of1208).ckpt\n",
      "Epoch: ( 26) (  593/ 1208) -- g_loss: 0.0544, d_loss: 0.1034 AE_r: 0.1036, AE_f: 0.0544, kt: 0.00376622, M: 0.10614804\n",
      "Epoch: ( 26) (  693/ 1208) -- g_loss: 0.0514, d_loss: 0.1022 AE_r: 0.1024, AE_f: 0.0514, kt: 0.00360523, M: 0.10258077\n",
      "Epoch: ( 26) (  793/ 1208) -- g_loss: 0.0486, d_loss: 0.1023 AE_r: 0.1025, AE_f: 0.0486, kt: 0.00367025, M: 0.10518552\n",
      "Epoch: ( 26) (  893/ 1208) -- g_loss: 0.0457, d_loss: 0.1021 AE_r: 0.1022, AE_f: 0.0457, kt: 0.00388775, M: 0.10768440\n",
      "Epoch: ( 26) (  993/ 1208) -- g_loss: 0.0470, d_loss: 0.1019 AE_r: 0.1021, AE_f: 0.0470, kt: 0.00420226, M: 0.10616033\n",
      "Epoch: ( 26) ( 1093/ 1208) -- g_loss: 0.0462, d_loss: 0.1022 AE_r: 0.1024, AE_f: 0.0462, kt: 0.00448170, M: 0.10745396\n",
      "Epoch: ( 26) ( 1193/ 1208) -- g_loss: 0.0472, d_loss: 0.0951 AE_r: 0.0953, AE_f: 0.0472, kt: 0.00467961, M: 0.09579899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: ( 27) (   85/ 1208) -- g_loss: 0.0526, d_loss: 0.0966 AE_r: 0.0969, AE_f: 0.0526, kt: 0.00486580, M: 0.10099107\n",
      "Epoch: ( 27) (  185/ 1208) -- g_loss: 0.0504, d_loss: 0.0967 AE_r: 0.0970, AE_f: 0.0504, kt: 0.00498398, M: 0.09891035\n",
      " [*] Close main session!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-decb89ce964e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss_calculated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAE_loss_r_calculated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAE_loss_f_calculated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_opt_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_calculated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_opt_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# update kt, m_global -- (The range of kt is [0,1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/VirtualenvEnvironments/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/VirtualenvEnvironments/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/VirtualenvEnvironments/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/VirtualenvEnvironments/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/VirtualenvEnvironments/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" train \"\"\"\n",
    "''' init '''\n",
    "# session\n",
    "sess = session()\n",
    "# saver\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "# summary writer\n",
    "summary_writer = tf.summary.FileWriter('./BEGAN/summaries/run%s' % run_num, sess.graph)\n",
    "\n",
    "''' initialization '''\n",
    "ckpt_dir = './BEGAN/checkpoints/run%s' % run_num\n",
    "mkdir(ckpt_dir + '/')\n",
    "if not load_checkpoint(ckpt_dir, sess):\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "''' train '''\n",
    "try:\n",
    "    #z_ipt_sample = np.random.normal(size=[100, z_dim])\n",
    "    z_ipt_sample = np.random.uniform(-1., 1., size=[100, z_dim])\n",
    "    kt = np.float32(0.)\n",
    "    lr_i = np.float32(lr_in)\n",
    "    \n",
    "    batch_epoch = len(data_pool) // (batch_size * n_critic)\n",
    "    max_it = epoch * batch_epoch\n",
    "\n",
    "    for it in range(max_it):\n",
    "\n",
    "        # which epoch\n",
    "        epoch = it // batch_epoch\n",
    "        it_epoch = it % batch_epoch + 1\n",
    "\n",
    "        # batch data\n",
    "        real_ipt = data_pool.batch()\n",
    "        \n",
    "        z_ipt = np.random.uniform(-1., 1., size=[batch_size, z_dim])\n",
    "\n",
    "        # terms to be calculated & feed list\n",
    "        g_opt_list = [g_opt, g_loss, AE_loss_r, AE_loss_f]\n",
    "        d_opt_list = [d_opt, d_loss, d_summary, g_summary, m_summary]\n",
    "        feed_dict = {real: real_ipt, z: z_ipt, k_t: kt, lr: lr_i}\n",
    "\n",
    "        # run\n",
    "        _, g_loss_calculated, AE_loss_r_calculated, AE_loss_f_calculated = sess.run(g_opt_list, feed_dict=feed_dict)\n",
    "        _, d_loss_calculated, summary_d, summary_g, summary_m = sess.run(d_opt_list, feed_dict=feed_dict)\n",
    "        \n",
    "        # update kt, m_global -- (The range of kt is [0,1])\n",
    "        kt = kt + lamda * (gamma * AE_loss_r_calculated - AE_loss_f_calculated)\n",
    "        kt = np.maximum(np.minimum(1.,kt), 0.)\n",
    "        m_global = AE_loss_r_calculated + np.abs(gamma * AE_loss_r_calculated - AE_loss_f_calculated)\n",
    "        \n",
    "        # write train summary\n",
    "        summary_writer.add_summary(summary_d, it)\n",
    "        summary_writer.add_summary(summary_g, it)\n",
    "        summary_writer.add_summary(summary_m, it)\n",
    "\n",
    "        \n",
    "\n",
    "        # display\n",
    "        if it % 100 == 0:\n",
    "            print(\"Epoch: (%3d) (%5d/%5d) -- g_loss: %.4f, d_loss: %.4f AE_r: %.4f, AE_f: %.4f, kt: %.8f, M: %.8f\" \n",
    "                  % (epoch, it_epoch, batch_epoch, \n",
    "                     g_loss_calculated, d_loss_calculated,\n",
    "                     AE_loss_r_calculated, AE_loss_f_calculated,\n",
    "                     kt, m_global))\n",
    "        \n",
    "        # learning rate decay\n",
    "        if (it + 1) % 2000 == 0:\n",
    "            lr_i *= 0.95\n",
    "        \n",
    "        # save\n",
    "        if (it + 1) % 1000 == 0:\n",
    "            save_path = saver.save(sess, '%s/Epoch_(%d)_(%dof%d).ckpt' % (ckpt_dir, epoch, it_epoch, batch_epoch))\n",
    "            print('Model saved in file: % s' % save_path)\n",
    "\n",
    "        # sample\n",
    "        if (it + 1) % 100 == 0:\n",
    "            f_sample_opt = sess.run(f_sample, feed_dict={z: z_ipt_sample})\n",
    "\n",
    "            save_dir = './BEGAN/sample_images_while_training/run%s' % run_num\n",
    "            mkdir(save_dir + '/')\n",
    "            imwrite(immerge(f_sample_opt, 10, 10), '%s/Epoch_(%d)_(%dof%d).jpg' % (save_dir, epoch, it_epoch, batch_epoch))\n",
    "\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    print(\" [*] Close main session!\")\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Loading checkpoint...\n",
      "INFO:tensorflow:Restoring parameters from ./BEGAN/checkpoints/run6/Epoch_(91)_(72of1208).ckpt\n",
      " [*] Loading successful! Copy variables from ./BEGAN/checkpoints/run6/Epoch_(91)_(72of1208).ckpt\n",
      "Loading Model...\n",
      "./BEGAN/test_images_after_training/run6/Epoch_(91)_(872of1208)/fig2.jpg\n",
      " [*] Close main session!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" test \"\"\"\n",
    "\n",
    "run_num = 6\n",
    "epoch = 91\n",
    "it_epoch = 872\n",
    "batch_epoch = 1208\n",
    "\n",
    "''' init '''\n",
    "#Directory to save sample images from generator in.\n",
    "test_sample_directory = './BEGAN/test_images_after_training/run%s/Epoch_(%d)_(%dof%d)' % (run_num, epoch, it_epoch, batch_epoch)\n",
    "\n",
    "#Directory to load trained model from. : run_num, epoch, it_epoch, batch_epoch\n",
    "ckpt_dir = './BEGAN/checkpoints/run%s' % run_num\n",
    "batch_size_sample = 100\n",
    "\n",
    "# session\n",
    "sess = session()\n",
    "\n",
    "''' Reload the model '''\n",
    "load_checkpoint(ckpt_dir, sess)\n",
    "print('Loading Model...')\n",
    "\n",
    "''' Generate '''\n",
    "try:\n",
    "    #z_ipt_sample = np.random.normal(size=[100, z_dim])\n",
    "    z_ipt_sample = np.random.uniform(-1., 1., size=[batch_size_sample, z_dim]) #Generate a random z batch\n",
    "    \n",
    "    f_sample_opt = sess.run(f_sample, feed_dict={z: z_ipt_sample}) #Use new z to get sample images from generator.\n",
    "    if not os.path.exists(test_sample_directory):\n",
    "        os.makedirs(test_sample_directory)\n",
    "    \n",
    "    imwrite(immerge(f_sample_opt, 10, 10), test_sample_directory+'/fig'+str(sample_num)+'.jpg')\n",
    "    print(test_sample_directory+'/fig'+str(sample_num)+'.jpg')\n",
    "    sample_num += 1\n",
    "    \n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    print(\" [*] Close main session!\")\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
