{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StarGAN implementation v3\n",
    "\n",
    "L_adv changed to compare with target image, gp with target image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1711.09020\n",
    "https://github.com/goldkim92/StarGAN-tensorflow/blob/master/\n",
    "https://github.com/ly-atdawn/StarGAN-Tensorflow\n",
    "https://github.com/igul222/improved_wgan_training/blob/master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.misc as scm\n",
    "import numpy as np\n",
    "\n",
    "def make_project_dir(project_dir):\n",
    "    if not os.path.exists(project_dir):\n",
    "        os.makedirs(project_dir)\n",
    "        os.makedirs(os.path.join(project_dir, 'models'))\n",
    "        os.makedirs(os.path.join(project_dir, 'result'))\n",
    "        os.makedirs(os.path.join(project_dir, 'result_test'))\n",
    "\n",
    "\n",
    "def get_image(img_path, flip=False): # [0,255] to [-1,1]\n",
    "    img = scm.imread(img_path) \n",
    "    if flip:\n",
    "        img = np.fliplr(img)\n",
    "    img = img * 2. /255. - 1.\n",
    "    img = img[..., ::-1]  # rgb to bgr\n",
    "    return img\n",
    "\n",
    "def get_label(path, size):\n",
    "    label = int(path[-5])\n",
    "    one_hot = np.zeros(size)\n",
    "    one_hot[ label ] = 1.0\n",
    "    one_hot[ one_hot==0 ] = 0.0\n",
    "    return one_hot\n",
    "\n",
    "def inverse_image(img): # [-1,1] to [0,255]\n",
    "    img = (img + 1.) / 2. * 255.\n",
    "    img[img > 255] = 255\n",
    "    img[img < 0] = 0\n",
    "    img = img[..., ::-1] # bgr to rgb\n",
    "    return img\n",
    "\n",
    "def pair_expressions(paths):\n",
    "    subject_exprs = []\n",
    "    subject_pairs = []\n",
    "    all_pairs = []\n",
    "    last_subject = 0\n",
    "\n",
    "    # Pair all expression of a subject\n",
    "    for path in paths:\n",
    "        subject = int(path[-10:-6])\n",
    "\n",
    "        if subject != last_subject and last_subject != 0:\n",
    "            subject_pairs = [(x, y) for x in subject_exprs for y in subject_exprs]\n",
    "            all_pairs.extend(subject_pairs)\n",
    "            subject_exprs = []\n",
    "\n",
    "        subject_exprs.append(path)\n",
    "        last_subject = subject\n",
    "\n",
    "    # Last subject\n",
    "    subject_pairs = [(x, y) for x in subject_exprs for y in subject_exprs]\n",
    "    all_pairs.extend(subject_pairs)\n",
    "    return all_pairs\n",
    "\n",
    "def get_shape_c(tensor): # static shape\n",
    "    return tensor.get_shape().as_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits\n",
    "\n",
    "def conv(x, filter_shape, bias=True, stride=1, padding=\"VALID\", name=\"conv2d\"):\n",
    "    kw, kh, nin, nout = filter_shape\n",
    "\n",
    "    stddev = np.sqrt(2.0/(np.sqrt(nin*nout)*kw*kh))\n",
    "    k_initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        x = tf.layers.conv2d(x, filters=nout, kernel_size=(kw, kh), strides=(stride, stride), padding=padding, \n",
    "                             use_bias=bias, kernel_initializer=k_initializer)\n",
    "    return x\n",
    "\n",
    "def deconv(x, filter_shape, bias=True, stride=1, padding=\"VALID\", name=\"conv2d_transpose\"):\n",
    "    kw, kh, nin, nout = filter_shape\n",
    "\n",
    "    stddev = np.sqrt(1.0/(np.sqrt(nin*nout)*kw*kh))\n",
    "    k_initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "    with tf.variable_scope(name):\n",
    "        x = tf.layers.conv2d_transpose(x, filters=nout, kernel_size=(kw, kh), strides=(stride, stride), padding=padding, \n",
    "                                       use_bias=bias, kernel_initializer=k_initializer)\n",
    "    return x\n",
    "\n",
    "def fc(x, output_shape, bias=True, name='fc'):\n",
    "    shape = x.get_shape().as_list()\n",
    "    dim = np.prod(shape[1:])\n",
    "    x = tf.reshape(x, [-1, dim])\n",
    "    input_shape = dim\n",
    "\n",
    "    stddev = np.sqrt(1.0/(np.sqrt(input_shape*output_shape)))\n",
    "    initializer = tf.random_normal_initializer(stddev=stddev)\n",
    "    with tf.variable_scope(name):\n",
    "        weight = tf.get_variable(\"weight\", shape=[input_shape, output_shape], initializer=initializer)\n",
    "        x = tf.matmul(x, weight)\n",
    "\n",
    "        if bias:\n",
    "            b = tf.get_variable(\"bias\", shape=[output_shape], initializer=tf.constant_initializer(0.))\n",
    "            x = tf.nn.bias_add(x, b)\n",
    "    return x\n",
    "\n",
    "\n",
    "def pool(x, r=2, s=1):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, r, r, 1], strides=[1, s, s, 1], padding=\"SAME\")\n",
    "\n",
    "def instance_norm(input, name='instance_norm'):\n",
    "    with tf.variable_scope(name):\n",
    "        depth = input.get_shape()[3]\n",
    "        scale = tf.get_variable('scale', [depth], initializer=tf.random_normal_initializer(1.0, 0.02, dtype=tf.float32))\n",
    "        offset = tf.get_variable('offset', [depth], initializer=tf.constant_initializer(0.0))\n",
    "        mean, variance = tf.nn.moments(input, axes=[1,2], keep_dims=True)\n",
    "        epsilon = 1e-5\n",
    "        inv = tf.rsqrt(variance + epsilon)\n",
    "        normalized = (input-mean)*inv\n",
    "        return scale*normalized + offset\n",
    "\n",
    "def l1_loss(x, y):\n",
    "    return tf.reduce_mean(tf.abs(x - y))\n",
    "\n",
    "def l2_loss(x, y):\n",
    "    return tf.reduce_mean(tf.square(x - y))\n",
    "\n",
    "def resize_nn(x, size):\n",
    "    return tf.image.resize_nearest_neighbor(x, size=(int(size), int(size)))\n",
    "\n",
    "def lrelu(x, leak=0.01, name='lrelu'): #lrelu(x, leak=0.2, name='lrelu'):\n",
    "    return tf.maximum(x, leak*x)\n",
    "\n",
    "def gradient_penalty(real, fake, f):\n",
    "        def interpolate(a, b):\n",
    "            shape = tf.concat((tf.shape(a)[0:1], tf.tile([1], [a.shape.ndims - 1])), axis=0)\n",
    "            alpha = tf.random_uniform(shape=shape, minval=0., maxval=1.)\n",
    "            inter = a + alpha * (b - a)\n",
    "            inter.set_shape(a.get_shape().as_list())\n",
    "            return inter\n",
    "\n",
    "        x = interpolate(real, fake)\n",
    "        pred, _ = f(x, reuse=True)\n",
    "        gradients = tf.gradients(pred, x)[0]\n",
    "        slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=3))\n",
    "        gp = tf.reduce_mean((slopes - 1.)**2)\n",
    "        return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class op_base:\n",
    "    def __init__(self, sess, project_name):\n",
    "        self.sess = sess\n",
    "\n",
    "        # Train\n",
    "        self.flag = True #args.flag\n",
    "        self.gpu_number = 0 #args.gpu_number\n",
    "        self.project = project_name #\"test_began\" #args.project\n",
    "\n",
    "        # Train Data\n",
    "        self.data_dir = \"./Face_data/Faces_with_expression_label/dataset_64x64_Straight\" #args.data_dir #./Data\n",
    "        self.dataset = \"expr\" #args.dataset  # celeba\n",
    "        self.data_size = 64 #args.data_size  # 64 or 128\n",
    "        self.data_opt = \"crop\" #args.data_opt  # raw or crop\n",
    "        self.data_label_vector_size = 7 #size of one-hot-encoded label vector\n",
    "\n",
    "        # Train Iteration\n",
    "        self.niter = 200 #50 #args.niter\n",
    "        self.niter_snapshot = 500 #args.nsnapshot\n",
    "        self.max_to_keep = 100 #args.max_to_keep models\n",
    "\n",
    "        # Train Parameter\n",
    "        self.batch_size = 16 #args.batch_size\n",
    "        self.learning_rate = 1e-4 #args.learning_rate\n",
    "        self.mm = 0.5 #args.momentum\n",
    "        self.mm2 = 0.999 #args.momentum2\n",
    "        self.lamda = 0.001 #args.lamda\n",
    "        self.gamma = 0.5 #args.gamma\n",
    "        self.filter_number = 64 #args.filter_number\n",
    "        self.input_size = 64 #args.input_size\n",
    "        self.embedding = 128 #64 #args.embedding\n",
    "        \n",
    "        self.lambda_cls = 1.\n",
    "        self.lambda_recon = 10.\n",
    "        self.lambda_gp = 10.\n",
    "\n",
    "        \n",
    "\n",
    "        # Result Dir & File\n",
    "        self.project_dir = 'assets_ae/{0}_{1}_{2}_{3}/'.format(self.project, self.dataset, self.data_opt, self.data_size)\n",
    "        self.ckpt_dir = os.path.join(self.project_dir, 'models')\n",
    "        self.model_name = \"{0}.model\".format(self.project)\n",
    "        self.ckpt_model_name = os.path.join(self.ckpt_dir, self.model_name)\n",
    "\n",
    "        # etc.\n",
    "        if not os.path.exists('assets_ae'):\n",
    "            os.makedirs('assets_ae')\n",
    "        make_project_dir(self.project_dir)\n",
    "\n",
    "    def load(self, sess, saver, ckpt_dir):\n",
    "        ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, os.path.join(ckpt_dir, ckpt_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "class Operator(op_base):\n",
    "    def __init__(self, sess, project_name):\n",
    "        op_base.__init__(self, sess, project_name)\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Input placeholder\n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, self.data_size, self.data_size, 3], name='x')\n",
    "        self.x_c = tf.placeholder(tf.float32, shape=[None, self.data_label_vector_size], name='x_c')\n",
    "        self.target = tf.placeholder(tf.float32, shape=[None, self.data_size, self.data_size, 3], name='target')\n",
    "        self.target_c = tf.placeholder(tf.float32, shape=[None, self.data_label_vector_size], name='target_c')\n",
    "        self.alpha = tf.placeholder(tf.float32, shape=[None, 1], name='alpha')\n",
    "        self.lr = tf.placeholder(tf.float32, name='lr')\n",
    "\n",
    "        # Generator\n",
    "        self.G_f = self.generator(self.x, self.target_c)\n",
    "        self.G_recon = self.generator(self.G_f, self.x_c, reuse=True)\n",
    "        \n",
    "        self.G_test = self.generator(self.x, self.target_c, reuse=True)\n",
    "        \n",
    "        # Discriminator\n",
    "        self.D_f, self.D_f_cls = self.discriminator(self.G_f)\n",
    "        self.D_target, self.D_target_cls = self.discriminator(self.target, reuse=True) # discriminate with the target\n",
    "        #self.D_x, self.D_x_cls = self.discriminator(self.x, reuse=True) # Original implementation, discriminate with the input\n",
    "        \n",
    "        # Gradient Penalty\n",
    "        self.real_data = tf.reshape(self.target, [-1, self.data_size*self.data_size*3]) # interpolate with target\n",
    "        self.fake_data = tf.reshape(self.G_f, [-1, self.data_size*self.data_size*3])\n",
    "        self.diff = self.fake_data - self.real_data\n",
    "        self.interpolate = self.real_data + self.alpha*self.diff\n",
    "        \n",
    "        self.inter_reshape = tf.reshape(self.interpolate, [-1, self.data_size, self.data_size, 3])\n",
    "        self.G_inter, _ = self.discriminator(self.inter_reshape, reuse=True)\n",
    "        \n",
    "        self.grad = tf.gradients(self.G_inter, \n",
    "                                 xs=[self.inter_reshape])[0]\n",
    "        self.slopes = tf.sqrt(tf.reduce_sum(tf.square(self.grad), axis=[1,2,3]))\n",
    "        self.gp = tf.reduce_mean(tf.square(self.slopes - 1.))\n",
    "        \n",
    "        \n",
    "        # Wasserstein loss\n",
    "#         self.wd = tf.reduce_mean(self.D_x) - tf.reduce_mean(self.D_f)\n",
    "        self.wd = tf.reduce_mean(self.D_target) - tf.reduce_mean(self.D_f)\n",
    "        self.L_adv_D = -self.wd + self.gp * self.lambda_gp\n",
    "        self.L_adv_G = -tf.reduce_mean(self.D_f)\n",
    "        \n",
    "        #self.L_D_cls = tf.reduce_mean(cross_entropy(labels=self.x_c, logits=self.D_x_cls))# Original implementation\n",
    "        self.L_D_cls = tf.reduce_mean(cross_entropy(labels=self.target_c, logits=self.D_target_cls))# discriminate with the target\n",
    "        self.L_G_cls = tf.reduce_mean(cross_entropy(labels=self.target_c, logits=self.D_f_cls))\n",
    "        self.L_G_recon = l1_loss(self.x, self.G_recon)\n",
    "                \n",
    "        self.L_D = self.L_adv_D + self.lambda_cls * self.L_D_cls\n",
    "        self.L_G = self.L_adv_G + self.lambda_cls * self.L_G_cls + self.lambda_recon * self.L_G_recon\n",
    "        \n",
    "\n",
    "        # Variables\n",
    "        D_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"discriminator\")\n",
    "        G_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"generator\")\n",
    "\n",
    "        # Optimizer\n",
    "        self.opt_D = tf.train.AdamOptimizer(self.lr, self.mm).minimize(self.L_D, var_list=D_vars)\n",
    "        self.opt_G = tf.train.AdamOptimizer(self.lr, self.mm).minimize(self.L_G, var_list=G_vars)\n",
    "\n",
    "        # initializer\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # tf saver\n",
    "        self.saver = tf.train.Saver(max_to_keep=(self.max_to_keep))\n",
    "\n",
    "        try:\n",
    "            self.load(self.sess, self.saver, self.ckpt_dir)\n",
    "        except:\n",
    "            # save full graph\n",
    "            self.saver.save(self.sess, self.ckpt_model_name, write_meta_graph=True)\n",
    "\n",
    "        # Summary\n",
    "        if self.flag:\n",
    "            tf.summary.scalar('loss/d_loss', self.L_D)\n",
    "            tf.summary.scalar('loss/g_loss', self.L_G)\n",
    "            tf.summary.scalar('loss/d_loss_cls', self.L_D_cls)\n",
    "            tf.summary.scalar('loss/g_loss_recon', self.L_G_recon)\n",
    "            tf.summary.scalar('loss/g_loss_cls', self.L_G_cls)\n",
    "            tf.summary.scalar('loss/wd', self.wd)\n",
    "\n",
    "            self.merged = tf.summary.merge_all()\n",
    "            self.writer = tf.summary.FileWriter(self.project_dir, self.sess.graph)\n",
    "\n",
    "    def train(self, train_flag):\n",
    "        # load data\n",
    "        data_path = self.data_dir\n",
    "        #test_data_path = \"./Face_data/Faces_with_expression_label/dataset_64x64\" # expressions\n",
    "\n",
    "        if os.path.exists(data_path + '.npy'):\n",
    "            data = np.load(data_path + '.npy')\n",
    "        else:\n",
    "            data = sorted(glob.glob(os.path.join(data_path, \"*.*\")))\n",
    "            data = pair_expressions(data)\n",
    "            np.save(data_path + '.npy', data)\n",
    "            \n",
    "        print('Shuffle ....')\n",
    "        random_order = np.random.permutation(len(data))\n",
    "        data = [data[i] for i in random_order[:]]\n",
    "        print('Shuffle Done')\n",
    "\n",
    "        # initial parameter\n",
    "        start_time = time.time()\n",
    "        self.count = 0\n",
    "\n",
    "        for epoch in range(self.niter):\n",
    "            batch_idxs = len(data) // self.batch_size\n",
    "            lr = np.float32(self.learning_rate)\n",
    "            \n",
    "            # learning rate decay\n",
    "            if epoch >= self.niter / 2.0:\n",
    "                lr_decay = (self.niter - epoch) / (self.niter / 2.0)\n",
    "                lr = lr * lr_decay\n",
    "            \n",
    "            for idx in range(0, batch_idxs):\n",
    "                self.count += 1\n",
    "\n",
    "                # Flip the batch with 0.5 prob to increase training data\n",
    "                if random.uniform(0, 1) < 0.5:\n",
    "                    flip = True\n",
    "                else:\n",
    "                    flip = False\n",
    "                \n",
    "                batch_files = data[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "                batch_inputs = [get_image(batch_file[0], flip) for batch_file in batch_files]\n",
    "                batch_target = [get_image(batch_file[1], flip) for batch_file in batch_files]\n",
    "                batch_inputs_labels = [get_label(batch_file[0], self.data_label_vector_size) for batch_file in batch_files]\n",
    "                batch_target_labels = [get_label(batch_file[1], self.data_label_vector_size) for batch_file in batch_files]\n",
    "                batch_alpha = np.random.uniform(low=0., high=1.0, size=[self.batch_size, 1]).astype(np.float32)\n",
    "                                \n",
    "                # feed list \n",
    "                D_fetches = [self.opt_D, self.L_D, self.L_D_cls]\n",
    "                G_fetches = [self.opt_G, self.L_G, self.L_G_cls, self.L_G_recon, self.wd]\n",
    "                feed_dict = {self.x: batch_inputs, self.x_c: batch_inputs_labels, \n",
    "                             self.target: batch_target, self.target_c: batch_target_labels, \n",
    "                             self.alpha: batch_alpha,\n",
    "                             self.lr: lr}\n",
    "                \n",
    "\n",
    "                # run tensorflow\n",
    "                for i in range(5):\n",
    "                    _, d_loss, d_loss_cls = self.sess.run(D_fetches, feed_dict=feed_dict)\n",
    "                    \n",
    "                _, g_loss, g_loss_cls, g_loss_recon, wd = self.sess.run(G_fetches, feed_dict=feed_dict)\n",
    "                  \n",
    "                if self.count % 100 == 1:\n",
    "                    print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, \"\n",
    "                          \"d_loss: %.6f, d_loss_cls: %.6f, g_loss: %.6f, g_loss_cls: %.6f, g_loss_recon: %.6f, \"\n",
    "                          \"wd: %.6f\"\n",
    "                          % (epoch, idx, batch_idxs, time.time() - start_time,\n",
    "                             d_loss, d_loss_cls, g_loss, g_loss_cls, g_loss_recon, wd))\n",
    "\n",
    "                # write train summary\n",
    "                summary = self.sess.run(self.merged, feed_dict=feed_dict)\n",
    "                self.writer.add_summary(summary, self.count)\n",
    "\n",
    "                # Test during Training\n",
    "                if self.count % self.niter_snapshot == (self.niter_snapshot - 1):\n",
    "                    # save & test\n",
    "                    self.saver.save(self.sess, self.ckpt_model_name, global_step=self.count, write_meta_graph=False)\n",
    "                    self.test_expr(train_flag)\n",
    "                    self.test_celebra(train_flag)\n",
    "\n",
    "    def test_celebra(self, train_flag=True):\n",
    "        print('Test Sample Generation...')\n",
    "        # generate output\n",
    "        img_num = 8*8\n",
    "        output_f = int(np.sqrt(img_num))\n",
    "        in_img_num = output_f\n",
    "        img_size = self.data_size\n",
    "        gen_img_num = img_num - output_f\n",
    "        label_size = self.data_label_vector_size\n",
    "        \n",
    "        # load data test\n",
    "        data_path = \"./Face_data/Celeba/dataset_64x64\" # expressions\n",
    "\n",
    "        if os.path.exists(data_path + '.npy'):\n",
    "            data = np.load(data_path + '.npy')\n",
    "        else:\n",
    "            data = sorted(glob.glob(os.path.join(data_path, \"*.*\")))\n",
    "            data = pair_expressions(data)\n",
    "            np.save(data_path + '.npy', data)\n",
    "\n",
    "        # shuffle test data\n",
    "        random_order = np.random.permutation(len(data))\n",
    "        data = [data[i] for i in random_order[:]]\n",
    "\n",
    "        im_output_gen = np.zeros([img_size * output_f, img_size * output_f, 3])\n",
    "\n",
    "        test_files = data[0: output_f]\n",
    "        test_data = [get_image(test_file) for test_file in test_files]\n",
    "        test_data = np.repeat(test_data, [label_size]*in_img_num, axis=0)\n",
    "        test_data_o = [scm.imread(test_file) for test_file in test_files]\n",
    "        \n",
    "        # get one-hot labels\n",
    "        int_labels = list(range(label_size))\n",
    "        one_hot = np.zeros((label_size, label_size))\n",
    "        one_hot[np.arange(label_size), int_labels] = 1\n",
    "        target_labels = np.tile(one_hot, (output_f, 1))\n",
    "        \n",
    "        \n",
    "        output_gen = (self.sess.run(self.G_test, feed_dict={self.x: test_data, \n",
    "                                                            self.target_c: target_labels}))  # generator output\n",
    "\n",
    "        output_gen = [inverse_image(output_gen[i]) for i in range(gen_img_num)]\n",
    "\n",
    "        for i in range(output_f):\n",
    "            for j in range(output_f):\n",
    "                if j == 0:\n",
    "                    im_output_gen[i * img_size:(i + 1) * img_size, j * img_size:(j + 1) * img_size, :] \\\n",
    "                        = test_data_o[i]\n",
    "                else:\n",
    "                    im_output_gen[i * img_size:(i + 1) * img_size, j * img_size:(j + 1) * img_size, :] \\\n",
    "                        = output_gen[(j-1) + (i * int(output_f-1))]\n",
    "\n",
    "        # output save\n",
    "        scm.imsave(self.project_dir + '/result/' + str(self.count) + '_celebra_output.bmp', im_output_gen)\n",
    "        \n",
    "    def test_expr(self, train_flag=True):\n",
    "        print('Train Sample Generation...')\n",
    "        # generate output\n",
    "        img_num =  36 #self.batch_size\n",
    "        display_img_num = int(img_num / 3)\n",
    "        img_size = self.data_size\n",
    "\n",
    "        output_f = int(np.sqrt(img_num))\n",
    "        im_output_gen = np.zeros([img_size * output_f, img_size * output_f, 3])\n",
    "        \n",
    "        # load data\n",
    "        data_path = self.data_dir\n",
    "\n",
    "        if os.path.exists(data_path + '.npy'):\n",
    "            data = np.load(data_path + '.npy')\n",
    "        else:\n",
    "            data = sorted(glob.glob(os.path.join(data_path, \"*.*\")))\n",
    "            data = pair_expressions(data)\n",
    "            np.save(data_path + '.npy', data)\n",
    "\n",
    "        # Test data shuffle\n",
    "        random_order = np.random.permutation(len(data))\n",
    "        data = [data[i] for i in random_order[:]]\n",
    "        \n",
    "        batch_files = data[0: display_img_num]\n",
    "        test_inputs = [get_image(batch_file[0]) for batch_file in batch_files]\n",
    "        test_inputs_o = [scm.imread((batch_file[0])) for batch_file in batch_files]\n",
    "        test_targets = [scm.imread((batch_file[1])) for batch_file in batch_files]\n",
    "        test_target_labels = [get_label(batch_file[1], self.data_label_vector_size) for batch_file in batch_files]\n",
    "\n",
    "        output_gen = (self.sess.run(self.G_test, feed_dict={self.x: test_inputs, \n",
    "                                                            self.target_c: test_target_labels}))  # generator output\n",
    "\n",
    "        output_gen = [inverse_image(output_gen[i]) for i in range(display_img_num)]\n",
    "\n",
    "        for i in range(output_f): # row\n",
    "            for j in range(output_f): # col\n",
    "                if j % 3 == 0: # input img\n",
    "                    im_output_gen[i * img_size:(i + 1) * img_size, j * img_size:(j + 1) * img_size, :] \\\n",
    "                        = test_inputs_o[int(j / 3) + (i * int(output_f / 3))]\n",
    "                elif j % 3 == 1: # output img\n",
    "                    im_output_gen[i * img_size:(i + 1) * img_size, j * img_size:(j + 1) * img_size, :] \\\n",
    "                        = output_gen[int(j / 3) + (i * int(output_f / 3))]\n",
    "                else: # target img\n",
    "                    im_output_gen[i * img_size:(i + 1) * img_size, j * img_size:(j + 1) * img_size, :] \\\n",
    "                        = test_targets[int(j / 3) + (i * int(output_f / 3))]\n",
    "                   \n",
    "\n",
    "        labels = np.argmax(test_target_labels, axis=1)\n",
    "        label_string = ''.join(str(int(l)) for l in labels)\n",
    "        # output save\n",
    "        scm.imsave(self.project_dir + '/result/' + str(self.count) + '_' + label_string \n",
    "                   + '_expr_output.bmp', im_output_gen)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StarGAN(Operator):\n",
    "    def __init__(self, sess, project_name):\n",
    "        Operator.__init__(self, sess, project_name)\n",
    "\n",
    "\n",
    "    def generator(self, x, c, reuse=None):\n",
    "        with tf.variable_scope('generator') as scope:\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "\n",
    "            f = 64\n",
    "            image_size = self.data_size\n",
    "            c_num = self.data_label_vector_size\n",
    "            p = \"SAME\"\n",
    "\n",
    "            x = tf.concat([x, tf.tile(tf.reshape(c, [-1, 1, 1, get_shape_c(c)[-1]]),\\\n",
    "                                      [1, x.get_shape().as_list()[1], x.get_shape().as_list()[2], 1])],\\\n",
    "                          axis=3)\n",
    "            \n",
    "            # Down-sampling\n",
    "            x = conv(x, [7, 7, 3+c_num, f], stride=1, padding=p, name='ds_1')\n",
    "            x = instance_norm(x, 'in_ds_1')\n",
    "            x = tf.nn.relu(x)\n",
    "            x = conv(x, [4, 4, f, f*2], stride=2, padding=p, name='ds_2')\n",
    "            x = instance_norm(x, 'in_ds_2')\n",
    "            x = tf.nn.relu(x)\n",
    "            x = conv(x, [4, 4, f*2, f*4], stride=2, padding=p, name='ds_3')\n",
    "            x = instance_norm(x, 'in_ds_3')\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            # Bottleneck\n",
    "            x_r = conv(x, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_1a')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_1a')\n",
    "            x_r = tf.nn.relu(x_r)\n",
    "            x_r = conv(x_r, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_1b')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_1b')\n",
    "            x = x + x_r\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            x_r = conv(x, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_2a')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_2a')\n",
    "            x_r = tf.nn.relu(x_r)\n",
    "            x_r = conv(x_r, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_2b')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_2b')\n",
    "            x = x + x_r\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            x_r = conv(x, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_3a')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_3a')\n",
    "            x_r = tf.nn.relu(x_r)\n",
    "            x_r = conv(x_r, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_3b')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_3b')\n",
    "            x = x + x_r\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            x_r = conv(x, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_4a')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_4a')\n",
    "            x_r = tf.nn.relu(x_r)\n",
    "            x_r = conv(x_r, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_4b')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_4b')\n",
    "            x = x + x_r\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            x_r = conv(x, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_5a')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_5a')\n",
    "            x_r = tf.nn.relu(x_r)\n",
    "            x_r = conv(x_r, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_5b')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_5b')\n",
    "            x = x + x_r\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            x_r = conv(x, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_6a')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_6a')\n",
    "            x_r = tf.nn.relu(x_r)\n",
    "            x_r = conv(x_r, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_6b')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_6b')\n",
    "            x = x + x_r\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            # Up-sampling\n",
    "            x = deconv(x, [4, 4, f*4, f*2], stride=2, padding=p, name='us_1')\n",
    "            x = instance_norm(x, 'in_us_1')\n",
    "            x = tf.nn.relu(x)\n",
    "            x = deconv(x, [4, 4, f*2, f], stride=2, padding=p, name='us_2')\n",
    "            x = instance_norm(x, 'in_us_2')\n",
    "            x = tf.nn.relu(x)\n",
    "            x = conv(x, [7, 7, f, 3], stride=1, padding=p, name='us_3')\n",
    "\n",
    "            x = tf.nn.tanh(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def discriminator(self, x, reuse=None):\n",
    "        with tf.variable_scope('discriminator') as scope:\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "\n",
    "            f = 64\n",
    "            f_max = f*8\n",
    "            image_size = self.data_size\n",
    "            k_size = int(image_size / np.power(2, 5))            \n",
    "            c_num = self.data_label_vector_size\n",
    "            p = \"SAME\"\n",
    "            \n",
    "            x = conv(x, [4, 4, 3, f], stride=2, padding=p, name='conv_1')\n",
    "            x = lrelu(x)\n",
    "            x = conv(x, [4, 4, f, f*2], stride=2, padding=p, name='conv_2')\n",
    "            x = lrelu(x)\n",
    "            x = conv(x, [4, 4, f*2, f*4], stride=2, padding=p, name='conv_3')\n",
    "            x = lrelu(x)\n",
    "            x = conv(x, [4, 4, f*4, f*8], stride=2, padding=p, name='conv_4')\n",
    "            x = lrelu(x)\n",
    "            x = conv(x, [4, 4, f*8, f*16], stride=2, padding=p, name='conv_5')\n",
    "            x = lrelu(x)\n",
    "            \n",
    "            if image_size == 128:\n",
    "                x = conv(x, [4, 4, f*16, f*32], stride=2, padding=p, name='conv_6')\n",
    "                x = lrelu(x)\n",
    "                f_max = f_max * 2\n",
    "                k_size = int(k_size / 2)\n",
    "                \n",
    "            out_src = conv(x, [3, 3, f_max, 1], stride=1, padding=p, name='conv_out_src')\n",
    "            out_cls = conv(x, [k_size, k_size, f_max, c_num], stride=1, name='conv_out_cls')\n",
    "        \n",
    "        return out_src, tf.squeeze(out_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle ....\n",
      "Shuffle Done\n",
      "Epoch: [ 0] [   0/1778] time: 1.6741, d_loss: 9.391254, d_loss_cls: 0.683294, g_loss: 6.182937, g_loss_cls: 0.683669, g_loss_recon: 0.544825, wd: 0.135955\n",
      "Epoch: [ 0] [ 100/1778] time: 70.7658, d_loss: -4.081106, d_loss_cls: 0.228412, g_loss: 0.385139, g_loss_cls: 0.269065, g_loss_recon: 0.247860, wd: 5.011426\n",
      "Epoch: [ 0] [ 200/1778] time: 142.4872, d_loss: -2.955659, d_loss_cls: 0.187727, g_loss: 5.255723, g_loss_cls: 0.332613, g_loss_recon: 0.200489, wd: 3.660147\n",
      "Epoch: [ 0] [ 300/1778] time: 214.2384, d_loss: -1.453561, d_loss_cls: 0.188989, g_loss: 5.529548, g_loss_cls: 0.369976, g_loss_recon: 0.170174, wd: 1.902555\n",
      "Epoch: [ 0] [ 400/1778] time: 285.9956, d_loss: -2.259196, d_loss_cls: 0.127369, g_loss: 2.527998, g_loss_cls: 0.341005, g_loss_recon: 0.154594, wd: 2.742476\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 0] [ 500/1778] time: 358.4416, d_loss: -1.752238, d_loss_cls: 0.152173, g_loss: 1.206721, g_loss_cls: 0.301913, g_loss_recon: 0.151334, wd: 2.252798\n",
      "Epoch: [ 0] [ 600/1778] time: 430.2542, d_loss: -1.733752, d_loss_cls: 0.112864, g_loss: 0.442332, g_loss_cls: 0.209057, g_loss_recon: 0.138026, wd: 2.071548\n",
      "Epoch: [ 0] [ 700/1778] time: 502.0890, d_loss: -1.896659, d_loss_cls: 0.055608, g_loss: -4.295355, g_loss_cls: 0.135413, g_loss_recon: 0.132387, wd: 2.286142\n",
      "Epoch: [ 0] [ 800/1778] time: 573.8750, d_loss: -1.703791, d_loss_cls: 0.057567, g_loss: 0.241747, g_loss_cls: 0.149537, g_loss_recon: 0.140714, wd: 2.039711\n",
      "Epoch: [ 0] [ 900/1778] time: 645.7299, d_loss: -1.832795, d_loss_cls: 0.039088, g_loss: -0.567531, g_loss_cls: 0.077971, g_loss_recon: 0.131814, wd: 2.087692\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 0] [1000/1778] time: 717.9506, d_loss: -1.480110, d_loss_cls: 0.117505, g_loss: -2.672909, g_loss_cls: 0.067334, g_loss_recon: 0.132335, wd: 1.862848\n",
      "Epoch: [ 0] [1100/1778] time: 789.7757, d_loss: -1.634543, d_loss_cls: 0.033850, g_loss: 1.059363, g_loss_cls: 0.041682, g_loss_recon: 0.125182, wd: 1.920666\n",
      "Epoch: [ 0] [1200/1778] time: 861.6230, d_loss: -1.034896, d_loss_cls: 0.043999, g_loss: -1.794049, g_loss_cls: 0.064535, g_loss_recon: 0.122237, wd: 1.237545\n",
      "Epoch: [ 0] [1300/1778] time: 933.4638, d_loss: -1.202252, d_loss_cls: 0.042348, g_loss: -0.652119, g_loss_cls: 0.038125, g_loss_recon: 0.118994, wd: 1.399889\n",
      "Epoch: [ 0] [1400/1778] time: 1005.2890, d_loss: -1.430176, d_loss_cls: 0.019557, g_loss: 0.315630, g_loss_cls: 0.027218, g_loss_recon: 0.115862, wd: 1.634455\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 0] [1500/1778] time: 1077.5030, d_loss: -1.647315, d_loss_cls: 0.016610, g_loss: -0.942075, g_loss_cls: 0.020666, g_loss_recon: 0.123258, wd: 1.912780\n",
      "Epoch: [ 0] [1600/1778] time: 1149.3234, d_loss: -1.445309, d_loss_cls: 0.018475, g_loss: 0.130094, g_loss_cls: 0.014832, g_loss_recon: 0.111574, wd: 1.613792\n",
      "Epoch: [ 0] [1700/1778] time: 1221.1189, d_loss: -1.251561, d_loss_cls: 0.022797, g_loss: 0.706086, g_loss_cls: 0.030134, g_loss_recon: 0.109406, wd: 1.442562\n",
      "Epoch: [ 1] [  22/1778] time: 1292.9541, d_loss: -1.259045, d_loss_cls: 0.034808, g_loss: 1.140527, g_loss_cls: 0.033262, g_loss_recon: 0.113994, wd: 1.475457\n",
      "Epoch: [ 1] [ 122/1778] time: 1364.7745, d_loss: -1.267122, d_loss_cls: 0.025971, g_loss: 0.247739, g_loss_cls: 0.051795, g_loss_recon: 0.115760, wd: 1.462348\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 1] [ 222/1778] time: 1436.9640, d_loss: -1.317965, d_loss_cls: 0.007954, g_loss: 0.752154, g_loss_cls: 0.015026, g_loss_recon: 0.111028, wd: 1.493186\n",
      "Epoch: [ 1] [ 322/1778] time: 1508.8161, d_loss: -1.129847, d_loss_cls: 0.030430, g_loss: -0.404439, g_loss_cls: 0.013785, g_loss_recon: 0.107334, wd: 1.371176\n",
      "Epoch: [ 1] [ 422/1778] time: 1580.6580, d_loss: -1.280436, d_loss_cls: 0.004992, g_loss: -0.750782, g_loss_cls: 0.007814, g_loss_recon: 0.104349, wd: 1.455318\n",
      "Epoch: [ 1] [ 522/1778] time: 1652.4805, d_loss: -1.113000, d_loss_cls: 0.010033, g_loss: 0.513179, g_loss_cls: 0.055432, g_loss_recon: 0.097668, wd: 1.250561\n",
      "Epoch: [ 1] [ 622/1778] time: 1724.3309, d_loss: -1.014210, d_loss_cls: 0.011958, g_loss: -0.049913, g_loss_cls: 0.016735, g_loss_recon: 0.097000, wd: 1.169755\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 1] [ 722/1778] time: 1796.5455, d_loss: -1.470057, d_loss_cls: 0.011586, g_loss: -1.363939, g_loss_cls: 0.038655, g_loss_recon: 0.139920, wd: 1.810968\n",
      "Epoch: [ 1] [ 822/1778] time: 1868.3953, d_loss: -1.171042, d_loss_cls: 0.011517, g_loss: -0.306813, g_loss_cls: 0.093553, g_loss_recon: 0.109569, wd: 1.367133\n",
      "Epoch: [ 1] [ 922/1778] time: 1940.2438, d_loss: -0.943861, d_loss_cls: 0.017683, g_loss: -0.384514, g_loss_cls: 0.012311, g_loss_recon: 0.090507, wd: 1.083738\n",
      "Epoch: [ 1] [1022/1778] time: 2012.1254, d_loss: -1.041882, d_loss_cls: 0.010129, g_loss: 0.721708, g_loss_cls: 0.026218, g_loss_recon: 0.089962, wd: 1.170367\n",
      "Epoch: [ 1] [1122/1778] time: 2083.9854, d_loss: -1.007258, d_loss_cls: 0.020202, g_loss: -0.305600, g_loss_cls: 0.027484, g_loss_recon: 0.095516, wd: 1.203420\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 1] [1222/1778] time: 2156.2125, d_loss: -0.981762, d_loss_cls: 0.006972, g_loss: 1.281603, g_loss_cls: 0.019728, g_loss_recon: 0.088180, wd: 1.171393\n",
      "Epoch: [ 1] [1322/1778] time: 2228.0403, d_loss: -1.071895, d_loss_cls: 0.007345, g_loss: 0.540771, g_loss_cls: 0.040986, g_loss_recon: 0.103451, wd: 1.258367\n",
      "Epoch: [ 1] [1422/1778] time: 2299.8840, d_loss: -1.163117, d_loss_cls: 0.004899, g_loss: -0.712902, g_loss_cls: 0.019888, g_loss_recon: 0.087135, wd: 1.331406\n",
      "Epoch: [ 1] [1522/1778] time: 2371.7464, d_loss: -1.040446, d_loss_cls: 0.010820, g_loss: -0.731540, g_loss_cls: 0.020271, g_loss_recon: 0.093858, wd: 1.209553\n",
      "Epoch: [ 1] [1622/1778] time: 2443.5853, d_loss: -1.027289, d_loss_cls: 0.005599, g_loss: 0.345631, g_loss_cls: 0.017716, g_loss_recon: 0.105637, wd: 1.198397\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 1] [1722/1778] time: 2515.8084, d_loss: -1.205900, d_loss_cls: 0.004775, g_loss: -0.287362, g_loss_cls: 0.006467, g_loss_recon: 0.094266, wd: 1.399170\n",
      "Epoch: [ 2] [  44/1778] time: 2587.6968, d_loss: -0.907132, d_loss_cls: 0.006247, g_loss: 0.719463, g_loss_cls: 0.025504, g_loss_recon: 0.089662, wd: 1.049418\n",
      "Epoch: [ 2] [ 144/1778] time: 2659.5680, d_loss: -0.766641, d_loss_cls: 0.006988, g_loss: -0.203297, g_loss_cls: 0.043120, g_loss_recon: 0.082983, wd: 0.859228\n",
      "Epoch: [ 2] [ 244/1778] time: 2731.4316, d_loss: -0.894413, d_loss_cls: 0.005642, g_loss: 0.642379, g_loss_cls: 0.003268, g_loss_recon: 0.091014, wd: 1.014699\n",
      "Epoch: [ 2] [ 344/1778] time: 2803.2659, d_loss: -1.046333, d_loss_cls: 0.005729, g_loss: 0.294310, g_loss_cls: 0.034142, g_loss_recon: 0.083743, wd: 1.220133\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 2] [ 444/1778] time: 2875.5702, d_loss: -0.948810, d_loss_cls: 0.005466, g_loss: 0.744521, g_loss_cls: 0.004635, g_loss_recon: 0.093313, wd: 1.119655\n",
      "Epoch: [ 2] [ 544/1778] time: 2947.4237, d_loss: -0.750264, d_loss_cls: 0.006559, g_loss: 1.147287, g_loss_cls: 0.024208, g_loss_recon: 0.080564, wd: 0.876149\n",
      "Epoch: [ 2] [ 644/1778] time: 3019.2838, d_loss: -0.939319, d_loss_cls: 0.002457, g_loss: -0.280460, g_loss_cls: 0.009239, g_loss_recon: 0.087893, wd: 1.095143\n",
      "Epoch: [ 2] [ 744/1778] time: 3091.1314, d_loss: -1.150978, d_loss_cls: 0.006440, g_loss: 0.516095, g_loss_cls: 0.017910, g_loss_recon: 0.083294, wd: 1.344191\n",
      "Epoch: [ 2] [ 844/1778] time: 3162.9682, d_loss: -0.897416, d_loss_cls: 0.002532, g_loss: 0.864273, g_loss_cls: 0.015672, g_loss_recon: 0.085508, wd: 1.030059\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 2] [ 944/1778] time: 3235.2004, d_loss: -1.123242, d_loss_cls: 0.003221, g_loss: 2.781820, g_loss_cls: 0.011721, g_loss_recon: 0.088527, wd: 1.329072\n",
      "Epoch: [ 2] [1044/1778] time: 3307.0144, d_loss: -0.929102, d_loss_cls: 0.002838, g_loss: 0.766875, g_loss_cls: 0.003337, g_loss_recon: 0.081211, wd: 1.078904\n",
      "Epoch: [ 2] [1144/1778] time: 3378.8446, d_loss: -1.104413, d_loss_cls: 0.002201, g_loss: -0.240399, g_loss_cls: 0.006228, g_loss_recon: 0.089675, wd: 1.329840\n",
      "Epoch: [ 2] [1244/1778] time: 3450.6680, d_loss: -0.972418, d_loss_cls: 0.004321, g_loss: 1.421295, g_loss_cls: 0.031643, g_loss_recon: 0.076604, wd: 1.132290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 2] [1344/1778] time: 3522.5249, d_loss: -0.896193, d_loss_cls: 0.002348, g_loss: 0.063820, g_loss_cls: 0.010194, g_loss_recon: 0.076127, wd: 1.028055\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 2] [1444/1778] time: 3594.7753, d_loss: -0.891107, d_loss_cls: 0.002868, g_loss: 0.422091, g_loss_cls: 0.010255, g_loss_recon: 0.078474, wd: 1.024050\n",
      "Epoch: [ 2] [1544/1778] time: 3666.6212, d_loss: -1.018217, d_loss_cls: 0.002157, g_loss: 0.748165, g_loss_cls: 0.003397, g_loss_recon: 0.078091, wd: 1.198222\n",
      "Epoch: [ 2] [1644/1778] time: 3738.4133, d_loss: -0.754762, d_loss_cls: 0.002279, g_loss: 0.771161, g_loss_cls: 0.028896, g_loss_recon: 0.084153, wd: 0.917780\n",
      "Epoch: [ 2] [1744/1778] time: 3810.2490, d_loss: -0.859714, d_loss_cls: 0.008197, g_loss: 1.215457, g_loss_cls: 0.014247, g_loss_recon: 0.082725, wd: 1.005237\n",
      "Epoch: [ 3] [  66/1778] time: 3882.0900, d_loss: -0.837548, d_loss_cls: 0.003504, g_loss: 0.007610, g_loss_cls: 0.001929, g_loss_recon: 0.078483, wd: 0.995155\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 3] [ 166/1778] time: 3954.3130, d_loss: -1.009312, d_loss_cls: 0.003577, g_loss: 0.411644, g_loss_cls: 0.025565, g_loss_recon: 0.083056, wd: 1.183379\n",
      "Epoch: [ 3] [ 266/1778] time: 4026.1850, d_loss: -0.892990, d_loss_cls: 0.001414, g_loss: 0.450203, g_loss_cls: 0.011543, g_loss_recon: 0.078039, wd: 1.060373\n",
      "Epoch: [ 3] [ 366/1778] time: 4098.0339, d_loss: -0.874860, d_loss_cls: 0.003360, g_loss: 1.476876, g_loss_cls: 0.006864, g_loss_recon: 0.081459, wd: 1.019426\n",
      "Epoch: [ 3] [ 466/1778] time: 4169.8759, d_loss: -0.800534, d_loss_cls: 0.003078, g_loss: 0.830183, g_loss_cls: 0.003551, g_loss_recon: 0.077594, wd: 0.942611\n",
      "Epoch: [ 3] [ 566/1778] time: 4241.7450, d_loss: -0.779106, d_loss_cls: 0.001455, g_loss: 0.282433, g_loss_cls: 0.031147, g_loss_recon: 0.079002, wd: 0.915452\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 3] [ 666/1778] time: 4313.9592, d_loss: -0.849068, d_loss_cls: 0.002062, g_loss: 0.662844, g_loss_cls: 0.002525, g_loss_recon: 0.077432, wd: 0.986988\n",
      "Epoch: [ 3] [ 766/1778] time: 4385.8004, d_loss: -1.078876, d_loss_cls: 0.001662, g_loss: -0.041645, g_loss_cls: 0.003927, g_loss_recon: 0.090350, wd: 1.347568\n",
      "Epoch: [ 3] [ 866/1778] time: 4457.6359, d_loss: -0.756126, d_loss_cls: 0.002677, g_loss: -0.641780, g_loss_cls: 0.021259, g_loss_recon: 0.082020, wd: 0.896913\n",
      "Epoch: [ 3] [ 966/1778] time: 4529.4686, d_loss: -0.915064, d_loss_cls: 0.002747, g_loss: 0.345147, g_loss_cls: 0.013643, g_loss_recon: 0.078448, wd: 1.107688\n",
      "Epoch: [ 3] [1066/1778] time: 4601.3196, d_loss: -0.797806, d_loss_cls: 0.001196, g_loss: 1.016029, g_loss_cls: 0.016723, g_loss_recon: 0.078845, wd: 0.933311\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 3] [1166/1778] time: 4673.5436, d_loss: -1.120507, d_loss_cls: 0.004007, g_loss: 0.675339, g_loss_cls: 0.016198, g_loss_recon: 0.078795, wd: 1.327773\n",
      "Epoch: [ 3] [1266/1778] time: 4745.3721, d_loss: -0.654844, d_loss_cls: 0.001998, g_loss: 1.826441, g_loss_cls: 0.004879, g_loss_recon: 0.074113, wd: 0.777935\n",
      "Epoch: [ 3] [1366/1778] time: 4817.2441, d_loss: -0.838736, d_loss_cls: 0.003580, g_loss: 1.257357, g_loss_cls: 0.031535, g_loss_recon: 0.075987, wd: 0.995772\n",
      "Epoch: [ 3] [1466/1778] time: 4889.0812, d_loss: -0.858424, d_loss_cls: 0.000813, g_loss: -0.293722, g_loss_cls: 0.000529, g_loss_recon: 0.076992, wd: 0.997198\n",
      "Epoch: [ 3] [1566/1778] time: 4960.9388, d_loss: -0.711108, d_loss_cls: 0.004149, g_loss: 0.824255, g_loss_cls: 0.001355, g_loss_recon: 0.080344, wd: 0.848519\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 3] [1666/1778] time: 5033.1943, d_loss: -0.824804, d_loss_cls: 0.001729, g_loss: 2.132074, g_loss_cls: 0.001487, g_loss_recon: 0.078918, wd: 1.004198\n",
      "Epoch: [ 3] [1766/1778] time: 5105.0421, d_loss: -0.873311, d_loss_cls: 0.002601, g_loss: -0.326155, g_loss_cls: 0.009049, g_loss_recon: 0.076095, wd: 1.032833\n",
      "Epoch: [ 4] [  88/1778] time: 5176.8603, d_loss: -0.829422, d_loss_cls: 0.000790, g_loss: 1.433503, g_loss_cls: 0.000849, g_loss_recon: 0.074058, wd: 0.984375\n",
      "Epoch: [ 4] [ 188/1778] time: 5248.7234, d_loss: -0.815963, d_loss_cls: 0.001810, g_loss: 0.446000, g_loss_cls: 0.000911, g_loss_recon: 0.079728, wd: 0.934409\n",
      "Epoch: [ 4] [ 288/1778] time: 5320.5989, d_loss: -0.673818, d_loss_cls: 0.002771, g_loss: 1.197926, g_loss_cls: 0.018279, g_loss_recon: 0.075107, wd: 0.807796\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 4] [ 388/1778] time: 5392.8581, d_loss: -0.703279, d_loss_cls: 0.000954, g_loss: 1.029535, g_loss_cls: 0.012490, g_loss_recon: 0.072245, wd: 0.841875\n",
      "Epoch: [ 4] [ 488/1778] time: 5464.7063, d_loss: -0.723297, d_loss_cls: 0.002656, g_loss: 1.662702, g_loss_cls: 0.021657, g_loss_recon: 0.075170, wd: 0.855257\n",
      "Epoch: [ 4] [ 588/1778] time: 5536.5402, d_loss: -0.803464, d_loss_cls: 0.004324, g_loss: -0.126634, g_loss_cls: 0.074521, g_loss_recon: 0.073294, wd: 0.939155\n",
      "Epoch: [ 4] [ 688/1778] time: 5608.3801, d_loss: -0.893199, d_loss_cls: 0.001347, g_loss: 2.335387, g_loss_cls: 0.036731, g_loss_recon: 0.072061, wd: 1.053435\n",
      "Epoch: [ 4] [ 788/1778] time: 5680.2165, d_loss: -0.704201, d_loss_cls: 0.003415, g_loss: 0.567878, g_loss_cls: 0.004440, g_loss_recon: 0.078427, wd: 0.846988\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 4] [ 888/1778] time: 5752.4335, d_loss: -0.705355, d_loss_cls: 0.000404, g_loss: 1.102861, g_loss_cls: 0.026790, g_loss_recon: 0.076790, wd: 0.883605\n",
      "Epoch: [ 4] [ 988/1778] time: 5824.2161, d_loss: -0.808972, d_loss_cls: 0.001579, g_loss: 0.274970, g_loss_cls: 0.036256, g_loss_recon: 0.074674, wd: 0.980715\n",
      "Epoch: [ 4] [1088/1778] time: 5896.0014, d_loss: -0.854051, d_loss_cls: 0.002755, g_loss: 1.146006, g_loss_cls: 0.005487, g_loss_recon: 0.080964, wd: 1.056477\n",
      "Epoch: [ 4] [1188/1778] time: 5967.8237, d_loss: -0.956789, d_loss_cls: 0.003127, g_loss: 0.727615, g_loss_cls: 0.162469, g_loss_recon: 0.071170, wd: 1.206946\n",
      "Epoch: [ 4] [1288/1778] time: 6039.6759, d_loss: -0.774520, d_loss_cls: 0.002091, g_loss: 1.075145, g_loss_cls: 0.005195, g_loss_recon: 0.070231, wd: 0.934298\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 4] [1388/1778] time: 6111.9070, d_loss: -0.615680, d_loss_cls: 0.001684, g_loss: 1.560167, g_loss_cls: 0.015572, g_loss_recon: 0.070926, wd: 0.791967\n",
      "Epoch: [ 4] [1488/1778] time: 6183.7677, d_loss: -0.841626, d_loss_cls: 0.002043, g_loss: 2.368485, g_loss_cls: 0.075825, g_loss_recon: 0.090301, wd: 1.017122\n",
      "Epoch: [ 4] [1588/1778] time: 6255.6324, d_loss: -0.967529, d_loss_cls: 0.001070, g_loss: 1.598170, g_loss_cls: 0.001845, g_loss_recon: 0.072785, wd: 1.170488\n",
      "Epoch: [ 4] [1688/1778] time: 6327.4777, d_loss: -0.738863, d_loss_cls: 0.000362, g_loss: 0.794495, g_loss_cls: 0.003895, g_loss_recon: 0.067763, wd: 0.880917\n",
      "Epoch: [ 5] [  10/1778] time: 6399.2904, d_loss: -0.749271, d_loss_cls: 0.003204, g_loss: 1.055256, g_loss_cls: 0.003931, g_loss_recon: 0.071594, wd: 0.881165\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 5] [ 110/1778] time: 6471.5056, d_loss: -0.717373, d_loss_cls: 0.000989, g_loss: 1.402794, g_loss_cls: 0.003051, g_loss_recon: 0.081469, wd: 0.943392\n",
      "Epoch: [ 5] [ 210/1778] time: 6543.3761, d_loss: -0.670196, d_loss_cls: 0.001039, g_loss: 1.055919, g_loss_cls: 0.017315, g_loss_recon: 0.069650, wd: 0.817810\n",
      "Epoch: [ 5] [ 310/1778] time: 6615.2001, d_loss: -0.653968, d_loss_cls: 0.001105, g_loss: 0.465678, g_loss_cls: 0.004454, g_loss_recon: 0.069563, wd: 0.815702\n",
      "Epoch: [ 5] [ 410/1778] time: 6687.0239, d_loss: -0.643838, d_loss_cls: 0.001403, g_loss: -0.426071, g_loss_cls: 0.073429, g_loss_recon: 0.074515, wd: 0.807810\n",
      "Epoch: [ 5] [ 510/1778] time: 6758.8034, d_loss: -0.642448, d_loss_cls: 0.003558, g_loss: 1.049277, g_loss_cls: 0.002904, g_loss_recon: 0.071646, wd: 0.793876\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 5] [ 610/1778] time: 6831.0285, d_loss: -0.831643, d_loss_cls: 0.000798, g_loss: 0.549519, g_loss_cls: 0.005759, g_loss_recon: 0.069615, wd: 1.046409\n",
      "Epoch: [ 5] [ 710/1778] time: 6902.8646, d_loss: -0.740078, d_loss_cls: 0.001596, g_loss: 0.056106, g_loss_cls: 0.011008, g_loss_recon: 0.068549, wd: 0.874698\n",
      "Epoch: [ 5] [ 810/1778] time: 6974.6793, d_loss: -0.695387, d_loss_cls: 0.001526, g_loss: 0.626040, g_loss_cls: 0.008731, g_loss_recon: 0.068546, wd: 0.843447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 5] [ 910/1778] time: 7046.5110, d_loss: -0.672366, d_loss_cls: 0.000961, g_loss: 1.012215, g_loss_cls: 0.000969, g_loss_recon: 0.069593, wd: 0.828980\n",
      "Epoch: [ 5] [1010/1778] time: 7118.3397, d_loss: -0.740642, d_loss_cls: 0.001502, g_loss: 1.408847, g_loss_cls: 0.004213, g_loss_recon: 0.073163, wd: 0.898486\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 5] [1110/1778] time: 7190.5976, d_loss: -0.801279, d_loss_cls: 0.001318, g_loss: 0.134795, g_loss_cls: 0.021800, g_loss_recon: 0.067588, wd: 0.994817\n",
      "Epoch: [ 5] [1210/1778] time: 7262.4298, d_loss: -0.723914, d_loss_cls: 0.000827, g_loss: 1.543848, g_loss_cls: 0.008371, g_loss_recon: 0.072492, wd: 0.882401\n",
      "Epoch: [ 5] [1310/1778] time: 7334.2338, d_loss: -0.509596, d_loss_cls: 0.000985, g_loss: -0.771251, g_loss_cls: 0.002650, g_loss_recon: 0.066825, wd: 0.633771\n",
      "Epoch: [ 5] [1410/1778] time: 7406.0367, d_loss: -0.975147, d_loss_cls: 0.002253, g_loss: 0.638698, g_loss_cls: 0.027738, g_loss_recon: 0.075870, wd: 1.181667\n",
      "Epoch: [ 5] [1510/1778] time: 7477.8645, d_loss: -0.825999, d_loss_cls: 0.001567, g_loss: -0.130910, g_loss_cls: 0.010868, g_loss_recon: 0.066579, wd: 0.979952\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 5] [1610/1778] time: 7550.0208, d_loss: -0.646644, d_loss_cls: 0.001854, g_loss: 0.386913, g_loss_cls: 0.011120, g_loss_recon: 0.068110, wd: 0.806482\n",
      "Epoch: [ 5] [1710/1778] time: 7621.9110, d_loss: -0.643271, d_loss_cls: 0.002539, g_loss: 0.336366, g_loss_cls: 0.036976, g_loss_recon: 0.066589, wd: 0.768896\n",
      "Epoch: [ 6] [  32/1778] time: 7693.7625, d_loss: -0.857615, d_loss_cls: 0.001036, g_loss: 0.525772, g_loss_cls: 0.006917, g_loss_recon: 0.071552, wd: 1.044929\n",
      "Epoch: [ 6] [ 132/1778] time: 7765.5948, d_loss: -0.661646, d_loss_cls: 0.001077, g_loss: 2.131115, g_loss_cls: 0.000130, g_loss_recon: 0.070121, wd: 0.815086\n",
      "Epoch: [ 6] [ 232/1778] time: 7837.4349, d_loss: -0.802160, d_loss_cls: 0.001466, g_loss: 0.374447, g_loss_cls: 0.002880, g_loss_recon: 0.073038, wd: 1.002337\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 6] [ 332/1778] time: 7909.6622, d_loss: -0.970671, d_loss_cls: 0.002341, g_loss: 0.120504, g_loss_cls: 0.000950, g_loss_recon: 0.070313, wd: 1.167398\n",
      "Epoch: [ 6] [ 432/1778] time: 7981.5163, d_loss: -0.924975, d_loss_cls: 0.000590, g_loss: -0.636188, g_loss_cls: 0.005302, g_loss_recon: 0.070160, wd: 1.098712\n",
      "Epoch: [ 6] [ 532/1778] time: 8053.2972, d_loss: -1.109562, d_loss_cls: 0.001041, g_loss: 1.114254, g_loss_cls: 0.003891, g_loss_recon: 0.073011, wd: 1.341799\n",
      "Epoch: [ 6] [ 632/1778] time: 8125.1201, d_loss: -0.600098, d_loss_cls: 0.003333, g_loss: 0.083833, g_loss_cls: 0.003331, g_loss_recon: 0.069273, wd: 0.757655\n",
      "Epoch: [ 6] [ 732/1778] time: 8196.9440, d_loss: -0.832146, d_loss_cls: 0.001116, g_loss: 0.694887, g_loss_cls: 0.010095, g_loss_recon: 0.073095, wd: 1.036154\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 6] [ 832/1778] time: 8269.1551, d_loss: -0.726624, d_loss_cls: 0.000794, g_loss: -0.489558, g_loss_cls: 0.013042, g_loss_recon: 0.071808, wd: 0.906791\n",
      "Epoch: [ 6] [ 932/1778] time: 8340.9251, d_loss: -0.526911, d_loss_cls: 0.002020, g_loss: -0.281051, g_loss_cls: 0.008913, g_loss_recon: 0.078697, wd: 0.696578\n",
      "Epoch: [ 6] [1032/1778] time: 8412.7772, d_loss: -0.735928, d_loss_cls: 0.000973, g_loss: 0.682052, g_loss_cls: 0.016698, g_loss_recon: 0.066637, wd: 0.908420\n",
      "Epoch: [ 6] [1132/1778] time: 8484.6409, d_loss: -0.654418, d_loss_cls: 0.001478, g_loss: 0.800116, g_loss_cls: 0.000422, g_loss_recon: 0.069174, wd: 0.818171\n",
      "Epoch: [ 6] [1232/1778] time: 8556.4838, d_loss: -0.707996, d_loss_cls: 0.001139, g_loss: 2.306144, g_loss_cls: 0.021587, g_loss_recon: 0.069230, wd: 0.880953\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 6] [1332/1778] time: 8628.6554, d_loss: -0.838754, d_loss_cls: 0.001875, g_loss: -0.041875, g_loss_cls: 0.001655, g_loss_recon: 0.071362, wd: 1.024605\n",
      "Epoch: [ 6] [1432/1778] time: 8700.4911, d_loss: -0.829556, d_loss_cls: 0.000604, g_loss: 1.247452, g_loss_cls: 0.000301, g_loss_recon: 0.069310, wd: 1.004915\n",
      "Epoch: [ 6] [1532/1778] time: 8772.3545, d_loss: -0.597193, d_loss_cls: 0.000719, g_loss: 0.569814, g_loss_cls: 0.004168, g_loss_recon: 0.067964, wd: 0.762043\n",
      "Epoch: [ 6] [1632/1778] time: 8844.1619, d_loss: -0.770249, d_loss_cls: 0.000596, g_loss: -0.494930, g_loss_cls: 0.002169, g_loss_recon: 0.072366, wd: 0.941943\n",
      "Epoch: [ 6] [1732/1778] time: 8915.9708, d_loss: -0.759921, d_loss_cls: 0.001764, g_loss: 0.907523, g_loss_cls: 0.032820, g_loss_recon: 0.065745, wd: 0.923762\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 7] [  54/1778] time: 8988.1717, d_loss: -0.896635, d_loss_cls: 0.000885, g_loss: 2.154349, g_loss_cls: 0.044995, g_loss_recon: 0.071127, wd: 1.090919\n",
      "Epoch: [ 7] [ 154/1778] time: 9059.9736, d_loss: -0.802088, d_loss_cls: 0.001689, g_loss: -0.371055, g_loss_cls: 0.025686, g_loss_recon: 0.066955, wd: 0.988864\n",
      "Epoch: [ 7] [ 254/1778] time: 9131.8369, d_loss: -0.659771, d_loss_cls: 0.000580, g_loss: 1.020245, g_loss_cls: 0.003449, g_loss_recon: 0.068719, wd: 0.813971\n",
      "Epoch: [ 7] [ 354/1778] time: 9203.6634, d_loss: -0.875663, d_loss_cls: 0.001735, g_loss: 1.829398, g_loss_cls: 0.001904, g_loss_recon: 0.066117, wd: 1.051098\n",
      "Epoch: [ 7] [ 454/1778] time: 9275.4464, d_loss: -0.773067, d_loss_cls: 0.001188, g_loss: 2.341183, g_loss_cls: 0.029606, g_loss_recon: 0.064988, wd: 0.948524\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 7] [ 554/1778] time: 9347.6881, d_loss: -0.717446, d_loss_cls: 0.000537, g_loss: 0.956755, g_loss_cls: 0.008992, g_loss_recon: 0.065296, wd: 0.869730\n",
      "Epoch: [ 7] [ 654/1778] time: 9419.5334, d_loss: -0.940698, d_loss_cls: 0.001157, g_loss: -0.813784, g_loss_cls: 0.008167, g_loss_recon: 0.068797, wd: 1.189983\n",
      "Epoch: [ 7] [ 754/1778] time: 9491.3444, d_loss: -0.587395, d_loss_cls: 0.001047, g_loss: 1.928785, g_loss_cls: 0.004855, g_loss_recon: 0.062531, wd: 0.739823\n",
      "Epoch: [ 7] [ 854/1778] time: 9563.2037, d_loss: -0.833130, d_loss_cls: 0.000626, g_loss: 0.146099, g_loss_cls: 0.003810, g_loss_recon: 0.066243, wd: 1.018676\n",
      "Epoch: [ 7] [ 954/1778] time: 9635.0076, d_loss: -0.497199, d_loss_cls: 0.000199, g_loss: 1.019211, g_loss_cls: 0.009570, g_loss_recon: 0.066773, wd: 0.663999\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 7] [1054/1778] time: 9707.1915, d_loss: -0.726514, d_loss_cls: 0.000442, g_loss: 2.170078, g_loss_cls: 0.002707, g_loss_recon: 0.064050, wd: 0.902229\n",
      "Epoch: [ 7] [1154/1778] time: 9779.0350, d_loss: -0.693923, d_loss_cls: 0.001296, g_loss: 0.941621, g_loss_cls: 0.004615, g_loss_recon: 0.068874, wd: 0.862562\n",
      "Epoch: [ 7] [1254/1778] time: 9850.8147, d_loss: -0.772421, d_loss_cls: 0.000774, g_loss: 1.362201, g_loss_cls: 0.001733, g_loss_recon: 0.065295, wd: 0.960418\n",
      "Epoch: [ 7] [1354/1778] time: 9922.6415, d_loss: -0.588114, d_loss_cls: 0.000926, g_loss: 1.280044, g_loss_cls: 0.004864, g_loss_recon: 0.066666, wd: 0.721506\n",
      "Epoch: [ 7] [1454/1778] time: 9994.4175, d_loss: -0.738378, d_loss_cls: 0.001074, g_loss: 1.604242, g_loss_cls: 0.040942, g_loss_recon: 0.064708, wd: 0.918823\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 7] [1554/1778] time: 10066.6044, d_loss: -0.949237, d_loss_cls: 0.001270, g_loss: 1.581388, g_loss_cls: 0.166235, g_loss_recon: 0.068699, wd: 1.165179\n",
      "Epoch: [ 7] [1654/1778] time: 10138.4220, d_loss: -0.817372, d_loss_cls: 0.001490, g_loss: 0.575299, g_loss_cls: 0.065718, g_loss_recon: 0.070458, wd: 1.003062\n",
      "Epoch: [ 7] [1754/1778] time: 10210.2103, d_loss: -0.830407, d_loss_cls: 0.001422, g_loss: 0.751011, g_loss_cls: 0.000441, g_loss_recon: 0.068345, wd: 1.003689\n",
      "Epoch: [ 8] [  76/1778] time: 10282.0356, d_loss: -0.633354, d_loss_cls: 0.000812, g_loss: 2.651603, g_loss_cls: 0.013091, g_loss_recon: 0.065193, wd: 0.781785\n",
      "Epoch: [ 8] [ 176/1778] time: 10353.8596, d_loss: -0.911035, d_loss_cls: 0.001570, g_loss: 0.547658, g_loss_cls: 0.006441, g_loss_recon: 0.067911, wd: 1.143477\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 8] [ 276/1778] time: 10426.0744, d_loss: -0.711043, d_loss_cls: 0.000909, g_loss: 2.851777, g_loss_cls: 0.003977, g_loss_recon: 0.066415, wd: 0.871431\n",
      "Epoch: [ 8] [ 376/1778] time: 10497.9081, d_loss: -0.854740, d_loss_cls: 0.001579, g_loss: 1.043528, g_loss_cls: 0.010885, g_loss_recon: 0.065076, wd: 1.057347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 8] [ 476/1778] time: 10569.7655, d_loss: -0.769375, d_loss_cls: 0.000409, g_loss: 0.632888, g_loss_cls: 0.002487, g_loss_recon: 0.064001, wd: 0.954658\n",
      "Epoch: [ 8] [ 576/1778] time: 10641.6522, d_loss: -0.869359, d_loss_cls: 0.003417, g_loss: 1.263522, g_loss_cls: 0.087222, g_loss_recon: 0.064996, wd: 1.089881\n",
      "Epoch: [ 8] [ 676/1778] time: 10713.4841, d_loss: -0.855198, d_loss_cls: 0.000906, g_loss: 0.024765, g_loss_cls: 0.007056, g_loss_recon: 0.069192, wd: 1.028799\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 8] [ 776/1778] time: 10785.7172, d_loss: -0.796643, d_loss_cls: 0.001143, g_loss: 0.691757, g_loss_cls: 0.004298, g_loss_recon: 0.058946, wd: 0.974075\n",
      "Epoch: [ 8] [ 876/1778] time: 10857.5107, d_loss: -0.691647, d_loss_cls: 0.000796, g_loss: -0.183507, g_loss_cls: 0.014310, g_loss_recon: 0.067018, wd: 0.870712\n",
      "Epoch: [ 8] [ 976/1778] time: 10929.3331, d_loss: -0.627907, d_loss_cls: 0.002014, g_loss: 0.006751, g_loss_cls: 0.006099, g_loss_recon: 0.067099, wd: 0.818265\n",
      "Epoch: [ 8] [1076/1778] time: 11001.1427, d_loss: -0.729155, d_loss_cls: 0.001039, g_loss: 2.181831, g_loss_cls: 0.000300, g_loss_recon: 0.074095, wd: 0.927286\n",
      "Epoch: [ 8] [1176/1778] time: 11072.9544, d_loss: -0.771523, d_loss_cls: 0.000640, g_loss: 0.572818, g_loss_cls: 0.000371, g_loss_recon: 0.066854, wd: 0.936221\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 8] [1276/1778] time: 11145.1935, d_loss: -0.739016, d_loss_cls: 0.000576, g_loss: 0.523152, g_loss_cls: 0.001109, g_loss_recon: 0.065971, wd: 0.932802\n",
      "Epoch: [ 8] [1376/1778] time: 11217.0469, d_loss: -0.745164, d_loss_cls: 0.001026, g_loss: 1.353990, g_loss_cls: 0.001506, g_loss_recon: 0.062641, wd: 0.931981\n",
      "Epoch: [ 8] [1476/1778] time: 11288.8542, d_loss: -0.467324, d_loss_cls: 0.000709, g_loss: 1.806117, g_loss_cls: 0.004865, g_loss_recon: 0.063491, wd: 0.616973\n",
      "Epoch: [ 8] [1576/1778] time: 11360.6665, d_loss: -0.557359, d_loss_cls: 0.001543, g_loss: -0.125530, g_loss_cls: 0.005880, g_loss_recon: 0.064407, wd: 0.726756\n",
      "Epoch: [ 8] [1676/1778] time: 11432.5088, d_loss: -0.572663, d_loss_cls: 0.003366, g_loss: 1.812122, g_loss_cls: 0.004588, g_loss_recon: 0.061163, wd: 0.704074\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 8] [1776/1778] time: 11504.7084, d_loss: -0.893457, d_loss_cls: 0.000983, g_loss: -0.017244, g_loss_cls: 0.035846, g_loss_recon: 0.068011, wd: 1.118808\n",
      "Epoch: [ 9] [  98/1778] time: 11576.5319, d_loss: -0.822944, d_loss_cls: 0.000629, g_loss: 2.468427, g_loss_cls: 0.000339, g_loss_recon: 0.065730, wd: 1.007203\n",
      "Epoch: [ 9] [ 198/1778] time: 11648.3474, d_loss: -0.559910, d_loss_cls: 0.000612, g_loss: -0.358694, g_loss_cls: 0.023812, g_loss_recon: 0.061379, wd: 0.701035\n",
      "Epoch: [ 9] [ 298/1778] time: 11720.1945, d_loss: -0.572448, d_loss_cls: 0.000910, g_loss: 1.813930, g_loss_cls: 0.001168, g_loss_recon: 0.064739, wd: 0.735809\n",
      "Epoch: [ 9] [ 398/1778] time: 11791.9906, d_loss: -0.808074, d_loss_cls: 0.000411, g_loss: -0.000769, g_loss_cls: 0.001741, g_loss_recon: 0.066926, wd: 1.003406\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 9] [ 498/1778] time: 11864.2381, d_loss: -1.025039, d_loss_cls: 0.000583, g_loss: 1.369007, g_loss_cls: 0.025180, g_loss_recon: 0.058724, wd: 1.266518\n",
      "Epoch: [ 9] [ 598/1778] time: 11936.0465, d_loss: -0.864798, d_loss_cls: 0.002106, g_loss: 2.939939, g_loss_cls: 0.005855, g_loss_recon: 0.069155, wd: 1.086275\n",
      "Epoch: [ 9] [ 698/1778] time: 12007.8809, d_loss: -0.681853, d_loss_cls: 0.000766, g_loss: 0.248186, g_loss_cls: 0.036522, g_loss_recon: 0.059540, wd: 0.838045\n",
      "Epoch: [ 9] [ 798/1778] time: 12079.7023, d_loss: -0.825934, d_loss_cls: 0.000976, g_loss: 0.939424, g_loss_cls: 0.015055, g_loss_recon: 0.060935, wd: 1.025563\n",
      "Epoch: [ 9] [ 898/1778] time: 12151.5068, d_loss: -0.894088, d_loss_cls: 0.001224, g_loss: 2.066156, g_loss_cls: 0.001602, g_loss_recon: 0.060426, wd: 1.083990\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 9] [ 998/1778] time: 12223.7015, d_loss: -0.716215, d_loss_cls: 0.000751, g_loss: -1.533853, g_loss_cls: 0.062877, g_loss_recon: 0.064594, wd: 0.942039\n",
      "Epoch: [ 9] [1098/1778] time: 12295.5027, d_loss: -0.578897, d_loss_cls: 0.002901, g_loss: -0.271718, g_loss_cls: 0.027916, g_loss_recon: 0.061020, wd: 0.742156\n",
      "Epoch: [ 9] [1198/1778] time: 12367.3189, d_loss: -0.752533, d_loss_cls: 0.000586, g_loss: 0.657371, g_loss_cls: 0.000848, g_loss_recon: 0.061464, wd: 0.921472\n",
      "Epoch: [ 9] [1298/1778] time: 12439.1075, d_loss: -1.043475, d_loss_cls: 0.000987, g_loss: 1.317615, g_loss_cls: 0.015222, g_loss_recon: 0.060452, wd: 1.268080\n",
      "Epoch: [ 9] [1398/1778] time: 12510.9393, d_loss: -0.658710, d_loss_cls: 0.000406, g_loss: 1.715412, g_loss_cls: 0.000450, g_loss_recon: 0.061846, wd: 0.834382\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 9] [1498/1778] time: 12583.1889, d_loss: -0.668165, d_loss_cls: 0.000779, g_loss: 1.111784, g_loss_cls: 0.002231, g_loss_recon: 0.064485, wd: 0.831078\n",
      "Epoch: [ 9] [1598/1778] time: 12654.9970, d_loss: -0.898456, d_loss_cls: 0.001290, g_loss: 1.299894, g_loss_cls: 0.001068, g_loss_recon: 0.062874, wd: 1.183456\n",
      "Epoch: [ 9] [1698/1778] time: 12726.8322, d_loss: -0.734796, d_loss_cls: 0.001127, g_loss: -0.116617, g_loss_cls: 0.003270, g_loss_recon: 0.062881, wd: 0.927965\n",
      "Epoch: [10] [  20/1778] time: 12798.6471, d_loss: -0.749549, d_loss_cls: 0.000506, g_loss: 0.760682, g_loss_cls: 0.029140, g_loss_recon: 0.068542, wd: 0.958482\n",
      "Epoch: [10] [ 120/1778] time: 12870.4395, d_loss: -0.716118, d_loss_cls: 0.000771, g_loss: -1.983853, g_loss_cls: 0.003126, g_loss_recon: 0.063065, wd: 0.920552\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [10] [ 220/1778] time: 12942.6762, d_loss: -0.697355, d_loss_cls: 0.001577, g_loss: 2.035781, g_loss_cls: 0.001560, g_loss_recon: 0.068099, wd: 0.884952\n",
      "Epoch: [10] [ 320/1778] time: 13014.5263, d_loss: -1.038318, d_loss_cls: 0.000388, g_loss: 1.115027, g_loss_cls: 0.000522, g_loss_recon: 0.063280, wd: 1.311761\n",
      "Epoch: [10] [ 420/1778] time: 13086.3367, d_loss: -0.936461, d_loss_cls: 0.000821, g_loss: 2.343093, g_loss_cls: 0.000482, g_loss_recon: 0.066931, wd: 1.139497\n",
      "Epoch: [10] [ 520/1778] time: 13158.1419, d_loss: -0.835266, d_loss_cls: 0.000395, g_loss: 0.773921, g_loss_cls: 0.002189, g_loss_recon: 0.066966, wd: 1.003430\n",
      "Epoch: [10] [ 620/1778] time: 13229.8940, d_loss: -0.828255, d_loss_cls: 0.000632, g_loss: 1.680297, g_loss_cls: 0.008209, g_loss_recon: 0.063287, wd: 1.012632\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [10] [ 720/1778] time: 13302.1161, d_loss: -0.992732, d_loss_cls: 0.001750, g_loss: 1.598571, g_loss_cls: 0.000426, g_loss_recon: 0.063453, wd: 1.229884\n",
      "Epoch: [10] [ 820/1778] time: 13373.9242, d_loss: -0.871791, d_loss_cls: 0.000584, g_loss: 1.559459, g_loss_cls: 0.002747, g_loss_recon: 0.068825, wd: 1.044391\n",
      "Epoch: [10] [ 920/1778] time: 13445.7535, d_loss: -0.660069, d_loss_cls: 0.001378, g_loss: -1.172353, g_loss_cls: 0.002705, g_loss_recon: 0.067559, wd: 0.838850\n",
      "Epoch: [10] [1020/1778] time: 13517.5781, d_loss: -0.666902, d_loss_cls: 0.001178, g_loss: 0.390381, g_loss_cls: 0.036578, g_loss_recon: 0.061506, wd: 0.867889\n",
      "Epoch: [10] [1120/1778] time: 13589.3899, d_loss: -0.610761, d_loss_cls: 0.000608, g_loss: 1.267514, g_loss_cls: 0.006549, g_loss_recon: 0.065476, wd: 0.792859\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [10] [1220/1778] time: 13661.5788, d_loss: -0.534919, d_loss_cls: 0.002124, g_loss: 2.139848, g_loss_cls: 0.011315, g_loss_recon: 0.067885, wd: 0.719734\n",
      "Epoch: [10] [1320/1778] time: 13733.4454, d_loss: -0.784823, d_loss_cls: 0.000511, g_loss: 1.063859, g_loss_cls: 0.001039, g_loss_recon: 0.064209, wd: 0.964688\n",
      "Epoch: [10] [1420/1778] time: 13805.2916, d_loss: -0.698834, d_loss_cls: 0.000412, g_loss: 1.211464, g_loss_cls: 0.006884, g_loss_recon: 0.063865, wd: 0.875497\n",
      "Epoch: [10] [1520/1778] time: 13877.1104, d_loss: -0.892448, d_loss_cls: 0.000212, g_loss: 1.880861, g_loss_cls: 0.003685, g_loss_recon: 0.059614, wd: 1.096870\n",
      "Epoch: [10] [1620/1778] time: 13948.9506, d_loss: -0.685097, d_loss_cls: 0.001237, g_loss: 1.636266, g_loss_cls: 0.001251, g_loss_recon: 0.063867, wd: 0.854844\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10] [1720/1778] time: 14021.1543, d_loss: -0.800589, d_loss_cls: 0.000585, g_loss: -0.221225, g_loss_cls: 0.000394, g_loss_recon: 0.064067, wd: 1.004799\n",
      "Epoch: [11] [  42/1778] time: 14092.9755, d_loss: -0.875886, d_loss_cls: 0.001032, g_loss: 1.204143, g_loss_cls: 0.006518, g_loss_recon: 0.063879, wd: 1.113116\n",
      "Epoch: [11] [ 142/1778] time: 14164.8113, d_loss: -0.544853, d_loss_cls: 0.000802, g_loss: 0.706751, g_loss_cls: 0.018732, g_loss_recon: 0.058534, wd: 0.692684\n",
      "Epoch: [11] [ 242/1778] time: 14236.6242, d_loss: -0.751370, d_loss_cls: 0.001385, g_loss: 2.345069, g_loss_cls: 0.015295, g_loss_recon: 0.065437, wd: 1.018971\n",
      "Epoch: [11] [ 342/1778] time: 14308.4441, d_loss: -0.638051, d_loss_cls: 0.001818, g_loss: -0.332123, g_loss_cls: 0.021204, g_loss_recon: 0.061387, wd: 0.814261\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [11] [ 442/1778] time: 14380.6497, d_loss: -0.562603, d_loss_cls: 0.000773, g_loss: -1.343048, g_loss_cls: 0.054988, g_loss_recon: 0.069776, wd: 0.739257\n",
      "Epoch: [11] [ 542/1778] time: 14452.4536, d_loss: -0.652478, d_loss_cls: 0.000846, g_loss: 2.844794, g_loss_cls: 0.025524, g_loss_recon: 0.068016, wd: 0.841239\n",
      "Epoch: [11] [ 642/1778] time: 14524.2622, d_loss: -0.696913, d_loss_cls: 0.001844, g_loss: 3.233639, g_loss_cls: 0.000762, g_loss_recon: 0.061667, wd: 0.855665\n",
      "Epoch: [11] [ 742/1778] time: 14596.0678, d_loss: -0.689593, d_loss_cls: 0.000824, g_loss: 1.377065, g_loss_cls: 0.019990, g_loss_recon: 0.057144, wd: 0.856943\n",
      "Epoch: [11] [ 842/1778] time: 14667.8317, d_loss: -0.870120, d_loss_cls: 0.001368, g_loss: 1.017162, g_loss_cls: 0.004132, g_loss_recon: 0.062924, wd: 1.072305\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [11] [ 942/1778] time: 14739.9804, d_loss: -0.581600, d_loss_cls: 0.000726, g_loss: 0.629469, g_loss_cls: 0.000149, g_loss_recon: 0.062282, wd: 0.753793\n",
      "Epoch: [11] [1042/1778] time: 14811.8147, d_loss: -0.613468, d_loss_cls: 0.001042, g_loss: 0.234866, g_loss_cls: 0.022186, g_loss_recon: 0.060085, wd: 0.797598\n",
      "Epoch: [11] [1142/1778] time: 14883.6392, d_loss: -0.936421, d_loss_cls: 0.000816, g_loss: -1.470289, g_loss_cls: 0.000269, g_loss_recon: 0.063944, wd: 1.190682\n",
      "Epoch: [11] [1242/1778] time: 14955.4390, d_loss: -0.634317, d_loss_cls: 0.000319, g_loss: 0.695575, g_loss_cls: 0.005647, g_loss_recon: 0.060535, wd: 0.803660\n",
      "Epoch: [11] [1342/1778] time: 15027.2554, d_loss: -0.884621, d_loss_cls: 0.000913, g_loss: 1.697581, g_loss_cls: 0.002895, g_loss_recon: 0.059553, wd: 1.085819\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [11] [1442/1778] time: 15099.4553, d_loss: -0.524492, d_loss_cls: 0.000932, g_loss: 4.977434, g_loss_cls: 0.002559, g_loss_recon: 0.063253, wd: 0.685061\n",
      "Epoch: [11] [1542/1778] time: 15171.2760, d_loss: -0.776703, d_loss_cls: 0.001109, g_loss: 0.897481, g_loss_cls: 0.002134, g_loss_recon: 0.063680, wd: 1.001647\n",
      "Epoch: [11] [1642/1778] time: 15243.0999, d_loss: -0.810430, d_loss_cls: 0.001325, g_loss: 1.165563, g_loss_cls: 0.042593, g_loss_recon: 0.059213, wd: 1.004227\n",
      "Epoch: [11] [1742/1778] time: 15314.9016, d_loss: -0.560068, d_loss_cls: 0.000471, g_loss: 0.508662, g_loss_cls: 0.002231, g_loss_recon: 0.057065, wd: 0.710311\n",
      "Epoch: [12] [  64/1778] time: 15386.7397, d_loss: -1.104306, d_loss_cls: 0.000254, g_loss: -0.829758, g_loss_cls: 0.000134, g_loss_recon: 0.058264, wd: 1.358762\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [12] [ 164/1778] time: 15458.9384, d_loss: -0.535411, d_loss_cls: 0.000793, g_loss: 1.791713, g_loss_cls: 0.002024, g_loss_recon: 0.067650, wd: 0.718479\n",
      "Epoch: [12] [ 264/1778] time: 15530.7226, d_loss: -1.001077, d_loss_cls: 0.000371, g_loss: 0.476436, g_loss_cls: 0.009556, g_loss_recon: 0.058318, wd: 1.214011\n",
      "Epoch: [12] [ 364/1778] time: 15602.5875, d_loss: -0.638948, d_loss_cls: 0.001253, g_loss: 0.058758, g_loss_cls: 0.026324, g_loss_recon: 0.058086, wd: 0.807033\n",
      "Epoch: [12] [ 464/1778] time: 15674.4349, d_loss: -0.625371, d_loss_cls: 0.001049, g_loss: 2.023401, g_loss_cls: 0.001388, g_loss_recon: 0.060785, wd: 0.770538\n",
      "Epoch: [12] [ 564/1778] time: 15746.2683, d_loss: -0.797021, d_loss_cls: 0.001128, g_loss: 2.368021, g_loss_cls: 0.001806, g_loss_recon: 0.058426, wd: 0.989139\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [12] [ 664/1778] time: 15818.4329, d_loss: -0.492226, d_loss_cls: 0.000410, g_loss: 0.647266, g_loss_cls: 0.001550, g_loss_recon: 0.059775, wd: 0.643190\n",
      "Epoch: [12] [ 764/1778] time: 15890.2280, d_loss: -0.954776, d_loss_cls: 0.001599, g_loss: 1.875905, g_loss_cls: 0.003876, g_loss_recon: 0.060259, wd: 1.202840\n",
      "Epoch: [12] [ 864/1778] time: 15962.0522, d_loss: -0.776312, d_loss_cls: 0.001736, g_loss: 0.879385, g_loss_cls: 0.002684, g_loss_recon: 0.059087, wd: 0.976620\n",
      "Epoch: [12] [ 964/1778] time: 16033.8564, d_loss: -1.146915, d_loss_cls: 0.000751, g_loss: 0.635697, g_loss_cls: 0.001622, g_loss_recon: 0.063521, wd: 1.426445\n",
      "Epoch: [12] [1064/1778] time: 16105.6545, d_loss: -0.843021, d_loss_cls: 0.000639, g_loss: 0.121670, g_loss_cls: 0.001794, g_loss_recon: 0.054112, wd: 1.054992\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [12] [1164/1778] time: 16177.8077, d_loss: -0.777711, d_loss_cls: 0.001251, g_loss: 3.001667, g_loss_cls: 0.002120, g_loss_recon: 0.062377, wd: 0.985815\n",
      "Epoch: [12] [1264/1778] time: 16249.5805, d_loss: -0.588075, d_loss_cls: 0.001664, g_loss: 0.591443, g_loss_cls: 0.000515, g_loss_recon: 0.064295, wd: 0.745548\n",
      "Epoch: [12] [1364/1778] time: 16321.3800, d_loss: -0.690801, d_loss_cls: 0.001271, g_loss: 0.813043, g_loss_cls: 0.002921, g_loss_recon: 0.060668, wd: 0.884998\n",
      "Epoch: [12] [1464/1778] time: 16393.1788, d_loss: -0.523656, d_loss_cls: 0.001901, g_loss: 1.145526, g_loss_cls: 0.012704, g_loss_recon: 0.056294, wd: 0.670884\n",
      "Epoch: [12] [1564/1778] time: 16464.9780, d_loss: -0.775274, d_loss_cls: 0.001411, g_loss: -1.332092, g_loss_cls: 0.007849, g_loss_recon: 0.062719, wd: 0.940975\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [12] [1664/1778] time: 16537.1737, d_loss: -0.663378, d_loss_cls: 0.000459, g_loss: 0.002897, g_loss_cls: 0.001457, g_loss_recon: 0.056835, wd: 0.837222\n",
      "Epoch: [12] [1764/1778] time: 16608.9562, d_loss: -0.678725, d_loss_cls: 0.000773, g_loss: 3.694187, g_loss_cls: 0.001664, g_loss_recon: 0.061850, wd: 0.854167\n",
      "Epoch: [13] [  86/1778] time: 16680.7415, d_loss: -0.825691, d_loss_cls: 0.000775, g_loss: 1.676179, g_loss_cls: 0.000163, g_loss_recon: 0.060081, wd: 1.066249\n",
      "Epoch: [13] [ 186/1778] time: 16752.5340, d_loss: -0.766789, d_loss_cls: 0.000299, g_loss: 1.383686, g_loss_cls: 0.007362, g_loss_recon: 0.058748, wd: 0.953682\n",
      "Epoch: [13] [ 286/1778] time: 16824.3353, d_loss: -0.655346, d_loss_cls: 0.001478, g_loss: -0.611807, g_loss_cls: 0.004459, g_loss_recon: 0.057937, wd: 0.846954\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [13] [ 386/1778] time: 16896.5440, d_loss: -0.442960, d_loss_cls: 0.000886, g_loss: -0.216259, g_loss_cls: 0.000741, g_loss_recon: 0.058200, wd: 0.593897\n",
      "Epoch: [13] [ 486/1778] time: 16968.3628, d_loss: -0.685499, d_loss_cls: 0.001024, g_loss: -0.062450, g_loss_cls: 0.000893, g_loss_recon: 0.055620, wd: 0.877072\n",
      "Epoch: [13] [ 586/1778] time: 17040.1534, d_loss: -0.960016, d_loss_cls: 0.000620, g_loss: -1.251583, g_loss_cls: 0.000978, g_loss_recon: 0.060965, wd: 1.178801\n",
      "Epoch: [13] [ 686/1778] time: 17111.9559, d_loss: -0.659952, d_loss_cls: 0.000464, g_loss: 0.446570, g_loss_cls: 0.032476, g_loss_recon: 0.056958, wd: 0.841322\n",
      "Epoch: [13] [ 786/1778] time: 17183.7728, d_loss: -0.628508, d_loss_cls: 0.000836, g_loss: 0.924149, g_loss_cls: 0.000193, g_loss_recon: 0.058239, wd: 0.781515\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [13] [ 886/1778] time: 17255.9555, d_loss: -0.509192, d_loss_cls: 0.001744, g_loss: 0.311959, g_loss_cls: 0.003593, g_loss_recon: 0.059383, wd: 0.678482\n",
      "Epoch: [13] [ 986/1778] time: 17327.7880, d_loss: -0.668110, d_loss_cls: 0.000392, g_loss: 0.884343, g_loss_cls: 0.000074, g_loss_recon: 0.061457, wd: 0.914001\n",
      "Epoch: [13] [1086/1778] time: 17399.6264, d_loss: -0.626685, d_loss_cls: 0.000654, g_loss: 0.209434, g_loss_cls: 0.003025, g_loss_recon: 0.058682, wd: 0.803352\n",
      "Epoch: [13] [1186/1778] time: 17471.4475, d_loss: -0.774141, d_loss_cls: 0.000261, g_loss: 0.587680, g_loss_cls: 0.000185, g_loss_recon: 0.064385, wd: 0.964573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13] [1286/1778] time: 17543.2535, d_loss: -0.806228, d_loss_cls: 0.000680, g_loss: -0.289057, g_loss_cls: 0.000981, g_loss_recon: 0.063562, wd: 1.019248\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [13] [1386/1778] time: 17615.4424, d_loss: -0.570598, d_loss_cls: 0.000241, g_loss: 2.031877, g_loss_cls: 0.001111, g_loss_recon: 0.061869, wd: 0.786676\n",
      "Epoch: [13] [1486/1778] time: 17687.2326, d_loss: -0.586870, d_loss_cls: 0.001243, g_loss: 0.087805, g_loss_cls: 0.054958, g_loss_recon: 0.059671, wd: 0.736651\n",
      "Epoch: [13] [1586/1778] time: 17759.0090, d_loss: -0.694760, d_loss_cls: 0.000814, g_loss: 0.632224, g_loss_cls: 0.001706, g_loss_recon: 0.059685, wd: 0.869062\n",
      "Epoch: [13] [1686/1778] time: 17830.8332, d_loss: -0.947560, d_loss_cls: 0.000446, g_loss: 1.364197, g_loss_cls: 0.034061, g_loss_recon: 0.061090, wd: 1.168216\n",
      "Epoch: [14] [   8/1778] time: 17902.6433, d_loss: -0.701307, d_loss_cls: 0.000229, g_loss: -0.940183, g_loss_cls: 0.018054, g_loss_recon: 0.059986, wd: 0.895759\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [14] [ 108/1778] time: 17974.8166, d_loss: -0.884527, d_loss_cls: 0.000569, g_loss: -0.064418, g_loss_cls: 0.012435, g_loss_recon: 0.067913, wd: 1.190167\n",
      "Epoch: [14] [ 208/1778] time: 18046.6178, d_loss: -0.564278, d_loss_cls: 0.001687, g_loss: 0.814949, g_loss_cls: 0.020043, g_loss_recon: 0.057910, wd: 0.748034\n",
      "Epoch: [14] [ 308/1778] time: 18118.3789, d_loss: -0.699085, d_loss_cls: 0.000610, g_loss: 0.034210, g_loss_cls: 0.000369, g_loss_recon: 0.056367, wd: 0.875622\n",
      "Epoch: [14] [ 408/1778] time: 18190.1893, d_loss: -0.720093, d_loss_cls: 0.000905, g_loss: -0.982477, g_loss_cls: 0.005102, g_loss_recon: 0.055652, wd: 0.909297\n",
      "Epoch: [14] [ 508/1778] time: 18262.0087, d_loss: -0.725218, d_loss_cls: 0.000777, g_loss: 3.336540, g_loss_cls: 0.000464, g_loss_recon: 0.059597, wd: 0.904835\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [14] [ 608/1778] time: 18334.2011, d_loss: -0.686434, d_loss_cls: 0.000303, g_loss: -2.170958, g_loss_cls: 0.000497, g_loss_recon: 0.060107, wd: 0.873401\n",
      "Epoch: [14] [ 708/1778] time: 18406.0133, d_loss: -0.682842, d_loss_cls: 0.000686, g_loss: 0.035056, g_loss_cls: 0.004215, g_loss_recon: 0.054271, wd: 0.860835\n",
      "Epoch: [14] [ 808/1778] time: 18477.8065, d_loss: -0.705045, d_loss_cls: 0.001228, g_loss: 1.102967, g_loss_cls: 0.026137, g_loss_recon: 0.060714, wd: 0.915623\n",
      "Epoch: [14] [ 908/1778] time: 18549.5557, d_loss: -0.740065, d_loss_cls: 0.001109, g_loss: 1.049932, g_loss_cls: 0.003754, g_loss_recon: 0.059160, wd: 0.947556\n",
      "Epoch: [14] [1008/1778] time: 18621.3482, d_loss: -0.698871, d_loss_cls: 0.001123, g_loss: -0.037970, g_loss_cls: 0.009645, g_loss_recon: 0.063121, wd: 0.906043\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [14] [1108/1778] time: 18693.5212, d_loss: -0.527727, d_loss_cls: 0.000880, g_loss: 0.854827, g_loss_cls: 0.041593, g_loss_recon: 0.059677, wd: 0.682120\n",
      "Epoch: [14] [1208/1778] time: 18765.3089, d_loss: -0.573067, d_loss_cls: 0.002059, g_loss: 0.452192, g_loss_cls: 0.010115, g_loss_recon: 0.061964, wd: 0.746376\n",
      "Epoch: [14] [1308/1778] time: 18837.0831, d_loss: -0.558829, d_loss_cls: 0.001005, g_loss: 2.499589, g_loss_cls: 0.011990, g_loss_recon: 0.055010, wd: 0.736661\n",
      "Epoch: [14] [1408/1778] time: 18908.8773, d_loss: -0.761464, d_loss_cls: 0.000344, g_loss: 1.540270, g_loss_cls: 0.007386, g_loss_recon: 0.062969, wd: 0.966752\n",
      "Epoch: [14] [1508/1778] time: 18980.6653, d_loss: -0.471914, d_loss_cls: 0.000759, g_loss: 0.041727, g_loss_cls: 0.000127, g_loss_recon: 0.056995, wd: 0.632063\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [14] [1608/1778] time: 19052.8700, d_loss: -0.582173, d_loss_cls: 0.000524, g_loss: 2.301223, g_loss_cls: 0.000126, g_loss_recon: 0.056967, wd: 0.756972\n",
      "Epoch: [14] [1708/1778] time: 19124.6520, d_loss: -0.702937, d_loss_cls: 0.001460, g_loss: 2.407949, g_loss_cls: 0.005975, g_loss_recon: 0.060656, wd: 0.934066\n",
      "Epoch: [15] [  30/1778] time: 19196.4113, d_loss: -0.702029, d_loss_cls: 0.000724, g_loss: 1.400680, g_loss_cls: 0.000674, g_loss_recon: 0.055062, wd: 0.873621\n",
      "Epoch: [15] [ 130/1778] time: 19268.2150, d_loss: -0.602472, d_loss_cls: 0.001012, g_loss: 3.584551, g_loss_cls: 0.001118, g_loss_recon: 0.064291, wd: 0.840441\n",
      "Epoch: [15] [ 230/1778] time: 19340.0155, d_loss: -0.602988, d_loss_cls: 0.000454, g_loss: 1.098479, g_loss_cls: 0.000408, g_loss_recon: 0.056423, wd: 0.792864\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [15] [ 330/1778] time: 19412.1950, d_loss: -0.646834, d_loss_cls: 0.001384, g_loss: -0.205797, g_loss_cls: 0.001860, g_loss_recon: 0.058140, wd: 0.814199\n",
      "Epoch: [15] [ 430/1778] time: 19484.0193, d_loss: -0.810194, d_loss_cls: 0.001392, g_loss: 1.180506, g_loss_cls: 0.038118, g_loss_recon: 0.057037, wd: 1.028477\n",
      "Epoch: [15] [ 530/1778] time: 19555.7858, d_loss: -0.552008, d_loss_cls: 0.000759, g_loss: -0.403056, g_loss_cls: 0.002217, g_loss_recon: 0.057999, wd: 0.726233\n",
      "Epoch: [15] [ 630/1778] time: 19627.5543, d_loss: -0.639921, d_loss_cls: 0.000603, g_loss: 2.900766, g_loss_cls: 0.021530, g_loss_recon: 0.059934, wd: 0.835775\n",
      "Epoch: [15] [ 730/1778] time: 19699.3581, d_loss: -0.575376, d_loss_cls: 0.000811, g_loss: 0.586981, g_loss_cls: 0.000097, g_loss_recon: 0.055872, wd: 0.757877\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [15] [ 830/1778] time: 19771.5261, d_loss: -0.708512, d_loss_cls: 0.000962, g_loss: 1.013915, g_loss_cls: 0.002322, g_loss_recon: 0.065657, wd: 0.942977\n",
      "Epoch: [15] [ 930/1778] time: 19843.3061, d_loss: -0.762714, d_loss_cls: 0.000976, g_loss: -1.164772, g_loss_cls: 0.006753, g_loss_recon: 0.058716, wd: 1.023685\n",
      "Epoch: [15] [1030/1778] time: 19915.1243, d_loss: -0.716179, d_loss_cls: 0.000076, g_loss: 0.385952, g_loss_cls: 0.003302, g_loss_recon: 0.056867, wd: 0.916656\n",
      "Epoch: [15] [1130/1778] time: 19986.9118, d_loss: -0.839428, d_loss_cls: 0.000662, g_loss: -0.489454, g_loss_cls: 0.001938, g_loss_recon: 0.056520, wd: 1.064621\n",
      "Epoch: [15] [1230/1778] time: 20058.7058, d_loss: -0.603997, d_loss_cls: 0.000327, g_loss: 0.126509, g_loss_cls: 0.000591, g_loss_recon: 0.055039, wd: 0.795269\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [15] [1330/1778] time: 20130.8420, d_loss: -0.513737, d_loss_cls: 0.000766, g_loss: -1.745986, g_loss_cls: 0.013661, g_loss_recon: 0.061424, wd: 0.684702\n",
      "Epoch: [15] [1430/1778] time: 20202.6384, d_loss: -0.614326, d_loss_cls: 0.001247, g_loss: -1.658414, g_loss_cls: 0.006870, g_loss_recon: 0.054877, wd: 0.782412\n",
      "Epoch: [15] [1530/1778] time: 20274.4482, d_loss: -0.675506, d_loss_cls: 0.001223, g_loss: 1.258911, g_loss_cls: 0.001534, g_loss_recon: 0.059844, wd: 0.846692\n",
      "Epoch: [15] [1630/1778] time: 20346.2703, d_loss: -0.648456, d_loss_cls: 0.001008, g_loss: 0.310123, g_loss_cls: 0.031542, g_loss_recon: 0.057068, wd: 0.840521\n",
      "Epoch: [15] [1730/1778] time: 20417.9683, d_loss: -0.686121, d_loss_cls: 0.000673, g_loss: -2.256202, g_loss_cls: 0.054755, g_loss_recon: 0.059275, wd: 0.874475\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [16] [  52/1778] time: 20490.1685, d_loss: -0.645014, d_loss_cls: 0.000771, g_loss: -0.069493, g_loss_cls: 0.000610, g_loss_recon: 0.053510, wd: 0.838580\n",
      "Epoch: [16] [ 152/1778] time: 20561.9915, d_loss: -0.599432, d_loss_cls: 0.001525, g_loss: 0.252747, g_loss_cls: 0.001740, g_loss_recon: 0.053473, wd: 0.788310\n",
      "Epoch: [16] [ 252/1778] time: 20633.8181, d_loss: -0.835158, d_loss_cls: 0.001088, g_loss: 1.502256, g_loss_cls: 0.002295, g_loss_recon: 0.058000, wd: 1.012902\n",
      "Epoch: [16] [ 352/1778] time: 20705.6255, d_loss: -0.561839, d_loss_cls: 0.000600, g_loss: -2.314381, g_loss_cls: 0.001645, g_loss_recon: 0.055080, wd: 0.723245\n",
      "Epoch: [16] [ 452/1778] time: 20777.4293, d_loss: -0.664748, d_loss_cls: 0.000746, g_loss: -0.374803, g_loss_cls: 0.001617, g_loss_recon: 0.057315, wd: 0.835015\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [16] [ 552/1778] time: 20849.6224, d_loss: -0.673041, d_loss_cls: 0.000771, g_loss: 1.221199, g_loss_cls: 0.004701, g_loss_recon: 0.056457, wd: 0.851303\n",
      "Epoch: [16] [ 652/1778] time: 20921.4027, d_loss: -0.616777, d_loss_cls: 0.000348, g_loss: -0.026475, g_loss_cls: 0.020339, g_loss_recon: 0.057653, wd: 0.760129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [16] [ 752/1778] time: 20993.2295, d_loss: -0.803608, d_loss_cls: 0.000293, g_loss: 2.665714, g_loss_cls: 0.000089, g_loss_recon: 0.057146, wd: 1.006729\n",
      "Epoch: [16] [ 852/1778] time: 21065.0634, d_loss: -0.689556, d_loss_cls: 0.001055, g_loss: 0.072534, g_loss_cls: 0.009144, g_loss_recon: 0.053466, wd: 0.859375\n",
      "Epoch: [16] [ 952/1778] time: 21136.8531, d_loss: -0.766582, d_loss_cls: 0.000994, g_loss: 2.309014, g_loss_cls: 0.002273, g_loss_recon: 0.059445, wd: 0.992172\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [16] [1052/1778] time: 21209.0501, d_loss: -0.617099, d_loss_cls: 0.000675, g_loss: 0.887050, g_loss_cls: 0.003819, g_loss_recon: 0.055959, wd: 0.784430\n",
      "Epoch: [16] [1152/1778] time: 21280.8391, d_loss: -0.803180, d_loss_cls: 0.000192, g_loss: -0.538737, g_loss_cls: 0.051579, g_loss_recon: 0.055127, wd: 1.008503\n",
      "Epoch: [16] [1252/1778] time: 21352.6377, d_loss: -0.597541, d_loss_cls: 0.000408, g_loss: 1.499255, g_loss_cls: 0.001127, g_loss_recon: 0.055968, wd: 0.790120\n",
      "Epoch: [16] [1352/1778] time: 21424.4284, d_loss: -0.643006, d_loss_cls: 0.001965, g_loss: 0.496657, g_loss_cls: 0.012648, g_loss_recon: 0.057003, wd: 0.802171\n",
      "Epoch: [16] [1452/1778] time: 21496.2440, d_loss: -0.720102, d_loss_cls: 0.001047, g_loss: 1.773826, g_loss_cls: 0.009307, g_loss_recon: 0.057652, wd: 0.921988\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [16] [1552/1778] time: 21568.3435, d_loss: -0.602774, d_loss_cls: 0.000876, g_loss: 1.006072, g_loss_cls: 0.000840, g_loss_recon: 0.056637, wd: 0.848148\n",
      "Epoch: [16] [1652/1778] time: 21640.1322, d_loss: -0.759453, d_loss_cls: 0.003397, g_loss: 1.214179, g_loss_cls: 0.002114, g_loss_recon: 0.057598, wd: 0.980759\n",
      "Epoch: [16] [1752/1778] time: 21711.9523, d_loss: -0.405457, d_loss_cls: 0.000860, g_loss: 0.194771, g_loss_cls: 0.000156, g_loss_recon: 0.057545, wd: 0.572431\n",
      "Epoch: [17] [  74/1778] time: 21783.7266, d_loss: -0.804732, d_loss_cls: 0.000557, g_loss: 0.465719, g_loss_cls: 0.041130, g_loss_recon: 0.055688, wd: 1.000631\n",
      "Epoch: [17] [ 174/1778] time: 21855.5414, d_loss: -0.778112, d_loss_cls: 0.000230, g_loss: -0.618750, g_loss_cls: 0.003690, g_loss_recon: 0.059644, wd: 0.977267\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [17] [ 274/1778] time: 21927.7351, d_loss: -0.945718, d_loss_cls: 0.000738, g_loss: -2.744178, g_loss_cls: 0.006361, g_loss_recon: 0.059820, wd: 1.171848\n",
      "Epoch: [17] [ 374/1778] time: 21999.5383, d_loss: -0.525748, d_loss_cls: 0.000443, g_loss: -0.255835, g_loss_cls: 0.001403, g_loss_recon: 0.055373, wd: 0.677335\n",
      "Epoch: [17] [ 474/1778] time: 22071.3323, d_loss: -0.899440, d_loss_cls: 0.001030, g_loss: 1.327426, g_loss_cls: 0.014234, g_loss_recon: 0.054950, wd: 1.113691\n",
      "Epoch: [17] [ 574/1778] time: 22143.1148, d_loss: -0.658567, d_loss_cls: 0.001337, g_loss: -2.034825, g_loss_cls: 0.000137, g_loss_recon: 0.059331, wd: 0.881487\n",
      "Epoch: [17] [ 674/1778] time: 22214.9380, d_loss: -0.939979, d_loss_cls: 0.000474, g_loss: -1.774332, g_loss_cls: 0.000452, g_loss_recon: 0.058035, wd: 1.212543\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [17] [ 774/1778] time: 22287.1577, d_loss: -0.614806, d_loss_cls: 0.000655, g_loss: 2.046840, g_loss_cls: 0.013214, g_loss_recon: 0.059269, wd: 0.810066\n",
      "Epoch: [17] [ 874/1778] time: 22358.9870, d_loss: -0.450064, d_loss_cls: 0.001674, g_loss: 0.449230, g_loss_cls: 0.003237, g_loss_recon: 0.054614, wd: 0.622797\n",
      "Epoch: [17] [ 974/1778] time: 22430.7665, d_loss: -0.837493, d_loss_cls: 0.000999, g_loss: -0.049222, g_loss_cls: 0.004019, g_loss_recon: 0.054183, wd: 1.066438\n",
      "Epoch: [17] [1074/1778] time: 22502.5779, d_loss: -0.678254, d_loss_cls: 0.000671, g_loss: 1.082634, g_loss_cls: 0.000440, g_loss_recon: 0.055760, wd: 0.863013\n",
      "Epoch: [17] [1174/1778] time: 22574.3657, d_loss: -1.003777, d_loss_cls: 0.000203, g_loss: 0.818757, g_loss_cls: 0.000040, g_loss_recon: 0.056753, wd: 1.247927\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [17] [1274/1778] time: 22646.5442, d_loss: -0.679052, d_loss_cls: 0.000585, g_loss: -1.583569, g_loss_cls: 0.002852, g_loss_recon: 0.054727, wd: 0.862427\n",
      "Epoch: [17] [1374/1778] time: 22718.3361, d_loss: -0.554299, d_loss_cls: 0.000720, g_loss: -0.414780, g_loss_cls: 0.000210, g_loss_recon: 0.053730, wd: 0.715333\n",
      "Epoch: [17] [1474/1778] time: 22790.1389, d_loss: -0.662937, d_loss_cls: 0.000635, g_loss: 2.499389, g_loss_cls: 0.001447, g_loss_recon: 0.058452, wd: 0.821216\n",
      "Epoch: [17] [1574/1778] time: 22861.9239, d_loss: -1.288815, d_loss_cls: 0.000306, g_loss: 1.168198, g_loss_cls: 0.015077, g_loss_recon: 0.051840, wd: 1.585474\n",
      "Epoch: [17] [1674/1778] time: 22933.7178, d_loss: -0.840229, d_loss_cls: 0.000528, g_loss: 0.247797, g_loss_cls: 0.000586, g_loss_recon: 0.059204, wd: 1.060865\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [17] [1774/1778] time: 23005.9118, d_loss: -0.488534, d_loss_cls: 0.000647, g_loss: 1.107313, g_loss_cls: 0.000057, g_loss_recon: 0.055518, wd: 0.641822\n",
      "Epoch: [18] [  96/1778] time: 23077.6964, d_loss: -0.700839, d_loss_cls: 0.001073, g_loss: 1.600905, g_loss_cls: 0.001721, g_loss_recon: 0.055985, wd: 0.900057\n",
      "Epoch: [18] [ 196/1778] time: 23149.5016, d_loss: -0.793080, d_loss_cls: 0.000383, g_loss: 1.116562, g_loss_cls: 0.035381, g_loss_recon: 0.056916, wd: 1.016856\n",
      "Epoch: [18] [ 296/1778] time: 23221.2621, d_loss: -0.667735, d_loss_cls: 0.000818, g_loss: -0.813819, g_loss_cls: 0.017321, g_loss_recon: 0.055107, wd: 0.868099\n",
      "Epoch: [18] [ 396/1778] time: 23293.0601, d_loss: -0.569902, d_loss_cls: 0.001251, g_loss: -1.224565, g_loss_cls: 0.000413, g_loss_recon: 0.059812, wd: 0.736940\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [18] [ 496/1778] time: 23365.2610, d_loss: -0.641448, d_loss_cls: 0.001186, g_loss: -0.547195, g_loss_cls: 0.001849, g_loss_recon: 0.061103, wd: 0.839970\n",
      "Epoch: [18] [ 596/1778] time: 23437.0312, d_loss: -0.634481, d_loss_cls: 0.000684, g_loss: 1.741893, g_loss_cls: 0.000729, g_loss_recon: 0.055750, wd: 0.847458\n",
      "Epoch: [18] [ 696/1778] time: 23508.8402, d_loss: -0.696540, d_loss_cls: 0.000950, g_loss: -0.831716, g_loss_cls: 0.000605, g_loss_recon: 0.057750, wd: 0.880425\n",
      "Epoch: [18] [ 796/1778] time: 23580.6361, d_loss: -0.539169, d_loss_cls: 0.001501, g_loss: -0.836890, g_loss_cls: 0.002637, g_loss_recon: 0.055639, wd: 0.712341\n",
      "Epoch: [18] [ 896/1778] time: 23652.4397, d_loss: -0.449104, d_loss_cls: 0.000551, g_loss: 2.467847, g_loss_cls: 0.000134, g_loss_recon: 0.057061, wd: 0.590272\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [18] [ 996/1778] time: 23724.6355, d_loss: -0.796187, d_loss_cls: 0.000323, g_loss: -0.098692, g_loss_cls: 0.001206, g_loss_recon: 0.054333, wd: 1.001864\n",
      "Epoch: [18] [1096/1778] time: 23796.4861, d_loss: -0.875298, d_loss_cls: 0.001892, g_loss: 0.171554, g_loss_cls: 0.001401, g_loss_recon: 0.053182, wd: 1.092646\n",
      "Epoch: [18] [1196/1778] time: 23868.3522, d_loss: -0.683093, d_loss_cls: 0.000138, g_loss: 0.067217, g_loss_cls: 0.000059, g_loss_recon: 0.054080, wd: 0.890825\n",
      "Epoch: [18] [1296/1778] time: 23940.1988, d_loss: -0.671680, d_loss_cls: 0.000681, g_loss: 0.166045, g_loss_cls: 0.006156, g_loss_recon: 0.056682, wd: 0.857506\n",
      "Epoch: [18] [1396/1778] time: 24012.0187, d_loss: -0.372489, d_loss_cls: 0.001172, g_loss: -0.122112, g_loss_cls: 0.003540, g_loss_recon: 0.050933, wd: 0.527193\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [18] [1496/1778] time: 24084.1888, d_loss: -0.718397, d_loss_cls: 0.000456, g_loss: 1.970745, g_loss_cls: 0.007605, g_loss_recon: 0.056167, wd: 0.918013\n",
      "Epoch: [18] [1596/1778] time: 24155.9880, d_loss: -0.513953, d_loss_cls: 0.000644, g_loss: 2.803382, g_loss_cls: 0.004222, g_loss_recon: 0.054274, wd: 0.670693\n",
      "Epoch: [18] [1696/1778] time: 24227.7795, d_loss: -0.637613, d_loss_cls: 0.000602, g_loss: 1.246167, g_loss_cls: 0.048794, g_loss_recon: 0.055815, wd: 0.838441\n",
      "Epoch: [19] [  18/1778] time: 24299.5542, d_loss: -0.550234, d_loss_cls: 0.001834, g_loss: -1.562542, g_loss_cls: 0.000623, g_loss_recon: 0.058306, wd: 0.720359\n",
      "Epoch: [19] [ 118/1778] time: 24371.3646, d_loss: -0.643073, d_loss_cls: 0.000945, g_loss: 2.843387, g_loss_cls: 0.000437, g_loss_recon: 0.069346, wd: 0.878848\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19] [ 218/1778] time: 24443.5589, d_loss: -0.659129, d_loss_cls: 0.000439, g_loss: 0.584984, g_loss_cls: 0.030023, g_loss_recon: 0.062236, wd: 0.912380\n",
      "Epoch: [19] [ 318/1778] time: 24515.3835, d_loss: -0.667530, d_loss_cls: 0.000530, g_loss: 1.444247, g_loss_cls: 0.002424, g_loss_recon: 0.053975, wd: 0.838112\n",
      "Epoch: [19] [ 418/1778] time: 24587.1873, d_loss: -0.553943, d_loss_cls: 0.000406, g_loss: 0.566056, g_loss_cls: 0.000128, g_loss_recon: 0.059267, wd: 0.761972\n",
      "Epoch: [19] [ 518/1778] time: 24658.9847, d_loss: -0.629467, d_loss_cls: 0.001043, g_loss: -1.438994, g_loss_cls: 0.024087, g_loss_recon: 0.053426, wd: 0.772328\n",
      "Epoch: [19] [ 618/1778] time: 24730.7811, d_loss: -0.376840, d_loss_cls: 0.000612, g_loss: 0.751663, g_loss_cls: 0.000106, g_loss_recon: 0.053790, wd: 0.537299\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [19] [ 718/1778] time: 24802.9906, d_loss: -0.537940, d_loss_cls: 0.001129, g_loss: -0.218606, g_loss_cls: 0.012507, g_loss_recon: 0.057594, wd: 0.709634\n",
      "Epoch: [19] [ 818/1778] time: 24874.7622, d_loss: -0.671486, d_loss_cls: 0.000539, g_loss: -1.242058, g_loss_cls: 0.000098, g_loss_recon: 0.054530, wd: 0.855715\n",
      "Epoch: [19] [ 918/1778] time: 24946.5641, d_loss: -0.527285, d_loss_cls: 0.000795, g_loss: -2.151223, g_loss_cls: 0.000121, g_loss_recon: 0.053492, wd: 0.701267\n",
      "Epoch: [19] [1018/1778] time: 25018.3596, d_loss: -0.725781, d_loss_cls: 0.000462, g_loss: -0.095969, g_loss_cls: 0.003016, g_loss_recon: 0.057242, wd: 0.943449\n",
      "Epoch: [19] [1118/1778] time: 25090.1609, d_loss: -0.815584, d_loss_cls: 0.000223, g_loss: -1.034640, g_loss_cls: 0.001069, g_loss_recon: 0.055072, wd: 1.080523\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [19] [1218/1778] time: 25162.3731, d_loss: -0.982217, d_loss_cls: 0.001458, g_loss: -1.283819, g_loss_cls: 0.003208, g_loss_recon: 0.062527, wd: 1.268122\n",
      "Epoch: [19] [1318/1778] time: 25234.1836, d_loss: -0.883857, d_loss_cls: 0.001442, g_loss: 0.093005, g_loss_cls: 0.007034, g_loss_recon: 0.056361, wd: 1.090911\n",
      "Epoch: [19] [1418/1778] time: 25305.9849, d_loss: -0.659734, d_loss_cls: 0.001094, g_loss: -1.307224, g_loss_cls: 0.000105, g_loss_recon: 0.054310, wd: 0.855147\n",
      "Epoch: [19] [1518/1778] time: 25377.7889, d_loss: -0.654353, d_loss_cls: 0.001951, g_loss: 1.581011, g_loss_cls: 0.019830, g_loss_recon: 0.055972, wd: 0.830133\n",
      "Epoch: [19] [1618/1778] time: 25449.6198, d_loss: -0.723175, d_loss_cls: 0.000420, g_loss: -1.846122, g_loss_cls: 0.004951, g_loss_recon: 0.056490, wd: 0.905065\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [19] [1718/1778] time: 25521.8271, d_loss: -0.461307, d_loss_cls: 0.000240, g_loss: 1.194334, g_loss_cls: 0.000888, g_loss_recon: 0.052357, wd: 0.655917\n",
      "Epoch: [20] [  40/1778] time: 25593.6778, d_loss: -0.526100, d_loss_cls: 0.000581, g_loss: 0.913164, g_loss_cls: 0.000724, g_loss_recon: 0.053887, wd: 0.688763\n",
      "Epoch: [20] [ 140/1778] time: 25665.5046, d_loss: -0.689745, d_loss_cls: 0.001108, g_loss: -0.767650, g_loss_cls: 0.000193, g_loss_recon: 0.053106, wd: 0.886333\n",
      "Epoch: [20] [ 240/1778] time: 25737.3544, d_loss: -0.646800, d_loss_cls: 0.001784, g_loss: 1.758173, g_loss_cls: 0.003799, g_loss_recon: 0.054243, wd: 0.882526\n",
      "Epoch: [20] [ 340/1778] time: 25809.1434, d_loss: -0.604571, d_loss_cls: 0.000481, g_loss: -0.195330, g_loss_cls: 0.001950, g_loss_recon: 0.056778, wd: 0.778667\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [20] [ 440/1778] time: 25881.3660, d_loss: -0.551147, d_loss_cls: 0.000843, g_loss: 0.605757, g_loss_cls: 0.000112, g_loss_recon: 0.060067, wd: 0.723157\n",
      "Epoch: [20] [ 540/1778] time: 25953.1660, d_loss: -0.685738, d_loss_cls: 0.000713, g_loss: -0.601716, g_loss_cls: 0.000170, g_loss_recon: 0.056787, wd: 0.857701\n",
      "Epoch: [20] [ 640/1778] time: 26024.9298, d_loss: -0.728327, d_loss_cls: 0.000517, g_loss: 1.389261, g_loss_cls: 0.000273, g_loss_recon: 0.055153, wd: 0.955847\n",
      "Epoch: [20] [ 740/1778] time: 26096.7304, d_loss: -0.713492, d_loss_cls: 0.000593, g_loss: -2.144803, g_loss_cls: 0.044435, g_loss_recon: 0.053694, wd: 0.911455\n",
      "Epoch: [20] [ 840/1778] time: 26168.5320, d_loss: -0.620173, d_loss_cls: 0.000951, g_loss: 0.105905, g_loss_cls: 0.000043, g_loss_recon: 0.055318, wd: 0.789814\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [20] [ 940/1778] time: 26240.7426, d_loss: -0.743852, d_loss_cls: 0.000876, g_loss: -0.722660, g_loss_cls: 0.000799, g_loss_recon: 0.051796, wd: 0.920449\n",
      "Epoch: [20] [1040/1778] time: 26312.5583, d_loss: -0.691536, d_loss_cls: 0.000661, g_loss: 0.103569, g_loss_cls: 0.003753, g_loss_recon: 0.052966, wd: 0.878879\n",
      "Epoch: [20] [1140/1778] time: 26384.4069, d_loss: -0.860275, d_loss_cls: 0.000798, g_loss: -0.020543, g_loss_cls: 0.000515, g_loss_recon: 0.051227, wd: 1.077195\n",
      "Epoch: [20] [1240/1778] time: 26456.2047, d_loss: -0.796764, d_loss_cls: 0.000878, g_loss: 2.203125, g_loss_cls: 0.000291, g_loss_recon: 0.055366, wd: 1.039992\n",
      "Epoch: [20] [1340/1778] time: 26528.0227, d_loss: -0.532017, d_loss_cls: 0.001168, g_loss: -0.743335, g_loss_cls: 0.004381, g_loss_recon: 0.055387, wd: 0.739264\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [20] [1440/1778] time: 26600.2213, d_loss: -0.681445, d_loss_cls: 0.001361, g_loss: 3.410937, g_loss_cls: 0.007364, g_loss_recon: 0.051867, wd: 0.862028\n",
      "Epoch: [20] [1540/1778] time: 26672.0411, d_loss: -0.686873, d_loss_cls: 0.000684, g_loss: 0.125908, g_loss_cls: 0.000188, g_loss_recon: 0.052162, wd: 0.881073\n",
      "Epoch: [20] [1640/1778] time: 26743.8530, d_loss: -0.930453, d_loss_cls: 0.000414, g_loss: -0.323706, g_loss_cls: 0.000657, g_loss_recon: 0.055327, wd: 1.170481\n",
      "Epoch: [20] [1740/1778] time: 26815.6429, d_loss: -0.730707, d_loss_cls: 0.001270, g_loss: -0.565408, g_loss_cls: 0.000079, g_loss_recon: 0.053880, wd: 0.912551\n",
      "Epoch: [21] [  62/1778] time: 26887.4395, d_loss: -0.676793, d_loss_cls: 0.000128, g_loss: -1.216725, g_loss_cls: 0.007083, g_loss_recon: 0.052238, wd: 0.829918\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [21] [ 162/1778] time: 26959.5649, d_loss: -0.466667, d_loss_cls: 0.002322, g_loss: 0.805314, g_loss_cls: 0.012701, g_loss_recon: 0.056205, wd: 0.654059\n",
      "Epoch: [21] [ 262/1778] time: 27031.3431, d_loss: -0.700824, d_loss_cls: 0.001460, g_loss: -0.753125, g_loss_cls: 0.000107, g_loss_recon: 0.055285, wd: 0.880628\n",
      "Epoch: [21] [ 362/1778] time: 27103.1453, d_loss: -0.342346, d_loss_cls: 0.002972, g_loss: -1.965805, g_loss_cls: 0.004167, g_loss_recon: 0.055562, wd: 0.501648\n",
      "Epoch: [21] [ 462/1778] time: 27174.9290, d_loss: -0.618871, d_loss_cls: 0.000509, g_loss: 2.322251, g_loss_cls: 0.000122, g_loss_recon: 0.052939, wd: 0.829130\n",
      "Epoch: [21] [ 562/1778] time: 27246.6908, d_loss: -0.420594, d_loss_cls: 0.000754, g_loss: 0.323365, g_loss_cls: 0.014801, g_loss_recon: 0.053563, wd: 0.577002\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [21] [ 662/1778] time: 27318.8837, d_loss: -0.782876, d_loss_cls: 0.000780, g_loss: 1.374834, g_loss_cls: 0.002519, g_loss_recon: 0.053673, wd: 0.976820\n",
      "Epoch: [21] [ 762/1778] time: 27390.7297, d_loss: -0.671517, d_loss_cls: 0.000686, g_loss: 1.077361, g_loss_cls: 0.018863, g_loss_recon: 0.052055, wd: 0.859350\n",
      "Epoch: [21] [ 862/1778] time: 27462.5714, d_loss: -0.734248, d_loss_cls: 0.001887, g_loss: 1.041953, g_loss_cls: 0.003959, g_loss_recon: 0.052893, wd: 0.919079\n",
      "Epoch: [21] [ 962/1778] time: 27534.4213, d_loss: -0.660612, d_loss_cls: 0.001792, g_loss: -0.892090, g_loss_cls: 0.003377, g_loss_recon: 0.052023, wd: 0.821785\n",
      "Epoch: [21] [1062/1778] time: 27606.2701, d_loss: -0.605946, d_loss_cls: 0.000508, g_loss: 1.260334, g_loss_cls: 0.001166, g_loss_recon: 0.050029, wd: 0.771876\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [21] [1162/1778] time: 27678.4847, d_loss: -0.734472, d_loss_cls: 0.000534, g_loss: 0.296001, g_loss_cls: 0.000777, g_loss_recon: 0.054359, wd: 0.953114\n",
      "Epoch: [21] [1262/1778] time: 27750.2869, d_loss: -0.336942, d_loss_cls: 0.001014, g_loss: 1.155571, g_loss_cls: 0.002362, g_loss_recon: 0.050689, wd: 0.448875\n",
      "Epoch: [21] [1362/1778] time: 27822.0836, d_loss: -0.745897, d_loss_cls: 0.000786, g_loss: 1.079479, g_loss_cls: 0.000055, g_loss_recon: 0.053204, wd: 0.952396\n",
      "Epoch: [21] [1462/1778] time: 27893.9346, d_loss: -1.181608, d_loss_cls: 0.000815, g_loss: 1.093315, g_loss_cls: 0.002754, g_loss_recon: 0.051864, wd: 1.492223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [21] [1562/1778] time: 27965.7259, d_loss: -0.413936, d_loss_cls: 0.002175, g_loss: -0.748754, g_loss_cls: 0.001805, g_loss_recon: 0.054912, wd: 0.570300\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [21] [1662/1778] time: 28037.9080, d_loss: -0.553253, d_loss_cls: 0.000729, g_loss: -1.132963, g_loss_cls: 0.005041, g_loss_recon: 0.052712, wd: 0.734710\n",
      "Epoch: [21] [1762/1778] time: 28109.7678, d_loss: -0.509461, d_loss_cls: 0.000409, g_loss: 0.339714, g_loss_cls: 0.000578, g_loss_recon: 0.052966, wd: 0.691163\n",
      "Epoch: [22] [  84/1778] time: 28181.5885, d_loss: -0.679653, d_loss_cls: 0.000542, g_loss: -1.661734, g_loss_cls: 0.016958, g_loss_recon: 0.050102, wd: 0.861516\n",
      "Epoch: [22] [ 184/1778] time: 28253.3851, d_loss: -0.663831, d_loss_cls: 0.001089, g_loss: -0.315249, g_loss_cls: 0.000605, g_loss_recon: 0.055300, wd: 0.816557\n",
      "Epoch: [22] [ 284/1778] time: 28325.2226, d_loss: -0.629917, d_loss_cls: 0.000606, g_loss: 0.436267, g_loss_cls: 0.013616, g_loss_recon: 0.053187, wd: 0.808662\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [22] [ 384/1778] time: 28397.4025, d_loss: -0.719047, d_loss_cls: 0.000762, g_loss: 0.329361, g_loss_cls: 0.001107, g_loss_recon: 0.052007, wd: 0.940850\n",
      "Epoch: [22] [ 484/1778] time: 28469.2052, d_loss: -0.491573, d_loss_cls: 0.000699, g_loss: 0.619107, g_loss_cls: 0.000514, g_loss_recon: 0.052763, wd: 0.636919\n",
      "Epoch: [22] [ 584/1778] time: 28541.0097, d_loss: -0.579489, d_loss_cls: 0.000668, g_loss: -0.575961, g_loss_cls: 0.002519, g_loss_recon: 0.051107, wd: 0.770993\n"
     ]
    }
   ],
   "source": [
    "import distutils.util\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "''' config settings '''\n",
    "\n",
    "project_name = \"StarGAN_Face_4_\"\n",
    "train_flag = True\n",
    "\n",
    "'''-----------------'''\n",
    "\n",
    "gpu_number = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #args.gpu_number\n",
    "\n",
    "with tf.device('/gpu:{0}'.format(gpu_number)):\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.90)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options)\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        model = StarGAN(sess, project_name)\n",
    "\n",
    "        # TRAIN / TEST\n",
    "        if train_flag:\n",
    "            model.train(train_flag)\n",
    "        else:\n",
    "            model.test(train_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
