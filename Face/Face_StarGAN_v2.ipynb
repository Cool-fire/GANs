{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StarGAN implementation v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1711.09020\n",
    "https://github.com/goldkim92/StarGAN-tensorflow/blob/master/\n",
    "https://github.com/ly-atdawn/StarGAN-Tensorflow\n",
    "https://github.com/igul222/improved_wgan_training/blob/master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.misc as scm\n",
    "import numpy as np\n",
    "\n",
    "def make_project_dir(project_dir):\n",
    "    if not os.path.exists(project_dir):\n",
    "        os.makedirs(project_dir)\n",
    "        os.makedirs(os.path.join(project_dir, 'models'))\n",
    "        os.makedirs(os.path.join(project_dir, 'result'))\n",
    "        os.makedirs(os.path.join(project_dir, 'result_test'))\n",
    "\n",
    "\n",
    "def get_image(img_path, flip=False): # [0,255] to [-1,1]\n",
    "    img = scm.imread(img_path) \n",
    "    if flip:\n",
    "        img = np.fliplr(img)\n",
    "    img = img * 2. /255. - 1.\n",
    "    img = img[..., ::-1]  # rgb to bgr\n",
    "    return img\n",
    "\n",
    "def get_label(path, size):\n",
    "    label = int(path[-5])\n",
    "    one_hot = np.zeros(size)\n",
    "    one_hot[ label ] = 1.0\n",
    "    one_hot[ one_hot==0 ] = 0.0\n",
    "    return one_hot\n",
    "\n",
    "def inverse_image(img): # [-1,1] to [0,255]\n",
    "    img = (img + 1.) / 2. * 255.\n",
    "    img[img > 255] = 255\n",
    "    img[img < 0] = 0\n",
    "    img = img[..., ::-1] # bgr to rgb\n",
    "    return img\n",
    "\n",
    "def pair_expressions(paths):\n",
    "    subject_exprs = []\n",
    "    subject_pairs = []\n",
    "    all_pairs = []\n",
    "    last_subject = 0\n",
    "\n",
    "    # Pair all expression of a subject\n",
    "    for path in paths:\n",
    "        subject = int(path[-10:-6])\n",
    "\n",
    "        if subject != last_subject and last_subject != 0:\n",
    "            subject_pairs = [(x, y) for x in subject_exprs for y in subject_exprs]\n",
    "            all_pairs.extend(subject_pairs)\n",
    "            subject_exprs = []\n",
    "\n",
    "        subject_exprs.append(path)\n",
    "        last_subject = subject\n",
    "\n",
    "    # Last subject\n",
    "    subject_pairs = [(x, y) for x in subject_exprs for y in subject_exprs]\n",
    "    all_pairs.extend(subject_pairs)\n",
    "    return all_pairs\n",
    "\n",
    "def get_shape_c(tensor): # static shape\n",
    "    return tensor.get_shape().as_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits\n",
    "\n",
    "def conv(x, filter_shape, bias=True, stride=1, padding=\"VALID\", name=\"conv2d\"):\n",
    "    kw, kh, nin, nout = filter_shape\n",
    "\n",
    "    stddev = np.sqrt(2.0/(np.sqrt(nin*nout)*kw*kh))\n",
    "    k_initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        x = tf.layers.conv2d(x, filters=nout, kernel_size=(kw, kh), strides=(stride, stride), padding=padding, \n",
    "                             use_bias=bias, kernel_initializer=k_initializer)\n",
    "    return x\n",
    "\n",
    "def deconv(x, filter_shape, bias=True, stride=1, padding=\"VALID\", name=\"conv2d_transpose\"):\n",
    "    kw, kh, nin, nout = filter_shape\n",
    "\n",
    "    stddev = np.sqrt(1.0/(np.sqrt(nin*nout)*kw*kh))\n",
    "    k_initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "    with tf.variable_scope(name):\n",
    "        x = tf.layers.conv2d_transpose(x, filters=nout, kernel_size=(kw, kh), strides=(stride, stride), padding=padding, \n",
    "                                       use_bias=bias, kernel_initializer=k_initializer)\n",
    "    return x\n",
    "\n",
    "def fc(x, output_shape, bias=True, name='fc'):\n",
    "    shape = x.get_shape().as_list()\n",
    "    dim = np.prod(shape[1:])\n",
    "    x = tf.reshape(x, [-1, dim])\n",
    "    input_shape = dim\n",
    "\n",
    "    stddev = np.sqrt(1.0/(np.sqrt(input_shape*output_shape)))\n",
    "    initializer = tf.random_normal_initializer(stddev=stddev)\n",
    "    with tf.variable_scope(name):\n",
    "        weight = tf.get_variable(\"weight\", shape=[input_shape, output_shape], initializer=initializer)\n",
    "        x = tf.matmul(x, weight)\n",
    "\n",
    "        if bias:\n",
    "            b = tf.get_variable(\"bias\", shape=[output_shape], initializer=tf.constant_initializer(0.))\n",
    "            x = tf.nn.bias_add(x, b)\n",
    "    return x\n",
    "\n",
    "\n",
    "def pool(x, r=2, s=1):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, r, r, 1], strides=[1, s, s, 1], padding=\"SAME\")\n",
    "\n",
    "def instance_norm(input, name='instance_norm'):\n",
    "    with tf.variable_scope(name):\n",
    "        depth = input.get_shape()[3]\n",
    "        scale = tf.get_variable('scale', [depth], initializer=tf.random_normal_initializer(1.0, 0.02, dtype=tf.float32))\n",
    "        offset = tf.get_variable('offset', [depth], initializer=tf.constant_initializer(0.0))\n",
    "        mean, variance = tf.nn.moments(input, axes=[1,2], keep_dims=True)\n",
    "        epsilon = 1e-5\n",
    "        inv = tf.rsqrt(variance + epsilon)\n",
    "        normalized = (input-mean)*inv\n",
    "        return scale*normalized + offset\n",
    "\n",
    "def l1_loss(x, y):\n",
    "    return tf.reduce_mean(tf.abs(x - y))\n",
    "\n",
    "def l2_loss(x, y):\n",
    "    return tf.reduce_mean(tf.square(x - y))\n",
    "\n",
    "def resize_nn(x, size):\n",
    "    return tf.image.resize_nearest_neighbor(x, size=(int(size), int(size)))\n",
    "\n",
    "def lrelu(x, leak=0.01, name='lrelu'): #lrelu(x, leak=0.2, name='lrelu'):\n",
    "    return tf.maximum(x, leak*x)\n",
    "\n",
    "def gradient_penalty(real, fake, f):\n",
    "        def interpolate(a, b):\n",
    "            shape = tf.concat((tf.shape(a)[0:1], tf.tile([1], [a.shape.ndims - 1])), axis=0)\n",
    "            alpha = tf.random_uniform(shape=shape, minval=0., maxval=1.)\n",
    "            inter = a + alpha * (b - a)\n",
    "            inter.set_shape(a.get_shape().as_list())\n",
    "            return inter\n",
    "\n",
    "        x = interpolate(real, fake)\n",
    "        pred, _ = f(x, reuse=True)\n",
    "        gradients = tf.gradients(pred, x)[0]\n",
    "        slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=3))\n",
    "        gp = tf.reduce_mean((slopes - 1.)**2)\n",
    "        return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class op_base:\n",
    "    def __init__(self, sess, project_name):\n",
    "        self.sess = sess\n",
    "\n",
    "        # Train\n",
    "        self.flag = True #args.flag\n",
    "        self.gpu_number = 0 #args.gpu_number\n",
    "        self.project = project_name #\"test_began\" #args.project\n",
    "\n",
    "        # Train Data\n",
    "        self.data_dir = \"./Face_data/Faces_with_expression_label/dataset_64x64\" #args.data_dir #./Data\n",
    "        self.dataset = \"expr\" #args.dataset  # celeba\n",
    "        self.data_size = 64 #args.data_size  # 64 or 128\n",
    "        self.data_opt = \"crop\" #args.data_opt  # raw or crop\n",
    "        self.data_label_vector_size = 7 #size of one-hot-encoded label vector\n",
    "\n",
    "        # Train Iteration\n",
    "        self.niter = 200 #50 #args.niter\n",
    "        self.niter_snapshot = 500 #args.nsnapshot\n",
    "        self.max_to_keep = 5 #args.max_to_keep\n",
    "\n",
    "        # Train Parameter\n",
    "        self.batch_size = 16 #args.batch_size\n",
    "        self.learning_rate = 1e-4 #args.learning_rate\n",
    "        self.mm = 0.5 #args.momentum\n",
    "        self.mm2 = 0.999 #args.momentum2\n",
    "        self.lamda = 0.001 #args.lamda\n",
    "        self.gamma = 0.5 #args.gamma\n",
    "        self.filter_number = 64 #args.filter_number\n",
    "        self.input_size = 64 #args.input_size\n",
    "        self.embedding = 128 #64 #args.embedding\n",
    "        \n",
    "        self.lambda_cls = 1.\n",
    "        self.lambda_recon = 10.\n",
    "        self.lambda_gp = 10.\n",
    "\n",
    "        \n",
    "\n",
    "        # Result Dir & File\n",
    "        self.project_dir = 'assets_ae/{0}_{1}_{2}_{3}/'.format(self.project, self.dataset, self.data_opt, self.data_size)\n",
    "        self.ckpt_dir = os.path.join(self.project_dir, 'models')\n",
    "        self.model_name = \"{0}.model\".format(self.project)\n",
    "        self.ckpt_model_name = os.path.join(self.ckpt_dir, self.model_name)\n",
    "\n",
    "        # etc.\n",
    "        if not os.path.exists('assets_ae'):\n",
    "            os.makedirs('assets_ae')\n",
    "        make_project_dir(self.project_dir)\n",
    "\n",
    "    def load(self, sess, saver, ckpt_dir):\n",
    "        ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, os.path.join(ckpt_dir, ckpt_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "class Operator(op_base):\n",
    "    def __init__(self, sess, project_name):\n",
    "        op_base.__init__(self, sess, project_name)\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Input placeholder\n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, self.data_size, self.data_size, 3], name='x')\n",
    "        self.x_c = tf.placeholder(tf.float32, shape=[None, self.data_label_vector_size], name='x_c')\n",
    "        self.target_c = tf.placeholder(tf.float32, shape=[None, self.data_label_vector_size], name='target_c')\n",
    "        self.alpha = tf.placeholder(tf.float32, shape=[None, 1], name='alpha')\n",
    "        self.lr = tf.placeholder(tf.float32, name='lr')\n",
    "\n",
    "        # Generator\n",
    "        self.G_f = self.generator(self.x, self.target_c)\n",
    "        self.G_recon = self.generator(self.G_f, self.x_c, reuse=True)\n",
    "        \n",
    "        self.G_test = self.generator(self.x, self.target_c, reuse=True)\n",
    "        \n",
    "        # Discriminator\n",
    "        self.D_f, self.D_f_cls = self.discriminator(self.G_f)\n",
    "        self.D_x, self.D_x_cls = self.discriminator(self.x, reuse=True)\n",
    "        \n",
    "        # Gradient Penalty\n",
    "        #self.gp = gradient_penalty(self.x, self.G_f, self.discriminator)\n",
    "        self.real_data = tf.reshape(self.x, [-1, self.data_size*self.data_size*3])\n",
    "        self.fake_data = tf.reshape(self.G_f, [-1, self.data_size*self.data_size*3])\n",
    "        self.diff = self.fake_data - self.real_data\n",
    "        self.interpolate = self.real_data + self.alpha*self.diff\n",
    "        \n",
    "        self.inter_reshape = tf.reshape(self.interpolate, [-1, self.data_size, self.data_size, 3])\n",
    "        self.G_inter, _ = self.discriminator(self.inter_reshape, reuse=True)\n",
    "        \n",
    "#         self.G_inter = tf.reshape(self.x, [-1, ])\n",
    "        \n",
    "#         self.G_inter = self.discriminator(self.interpolate, reuse=True)\n",
    "        self.grad = tf.gradients(self.G_inter, \n",
    "                                 xs=[self.inter_reshape])[0]\n",
    "        self.slopes = tf.sqrt(tf.reduce_sum(tf.square(self.grad), axis=[1,2,3]))\n",
    "        self.gp = tf.reduce_mean(tf.square(self.slopes - 1.))\n",
    "        \n",
    "        \n",
    "        # Wasserstein loss\n",
    "        self.wd = tf.reduce_mean(self.D_x) - tf.reduce_mean(self.D_f)\n",
    "        self.L_adv_D = -self.wd + self.gp * self.lambda_gp\n",
    "        self.L_adv_G = -tf.reduce_mean(self.D_f)\n",
    "        \n",
    "        self.L_D_cls = tf.reduce_mean(cross_entropy(labels=self.x_c, logits=self.D_x_cls))\n",
    "        self.L_G_cls = tf.reduce_mean(cross_entropy(labels=self.target_c, logits=self.D_f_cls))\n",
    "        self.L_G_recon = l1_loss(self.x, self.G_recon)\n",
    "                \n",
    "        self.L_D = self.L_adv_D + self.lambda_cls * self.L_D_cls\n",
    "        self.L_G = self.L_adv_G + self.lambda_cls * self.L_G_cls + self.lambda_recon * self.L_G_recon\n",
    "        \n",
    "        \n",
    "#         self.L_D_f = tf.reduce_mean(self.D_f)\n",
    "#         self.L_D_x = -tf.reduce_mean(self.D_x)\n",
    "#         self.L_D_cls = tf.reduce_mean(cross_entropy(labels=self.x_c, logits=self.D_x_cls)) \n",
    "        \n",
    "#         grad = tf.gradients(ys=self.D_inter, xs=[self.interpolate])[0]\n",
    "#         grad_l2 = tf.sqrt(tf.reduce_sum(tf.square(grad), axis=3))\n",
    "#         self.L_D_gp = tf.reduce_mean(tf.squared_difference(grad_l2, tf.ones_like(grad_l2)))\n",
    "#         self.L_D = self.L_D_x + self.L_D_f + self.lambda_gp * self.L_D_gp + self.lambda_cls * self.L_D_cls\n",
    "        \n",
    "#         self.L_G_f = -tf.reduce_mean(self.D_f)\n",
    "#         self.L_G_recon = l1_loss(self.x, self.G_recon)\n",
    "#         self.L_G_cls = tf.reduce_mean(cross_entropy(labels=self.target_c, logits=self.D_f_cls))\n",
    "#         self.L_G = self.L_G_f + self.lambda_cls * self.L_G_cls + self.lambda_recon * self.L_G_recon\n",
    "\n",
    "        # Variables\n",
    "        D_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"discriminator\")\n",
    "        G_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"generator\")\n",
    "\n",
    "        # Optimizer\n",
    "        self.opt_D = tf.train.AdamOptimizer(self.lr, self.mm).minimize(self.L_D, var_list=D_vars)\n",
    "        self.opt_G = tf.train.AdamOptimizer(self.lr, self.mm).minimize(self.L_G, var_list=G_vars)\n",
    "\n",
    "        # initializer\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # tf saver\n",
    "        self.saver = tf.train.Saver(max_to_keep=(self.max_to_keep))\n",
    "\n",
    "        try:\n",
    "            self.load(self.sess, self.saver, self.ckpt_dir)\n",
    "        except:\n",
    "            # save full graph\n",
    "            self.saver.save(self.sess, self.ckpt_model_name, write_meta_graph=True)\n",
    "\n",
    "        # Summary\n",
    "        if self.flag:\n",
    "            tf.summary.scalar('loss/d_loss', self.L_D)\n",
    "            tf.summary.scalar('loss/g_loss', self.L_G)\n",
    "            tf.summary.scalar('loss/d_loss_cls', self.L_D_cls)\n",
    "            tf.summary.scalar('loss/g_loss_recon', self.L_G_recon)\n",
    "            tf.summary.scalar('loss/g_loss_cls', self.L_G_cls)\n",
    "            tf.summary.scalar('loss/wd', self.wd)\n",
    "\n",
    "            self.merged = tf.summary.merge_all()\n",
    "            self.writer = tf.summary.FileWriter(self.project_dir, self.sess.graph)\n",
    "\n",
    "    def train(self, train_flag):\n",
    "        # load data\n",
    "        data_path = self.data_dir\n",
    "        #test_data_path = \"./Face_data/Faces_with_expression_label/dataset_64x64\" # expressions\n",
    "\n",
    "        if os.path.exists(data_path + '.npy'):\n",
    "            data = np.load(data_path + '.npy')\n",
    "        else:\n",
    "            data = sorted(glob.glob(os.path.join(data_path, \"*.*\")))\n",
    "            np.save(data_path + '.npy', data)\n",
    "            \n",
    "        print('Shuffle ....')\n",
    "        random_order = np.random.permutation(len(data))\n",
    "        data = [data[i] for i in random_order[:]]\n",
    "        print('Shuffle Done')\n",
    "\n",
    "        # initial parameter\n",
    "        start_time = time.time()\n",
    "        self.count = 0\n",
    "\n",
    "        for epoch in range(self.niter):\n",
    "            batch_idxs = len(data) // self.batch_size\n",
    "            lr = np.float32(self.learning_rate)\n",
    "            \n",
    "            # learning rate decay\n",
    "            if epoch >= self.niter / 2.0:\n",
    "                lr_decay = (self.niter - epoch) / (self.niter / 2.0)\n",
    "                lr = lr * lr_decay\n",
    "            \n",
    "            for idx in range(0, batch_idxs):\n",
    "                self.count += 1\n",
    "\n",
    "                # Flip the batch with 0.5 prob to increase training data\n",
    "                if random.uniform(0, 1) < 0.5:\n",
    "                    flip = True\n",
    "                else:\n",
    "                    flip = False\n",
    "                \n",
    "                batch_files = data[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "                batch_inputs = [get_image(batch_file[0], flip) for batch_file in batch_files]\n",
    "                batch_inputs_labels = [get_label(batch_file[0], self.data_label_vector_size) for batch_file in batch_files]\n",
    "                batch_target_labels = [get_label(batch_file[1], self.data_label_vector_size) for batch_file in batch_files]\n",
    "                batch_alpha = np.random.uniform(low=0., high=1.0, size=[self.batch_size, 1]).astype(np.float32)\n",
    "                                \n",
    "                # feed list \n",
    "                D_fetches = [self.opt_D, self.L_D, self.L_D_cls]\n",
    "                G_fetches = [self.opt_G, self.L_G, self.L_G_cls, self.L_G_recon, self.wd]\n",
    "                feed_dict = {self.x: batch_inputs, self.x_c: batch_inputs_labels, \n",
    "                             self.target_c: batch_target_labels, \n",
    "                             self.alpha: batch_alpha,\n",
    "                             self.lr: lr}\n",
    "                \n",
    "\n",
    "                # run tensorflow\n",
    "                for i in range(5):\n",
    "                    _, d_loss, d_loss_cls = self.sess.run(D_fetches, feed_dict=feed_dict)\n",
    "                    \n",
    "                _, g_loss, g_loss_cls, g_loss_recon, wd = self.sess.run(G_fetches, feed_dict=feed_dict)\n",
    "                  \n",
    "                if self.count % 100 == 1:\n",
    "                    print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, \"\n",
    "                          \"d_loss: %.6f, d_loss_cls: %.6f, g_loss: %.6f, g_loss_cls: %.6f, g_loss_recon: %.6f, \"\n",
    "                          \"wd: %.6f\"\n",
    "                          % (epoch, idx, batch_idxs, time.time() - start_time,\n",
    "                             d_loss, d_loss_cls, g_loss, g_loss_cls, g_loss_recon, wd))\n",
    "\n",
    "                # write train summary\n",
    "                summary = self.sess.run(self.merged, feed_dict=feed_dict)\n",
    "                self.writer.add_summary(summary, self.count)\n",
    "\n",
    "                # Test during Training\n",
    "                if self.count % self.niter_snapshot == (self.niter_snapshot - 1):\n",
    "                    # save & test\n",
    "                    self.saver.save(self.sess, self.ckpt_model_name, global_step=self.count, write_meta_graph=False)\n",
    "                    self.test_expr(train_flag)\n",
    "                    self.test_celebra(train_flag)\n",
    "\n",
    "    def test_celebra(self, train_flag=True):\n",
    "        print('Test Sample Generation...')\n",
    "        # generate output\n",
    "        img_num = 8*8\n",
    "        output_f = int(np.sqrt(img_num))\n",
    "        in_img_num = output_f\n",
    "        img_size = self.data_size\n",
    "        gen_img_num = img_num - output_f\n",
    "        label_size = self.data_label_vector_size\n",
    "        \n",
    "        # load data test\n",
    "        data_path = \"./Face_data/Celeba/dataset_64x64\" # expressions\n",
    "\n",
    "        if os.path.exists(data_path + '.npy'):\n",
    "            data = np.load(data_path + '.npy')\n",
    "        else:\n",
    "            data = sorted(glob.glob(os.path.join(data_path, \"*.*\")))\n",
    "            np.save(data_path + '.npy', data)\n",
    "\n",
    "        # shuffle test data\n",
    "        random_order = np.random.permutation(len(data))\n",
    "        data = [data[i] for i in random_order[:]]\n",
    "\n",
    "        im_output_gen = np.zeros([img_size * output_f, img_size * output_f, 3])\n",
    "\n",
    "        test_files = data[0: output_f]\n",
    "        test_data = [get_image(test_file) for test_file in test_files]\n",
    "        test_data = np.repeat(test_data, [label_size]*in_img_num, axis=0)\n",
    "        test_data_o = [scm.imread(test_file) for test_file in test_files]\n",
    "        \n",
    "        # get one-hot labels\n",
    "        int_labels = list(range(label_size))\n",
    "        one_hot = np.zeros((label_size, label_size))\n",
    "        one_hot[np.arange(label_size), int_labels] = 1\n",
    "        target_labels = np.tile(one_hot, (output_f, 1))\n",
    "        \n",
    "        \n",
    "        output_gen = (self.sess.run(self.G_test, feed_dict={self.x: test_data, \n",
    "                                                            self.target_c: target_labels}))  # generator output\n",
    "\n",
    "        output_gen = [inverse_image(output_gen[i]) for i in range(gen_img_num)]\n",
    "\n",
    "        for i in range(output_f):\n",
    "            for j in range(output_f):\n",
    "                if j == 0:\n",
    "                    im_output_gen[i * img_size:(i + 1) * img_size, j * img_size:(j + 1) * img_size, :] \\\n",
    "                        = test_data_o[i]\n",
    "                else:\n",
    "                    im_output_gen[i * img_size:(i + 1) * img_size, j * img_size:(j + 1) * img_size, :] \\\n",
    "                        = output_gen[(j-1) + (i * int(output_f-1))]\n",
    "\n",
    "        # output save\n",
    "        scm.imsave(self.project_dir + '/result/' + str(self.count) + '_celebra_output.bmp', im_output_gen)\n",
    "        \n",
    "    def test_expr(self, train_flag=True):\n",
    "        print('Train Sample Generation...')\n",
    "        # generate output\n",
    "        img_num =  36 #self.batch_size\n",
    "        display_img_num = int(img_num / 3)\n",
    "        img_size = self.data_size\n",
    "\n",
    "        output_f = int(np.sqrt(img_num))\n",
    "        im_output_gen = np.zeros([img_size * output_f, img_size * output_f, 3])\n",
    "        \n",
    "        # load data\n",
    "        data_path = self.data_dir\n",
    "\n",
    "        if os.path.exists(data_path + '.npy'):\n",
    "            data = np.load(data_path + '.npy')\n",
    "        else:\n",
    "            data = sorted(glob.glob(os.path.join(data_path, \"*.*\")))\n",
    "            data = pair_expressions(data)\n",
    "            np.save(data_path + '.npy', data)\n",
    "\n",
    "        # Test data shuffle\n",
    "        random_order = np.random.permutation(len(data))\n",
    "        data = [data[i] for i in random_order[:]]\n",
    "        \n",
    "        batch_files = data[0: display_img_num]\n",
    "        test_inputs = [get_image(batch_file[0]) for batch_file in batch_files]\n",
    "        test_inputs_o = [scm.imread((batch_file[0])) for batch_file in batch_files]\n",
    "        test_targets = [scm.imread((batch_file[1])) for batch_file in batch_files]\n",
    "        test_target_labels = [get_label(batch_file[1], self.data_label_vector_size) for batch_file in batch_files]\n",
    "\n",
    "        output_gen = (self.sess.run(self.G_test, feed_dict={self.x: test_inputs, \n",
    "                                                            self.target_c: test_target_labels}))  # generator output\n",
    "\n",
    "        output_gen = [inverse_image(output_gen[i]) for i in range(display_img_num)]\n",
    "\n",
    "        for i in range(output_f): # row\n",
    "            for j in range(output_f): # col\n",
    "                if j % 3 == 0: # input img\n",
    "                    im_output_gen[i * img_size:(i + 1) * img_size, j * img_size:(j + 1) * img_size, :] \\\n",
    "                        = test_inputs_o[int(j / 3) + (i * int(output_f / 3))]\n",
    "                elif j % 3 == 1: # output img\n",
    "                    im_output_gen[i * img_size:(i + 1) * img_size, j * img_size:(j + 1) * img_size, :] \\\n",
    "                        = output_gen[int(j / 3) + (i * int(output_f / 3))]\n",
    "                else: # target img\n",
    "                    im_output_gen[i * img_size:(i + 1) * img_size, j * img_size:(j + 1) * img_size, :] \\\n",
    "                        = test_targets[int(j / 3) + (i * int(output_f / 3))]\n",
    "                   \n",
    "\n",
    "        labels = np.argmax(test_target_labels, axis=1)\n",
    "        label_string = ''.join(str(int(l)) for l in labels)\n",
    "        # output save\n",
    "        scm.imsave(self.project_dir + '/result/' + str(self.count) + '_' + label_string \n",
    "                   + '_expr_output.bmp', im_output_gen)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StarGAN(Operator):\n",
    "    def __init__(self, sess, project_name):\n",
    "        Operator.__init__(self, sess, project_name)\n",
    "\n",
    "\n",
    "    def generator(self, x, c, reuse=None):\n",
    "        with tf.variable_scope('generator') as scope:\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "\n",
    "            f = 64\n",
    "            image_size = self.data_size\n",
    "            c_num = self.data_label_vector_size\n",
    "            p = \"SAME\"\n",
    "\n",
    "            x = tf.concat([x, tf.tile(tf.reshape(c, [-1, 1, 1, get_shape_c(c)[-1]]),\\\n",
    "                                      [1, x.get_shape().as_list()[1], x.get_shape().as_list()[2], 1])],\\\n",
    "                          axis=3)\n",
    "            \n",
    "            # Down-sampling\n",
    "            x = conv(x, [7, 7, 3+c_num, f], stride=1, padding=p, name='ds_1')\n",
    "            x = instance_norm(x, 'in_ds_1')\n",
    "            x = tf.nn.relu(x)\n",
    "            x = conv(x, [4, 4, f, f*2], stride=2, padding=p, name='ds_2')\n",
    "            x = instance_norm(x, 'in_ds_2')\n",
    "            x = tf.nn.relu(x)\n",
    "            x = conv(x, [4, 4, f*2, f*4], stride=2, padding=p, name='ds_3')\n",
    "            x = instance_norm(x, 'in_ds_3')\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            # Bottleneck\n",
    "            x_r = conv(x, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_1a')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_1a')\n",
    "            x_r = tf.nn.relu(x_r)\n",
    "            x_r = conv(x_r, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_1b')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_1b')\n",
    "            x = x + x_r\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            x_r = conv(x, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_2a')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_2a')\n",
    "            x_r = tf.nn.relu(x_r)\n",
    "            x_r = conv(x_r, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_2b')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_2b')\n",
    "            x = x + x_r\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            x_r = conv(x, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_3a')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_3a')\n",
    "            x_r = tf.nn.relu(x_r)\n",
    "            x_r = conv(x_r, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_3b')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_3b')\n",
    "            x = x + x_r\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            x_r = conv(x, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_4a')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_4a')\n",
    "            x_r = tf.nn.relu(x_r)\n",
    "            x_r = conv(x_r, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_4b')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_4b')\n",
    "            x = x + x_r\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            x_r = conv(x, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_5a')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_5a')\n",
    "            x_r = tf.nn.relu(x_r)\n",
    "            x_r = conv(x_r, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_5b')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_5b')\n",
    "            x = x + x_r\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            x_r = conv(x, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_6a')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_6a')\n",
    "            x_r = tf.nn.relu(x_r)\n",
    "            x_r = conv(x_r, [3, 3, f*4, f*4], stride=1, padding=p, name='bneck_6b')\n",
    "            x_r = instance_norm(x_r, 'in_bneck_6b')\n",
    "            x = x + x_r\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "            # Up-sampling\n",
    "            x = deconv(x, [4, 4, f*4, f*2], stride=2, padding=p, name='us_1')\n",
    "            x = instance_norm(x, 'in_us_1')\n",
    "            x = tf.nn.relu(x)\n",
    "            x = deconv(x, [4, 4, f*2, f], stride=2, padding=p, name='us_2')\n",
    "            x = instance_norm(x, 'in_us_2')\n",
    "            x = tf.nn.relu(x)\n",
    "            x = conv(x, [7, 7, f, 3], stride=1, padding=p, name='us_3')\n",
    "\n",
    "            x = tf.nn.tanh(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def discriminator(self, x, reuse=None):\n",
    "        with tf.variable_scope('discriminator') as scope:\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "\n",
    "            f = 64\n",
    "            f_max = f*8\n",
    "            image_size = self.data_size\n",
    "            k_size = int(image_size / np.power(2, 5))            \n",
    "            c_num = self.data_label_vector_size\n",
    "            p = \"SAME\"\n",
    "            \n",
    "            x = conv(x, [4, 4, 3, f], stride=2, padding=p, name='conv_1')\n",
    "            x = lrelu(x)\n",
    "            x = conv(x, [4, 4, f, f*2], stride=2, padding=p, name='conv_2')\n",
    "            x = lrelu(x)\n",
    "            x = conv(x, [4, 4, f*2, f*4], stride=2, padding=p, name='conv_3')\n",
    "            x = lrelu(x)\n",
    "            x = conv(x, [4, 4, f*4, f*8], stride=2, padding=p, name='conv_4')\n",
    "            x = lrelu(x)\n",
    "            x = conv(x, [4, 4, f*8, f*16], stride=2, padding=p, name='conv_5')\n",
    "            x = lrelu(x)\n",
    "            \n",
    "            if image_size == 128:\n",
    "                x = conv(x, [4, 4, f*16, f*32], stride=2, padding=p, name='conv_6')\n",
    "                x = lrelu(x)\n",
    "                f_max = f_max * 2\n",
    "                k_size = int(k_size / 2)\n",
    "                \n",
    "            out_src = conv(x, [3, 3, f_max, 1], stride=1, padding=p, name='conv_out_src')\n",
    "            out_cls = conv(x, [k_size, k_size, f_max, c_num], stride=1, name='conv_out_cls')\n",
    "        \n",
    "        return out_src, tf.squeeze(out_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle ....\n",
      "Shuffle Done\n",
      "Epoch: [ 0] [   0/ 633] time: 1.6636, d_loss: 9.216977, d_loss_cls: 0.677631, g_loss: 6.748394, g_loss_cls: 0.685549, g_loss_recon: 0.603723, wd: 0.238556\n",
      "Epoch: [ 0] [ 100/ 633] time: 69.5239, d_loss: -3.223270, d_loss_cls: 0.326211, g_loss: -1.857672, g_loss_cls: 0.446668, g_loss_recon: 0.223447, wd: 4.101604\n",
      "Epoch: [ 0] [ 200/ 633] time: 138.2426, d_loss: -1.324638, d_loss_cls: 0.228790, g_loss: -6.735639, g_loss_cls: 0.446470, g_loss_recon: 0.171162, wd: 1.742344\n",
      "Epoch: [ 0] [ 300/ 633] time: 208.0725, d_loss: -1.905260, d_loss_cls: 0.233375, g_loss: 1.875639, g_loss_cls: 0.506886, g_loss_recon: 0.178054, wd: 2.684456\n",
      "Epoch: [ 0] [ 400/ 633] time: 278.3170, d_loss: -2.144655, d_loss_cls: 0.187462, g_loss: -3.451761, g_loss_cls: 0.388351, g_loss_recon: 0.149240, wd: 2.638731\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 0] [ 500/ 633] time: 349.7861, d_loss: -1.948005, d_loss_cls: 0.216839, g_loss: -2.537516, g_loss_cls: 0.294575, g_loss_recon: 0.133941, wd: 2.401826\n",
      "Epoch: [ 0] [ 600/ 633] time: 420.8180, d_loss: -1.689743, d_loss_cls: 0.124443, g_loss: -2.381270, g_loss_cls: 0.300647, g_loss_recon: 0.141424, wd: 2.221983\n",
      "Epoch: [ 1] [  67/ 633] time: 492.0189, d_loss: -1.316411, d_loss_cls: 0.126041, g_loss: -0.806007, g_loss_cls: 0.217856, g_loss_recon: 0.121386, wd: 1.625805\n",
      "Epoch: [ 1] [ 167/ 633] time: 563.2766, d_loss: -2.317788, d_loss_cls: 0.100946, g_loss: -2.299850, g_loss_cls: 0.168759, g_loss_recon: 0.148682, wd: 2.859284\n",
      "Epoch: [ 1] [ 267/ 633] time: 634.5823, d_loss: -1.830505, d_loss_cls: 0.061082, g_loss: -3.413829, g_loss_cls: 0.192338, g_loss_recon: 0.134715, wd: 2.103577\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 1] [ 367/ 633] time: 706.2398, d_loss: -1.166726, d_loss_cls: 0.088191, g_loss: -2.350800, g_loss_cls: 0.084508, g_loss_recon: 0.109696, wd: 1.531378\n",
      "Epoch: [ 1] [ 467/ 633] time: 777.5135, d_loss: -1.891993, d_loss_cls: 0.028761, g_loss: -2.622805, g_loss_cls: 0.177549, g_loss_recon: 0.121262, wd: 2.172071\n",
      "Epoch: [ 1] [ 567/ 633] time: 848.8110, d_loss: -1.379370, d_loss_cls: 0.066298, g_loss: -1.778954, g_loss_cls: 0.200022, g_loss_recon: 0.113626, wd: 1.624379\n",
      "Epoch: [ 2] [  34/ 633] time: 920.0877, d_loss: -1.423218, d_loss_cls: 0.031860, g_loss: -1.433549, g_loss_cls: 0.060982, g_loss_recon: 0.105018, wd: 1.649719\n",
      "Epoch: [ 2] [ 134/ 633] time: 991.3661, d_loss: -1.040762, d_loss_cls: 0.063355, g_loss: -1.097006, g_loss_cls: 0.038899, g_loss_recon: 0.092587, wd: 1.218214\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 2] [ 234/ 633] time: 1063.0055, d_loss: -1.303136, d_loss_cls: 0.023274, g_loss: -2.537207, g_loss_cls: 0.152369, g_loss_recon: 0.113333, wd: 1.504748\n",
      "Epoch: [ 2] [ 334/ 633] time: 1134.2734, d_loss: -1.160817, d_loss_cls: 0.013067, g_loss: -2.186688, g_loss_cls: 0.041503, g_loss_recon: 0.079932, wd: 1.262394\n",
      "Epoch: [ 2] [ 434/ 633] time: 1205.5607, d_loss: -1.187571, d_loss_cls: 0.023914, g_loss: -1.491286, g_loss_cls: 0.116321, g_loss_recon: 0.095715, wd: 1.343419\n",
      "Epoch: [ 2] [ 534/ 633] time: 1276.8614, d_loss: -1.055177, d_loss_cls: 0.016552, g_loss: -1.873234, g_loss_cls: 0.048872, g_loss_recon: 0.090007, wd: 1.165674\n",
      "Epoch: [ 3] [   1/ 633] time: 1348.1631, d_loss: -1.175762, d_loss_cls: 0.014379, g_loss: -0.433082, g_loss_cls: 0.049013, g_loss_recon: 0.083274, wd: 1.307768\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 3] [ 101/ 633] time: 1419.8527, d_loss: -1.087704, d_loss_cls: 0.010125, g_loss: -1.668159, g_loss_cls: 0.035109, g_loss_recon: 0.086302, wd: 1.212727\n",
      "Epoch: [ 3] [ 201/ 633] time: 1491.1258, d_loss: -0.941008, d_loss_cls: 0.006610, g_loss: -0.939045, g_loss_cls: 0.105007, g_loss_recon: 0.082328, wd: 1.033340\n",
      "Epoch: [ 3] [ 301/ 633] time: 1562.4241, d_loss: -1.057787, d_loss_cls: 0.004957, g_loss: -0.693314, g_loss_cls: 0.040018, g_loss_recon: 0.081187, wd: 1.147769\n",
      "Epoch: [ 3] [ 401/ 633] time: 1633.5991, d_loss: -1.188786, d_loss_cls: 0.006262, g_loss: -0.518545, g_loss_cls: 0.051313, g_loss_recon: 0.080063, wd: 1.302777\n",
      "Epoch: [ 3] [ 501/ 633] time: 1704.9246, d_loss: -1.031874, d_loss_cls: 0.008926, g_loss: -0.414031, g_loss_cls: 0.026926, g_loss_recon: 0.086577, wd: 1.127705\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 3] [ 601/ 633] time: 1776.6370, d_loss: -0.974935, d_loss_cls: 0.006341, g_loss: -1.198565, g_loss_cls: 0.021512, g_loss_recon: 0.078555, wd: 1.079235\n",
      "Epoch: [ 4] [  68/ 633] time: 1847.9575, d_loss: -0.907191, d_loss_cls: 0.004892, g_loss: -0.948219, g_loss_cls: 0.033759, g_loss_recon: 0.078446, wd: 0.982327\n",
      "Epoch: [ 4] [ 168/ 633] time: 1919.2990, d_loss: -0.938137, d_loss_cls: 0.003750, g_loss: -0.799521, g_loss_cls: 0.012385, g_loss_recon: 0.081140, wd: 1.039071\n",
      "Epoch: [ 4] [ 268/ 633] time: 1990.5718, d_loss: -0.829455, d_loss_cls: 0.009396, g_loss: -0.309262, g_loss_cls: 0.088613, g_loss_recon: 0.073872, wd: 0.922854\n",
      "Epoch: [ 4] [ 368/ 633] time: 2061.8845, d_loss: -0.888861, d_loss_cls: 0.005224, g_loss: -0.518769, g_loss_cls: 0.035276, g_loss_recon: 0.078286, wd: 0.986006\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 4] [ 468/ 633] time: 2133.6092, d_loss: -0.933026, d_loss_cls: 0.001550, g_loss: -0.320956, g_loss_cls: 0.022878, g_loss_recon: 0.073741, wd: 1.007837\n",
      "Epoch: [ 4] [ 568/ 633] time: 2204.9220, d_loss: -1.020139, d_loss_cls: 0.001866, g_loss: 0.335590, g_loss_cls: 0.053277, g_loss_recon: 0.086442, wd: 1.135666\n",
      "Epoch: [ 5] [  35/ 633] time: 2276.2644, d_loss: -0.943710, d_loss_cls: 0.001606, g_loss: 0.612742, g_loss_cls: 0.027586, g_loss_recon: 0.083937, wd: 1.035742\n",
      "Epoch: [ 5] [ 135/ 633] time: 2347.5493, d_loss: -0.849962, d_loss_cls: 0.002589, g_loss: 0.462655, g_loss_cls: 0.061191, g_loss_recon: 0.069355, wd: 0.949628\n",
      "Epoch: [ 5] [ 235/ 633] time: 2418.8372, d_loss: -1.061820, d_loss_cls: 0.002762, g_loss: -0.392818, g_loss_cls: 0.042450, g_loss_recon: 0.088413, wd: 1.175347\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 5] [ 335/ 633] time: 2490.5774, d_loss: -0.951269, d_loss_cls: 0.003693, g_loss: -0.115938, g_loss_cls: 0.057415, g_loss_recon: 0.075764, wd: 1.032515\n",
      "Epoch: [ 5] [ 435/ 633] time: 2561.8918, d_loss: -0.829221, d_loss_cls: 0.001413, g_loss: 0.574154, g_loss_cls: 0.031186, g_loss_recon: 0.065441, wd: 0.893159\n",
      "Epoch: [ 5] [ 535/ 633] time: 2633.2052, d_loss: -1.005095, d_loss_cls: 0.001617, g_loss: 0.558498, g_loss_cls: 0.020268, g_loss_recon: 0.087753, wd: 1.132656\n",
      "Epoch: [ 6] [   2/ 633] time: 2704.5300, d_loss: -0.820293, d_loss_cls: 0.001865, g_loss: 0.360134, g_loss_cls: 0.130607, g_loss_recon: 0.073157, wd: 0.911908\n",
      "Epoch: [ 6] [ 102/ 633] time: 2775.8549, d_loss: -0.912131, d_loss_cls: 0.001044, g_loss: 0.057079, g_loss_cls: 0.006344, g_loss_recon: 0.077805, wd: 0.993336\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 6] [ 202/ 633] time: 2847.6069, d_loss: -0.848299, d_loss_cls: 0.001763, g_loss: 0.642053, g_loss_cls: 0.207227, g_loss_recon: 0.080564, wd: 0.916466\n",
      "Epoch: [ 6] [ 302/ 633] time: 2918.9326, d_loss: -0.837460, d_loss_cls: 0.001576, g_loss: 0.160966, g_loss_cls: 0.054636, g_loss_recon: 0.070638, wd: 0.921901\n",
      "Epoch: [ 6] [ 402/ 633] time: 2990.2788, d_loss: -0.792311, d_loss_cls: 0.002123, g_loss: 0.124619, g_loss_cls: 0.007177, g_loss_recon: 0.072189, wd: 0.876109\n",
      "Epoch: [ 6] [ 502/ 633] time: 3061.5969, d_loss: -0.804265, d_loss_cls: 0.001304, g_loss: 0.723224, g_loss_cls: 0.115047, g_loss_recon: 0.080191, wd: 0.884291\n",
      "Epoch: [ 6] [ 602/ 633] time: 3132.9197, d_loss: -0.816150, d_loss_cls: 0.002103, g_loss: 0.151275, g_loss_cls: 0.017616, g_loss_recon: 0.071240, wd: 0.893839\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 7] [  69/ 633] time: 3204.6525, d_loss: -0.764983, d_loss_cls: 0.001346, g_loss: 0.319204, g_loss_cls: 0.027463, g_loss_recon: 0.071143, wd: 0.827741\n",
      "Epoch: [ 7] [ 169/ 633] time: 3275.9707, d_loss: -0.799672, d_loss_cls: 0.002034, g_loss: 0.096527, g_loss_cls: 0.018916, g_loss_recon: 0.065829, wd: 0.858746\n",
      "Epoch: [ 7] [ 269/ 633] time: 3347.2692, d_loss: -0.721024, d_loss_cls: 0.001222, g_loss: 0.292334, g_loss_cls: 0.019959, g_loss_recon: 0.072342, wd: 0.802158\n",
      "Epoch: [ 7] [ 369/ 633] time: 3418.5874, d_loss: -0.828805, d_loss_cls: 0.001667, g_loss: 0.034230, g_loss_cls: 0.023021, g_loss_recon: 0.068960, wd: 0.884762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 7] [ 469/ 633] time: 3489.8782, d_loss: -0.751620, d_loss_cls: 0.000721, g_loss: 0.075063, g_loss_cls: 0.007105, g_loss_recon: 0.065785, wd: 0.812229\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 7] [ 569/ 633] time: 3561.6275, d_loss: -0.663467, d_loss_cls: 0.003339, g_loss: 0.573195, g_loss_cls: 0.037032, g_loss_recon: 0.061590, wd: 0.730252\n",
      "Epoch: [ 8] [  36/ 633] time: 3633.0089, d_loss: -0.778060, d_loss_cls: 0.001247, g_loss: 0.216340, g_loss_cls: 0.022349, g_loss_recon: 0.062511, wd: 0.840270\n",
      "Epoch: [ 8] [ 136/ 633] time: 3704.3671, d_loss: -0.794903, d_loss_cls: 0.000813, g_loss: 0.236769, g_loss_cls: 0.096726, g_loss_recon: 0.083524, wd: 0.870831\n",
      "Epoch: [ 8] [ 236/ 633] time: 3775.7089, d_loss: -0.750074, d_loss_cls: 0.001045, g_loss: 0.016070, g_loss_cls: 0.138480, g_loss_recon: 0.064118, wd: 0.828074\n",
      "Epoch: [ 8] [ 336/ 633] time: 3847.0479, d_loss: -0.796430, d_loss_cls: 0.001051, g_loss: 0.177955, g_loss_cls: 0.065712, g_loss_recon: 0.070919, wd: 0.866824\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 8] [ 436/ 633] time: 3918.7944, d_loss: -0.692104, d_loss_cls: 0.001117, g_loss: 0.084876, g_loss_cls: 0.059217, g_loss_recon: 0.063948, wd: 0.743935\n",
      "Epoch: [ 8] [ 536/ 633] time: 3990.1282, d_loss: -0.808745, d_loss_cls: 0.000325, g_loss: 0.469624, g_loss_cls: 0.014197, g_loss_recon: 0.063648, wd: 0.899616\n",
      "Epoch: [ 9] [   3/ 633] time: 4061.4477, d_loss: -0.716111, d_loss_cls: 0.000778, g_loss: 0.246767, g_loss_cls: 0.011190, g_loss_recon: 0.069006, wd: 0.794283\n",
      "Epoch: [ 9] [ 103/ 633] time: 4132.7724, d_loss: -0.835710, d_loss_cls: 0.001446, g_loss: 0.380499, g_loss_cls: 0.030343, g_loss_recon: 0.068034, wd: 0.917801\n",
      "Epoch: [ 9] [ 203/ 633] time: 4204.1031, d_loss: -0.905955, d_loss_cls: 0.000301, g_loss: 0.465937, g_loss_cls: 0.007486, g_loss_recon: 0.076033, wd: 0.998951\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [ 9] [ 303/ 633] time: 4275.8183, d_loss: -0.893346, d_loss_cls: 0.000927, g_loss: -0.103621, g_loss_cls: 0.035952, g_loss_recon: 0.070939, wd: 0.975202\n",
      "Epoch: [ 9] [ 403/ 633] time: 4347.1413, d_loss: -0.690498, d_loss_cls: 0.000847, g_loss: 0.222266, g_loss_cls: 0.016934, g_loss_recon: 0.064254, wd: 0.752964\n",
      "Epoch: [ 9] [ 503/ 633] time: 4418.4550, d_loss: -0.746704, d_loss_cls: 0.001192, g_loss: 0.497898, g_loss_cls: 0.280059, g_loss_recon: 0.073120, wd: 0.829450\n",
      "Epoch: [ 9] [ 603/ 633] time: 4489.7860, d_loss: -0.742188, d_loss_cls: 0.000571, g_loss: 0.313683, g_loss_cls: 0.041948, g_loss_recon: 0.064251, wd: 0.819487\n",
      "Epoch: [10] [  70/ 633] time: 4561.0913, d_loss: -0.965815, d_loss_cls: 0.000165, g_loss: 0.329786, g_loss_cls: 0.069693, g_loss_recon: 0.071309, wd: 1.054094\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [10] [ 170/ 633] time: 4632.8376, d_loss: -0.695405, d_loss_cls: 0.001981, g_loss: 0.231505, g_loss_cls: 0.005644, g_loss_recon: 0.062902, wd: 0.754216\n",
      "Epoch: [10] [ 270/ 633] time: 4704.1632, d_loss: -0.856218, d_loss_cls: 0.000610, g_loss: 0.911417, g_loss_cls: 0.074168, g_loss_recon: 0.076122, wd: 0.926022\n",
      "Epoch: [10] [ 370/ 633] time: 4775.5104, d_loss: -0.780718, d_loss_cls: 0.000479, g_loss: 0.169110, g_loss_cls: 0.035392, g_loss_recon: 0.062417, wd: 0.860871\n",
      "Epoch: [10] [ 470/ 633] time: 4846.8363, d_loss: -0.708946, d_loss_cls: 0.000436, g_loss: -0.053165, g_loss_cls: 0.032654, g_loss_recon: 0.065315, wd: 0.779209\n",
      "Epoch: [10] [ 570/ 633] time: 4918.1540, d_loss: -0.668246, d_loss_cls: 0.000609, g_loss: 0.304162, g_loss_cls: 0.016082, g_loss_recon: 0.064029, wd: 0.728917\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [11] [  37/ 633] time: 4989.8893, d_loss: -0.876803, d_loss_cls: 0.000545, g_loss: 0.150567, g_loss_cls: 0.147186, g_loss_recon: 0.064094, wd: 0.951588\n",
      "Epoch: [11] [ 137/ 633] time: 5061.2085, d_loss: -0.738221, d_loss_cls: 0.000068, g_loss: 0.282934, g_loss_cls: 0.027475, g_loss_recon: 0.063851, wd: 0.808743\n",
      "Epoch: [11] [ 237/ 633] time: 5132.4999, d_loss: -0.529825, d_loss_cls: 0.000390, g_loss: -0.031034, g_loss_cls: 0.025192, g_loss_recon: 0.055967, wd: 0.583895\n",
      "Epoch: [11] [ 337/ 633] time: 5203.8009, d_loss: -0.771635, d_loss_cls: 0.002557, g_loss: 0.111620, g_loss_cls: 0.011888, g_loss_recon: 0.069827, wd: 0.847918\n",
      "Epoch: [11] [ 437/ 633] time: 5275.1216, d_loss: -0.812637, d_loss_cls: 0.000534, g_loss: 0.898321, g_loss_cls: 0.095863, g_loss_recon: 0.074004, wd: 0.891345\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [11] [ 537/ 633] time: 5346.8407, d_loss: -0.653469, d_loss_cls: 0.000712, g_loss: 0.040904, g_loss_cls: 0.034805, g_loss_recon: 0.061642, wd: 0.715458\n",
      "Epoch: [12] [   4/ 633] time: 5418.1381, d_loss: -0.798369, d_loss_cls: 0.000412, g_loss: 0.449216, g_loss_cls: 0.041802, g_loss_recon: 0.059617, wd: 0.857385\n",
      "Epoch: [12] [ 104/ 633] time: 5489.4679, d_loss: -0.554782, d_loss_cls: 0.000612, g_loss: 0.525142, g_loss_cls: 0.065880, g_loss_recon: 0.055956, wd: 0.626413\n",
      "Epoch: [12] [ 204/ 633] time: 5560.8178, d_loss: -0.674157, d_loss_cls: 0.000722, g_loss: 0.341646, g_loss_cls: 0.063071, g_loss_recon: 0.058625, wd: 0.710374\n",
      "Epoch: [12] [ 304/ 633] time: 5632.1260, d_loss: -0.742030, d_loss_cls: 0.000304, g_loss: 0.143157, g_loss_cls: 0.040339, g_loss_recon: 0.066349, wd: 0.834979\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [12] [ 404/ 633] time: 5703.8472, d_loss: -0.728249, d_loss_cls: 0.000741, g_loss: 0.358802, g_loss_cls: 0.038089, g_loss_recon: 0.059249, wd: 0.780070\n",
      "Epoch: [12] [ 504/ 633] time: 5775.1667, d_loss: -0.696259, d_loss_cls: 0.000425, g_loss: 0.345169, g_loss_cls: 0.051866, g_loss_recon: 0.065403, wd: 0.761904\n",
      "Epoch: [12] [ 604/ 633] time: 5846.4983, d_loss: -0.720669, d_loss_cls: 0.000614, g_loss: 0.134114, g_loss_cls: 0.010365, g_loss_recon: 0.061646, wd: 0.783358\n",
      "Epoch: [13] [  71/ 633] time: 5917.8322, d_loss: -0.652891, d_loss_cls: 0.001046, g_loss: 0.240617, g_loss_cls: 0.120421, g_loss_recon: 0.059040, wd: 0.731770\n",
      "Epoch: [13] [ 171/ 633] time: 5989.1683, d_loss: -0.605098, d_loss_cls: 0.000745, g_loss: 0.444438, g_loss_cls: 0.047591, g_loss_recon: 0.059519, wd: 0.661587\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [13] [ 271/ 633] time: 6060.8820, d_loss: -0.677687, d_loss_cls: 0.000755, g_loss: 0.690353, g_loss_cls: 0.189734, g_loss_recon: 0.066033, wd: 0.794370\n",
      "Epoch: [13] [ 371/ 633] time: 6132.2179, d_loss: -0.713819, d_loss_cls: 0.000830, g_loss: 0.416932, g_loss_cls: 0.028757, g_loss_recon: 0.052488, wd: 0.760108\n",
      "Epoch: [13] [ 471/ 633] time: 6203.5389, d_loss: -0.657048, d_loss_cls: 0.001119, g_loss: 0.402068, g_loss_cls: 0.014240, g_loss_recon: 0.056203, wd: 0.708730\n",
      "Epoch: [13] [ 571/ 633] time: 6274.8659, d_loss: -0.593707, d_loss_cls: 0.000660, g_loss: 0.171394, g_loss_cls: 0.007568, g_loss_recon: 0.056230, wd: 0.640918\n",
      "Epoch: [14] [  38/ 633] time: 6346.1727, d_loss: -0.803062, d_loss_cls: 0.009397, g_loss: 0.327743, g_loss_cls: 0.080376, g_loss_recon: 0.059859, wd: 0.892461\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [14] [ 138/ 633] time: 6417.8853, d_loss: -0.715099, d_loss_cls: 0.000268, g_loss: 0.512045, g_loss_cls: 0.052239, g_loss_recon: 0.060771, wd: 0.764580\n",
      "Epoch: [14] [ 238/ 633] time: 6489.1703, d_loss: -0.869247, d_loss_cls: 0.000633, g_loss: 0.483160, g_loss_cls: 0.039452, g_loss_recon: 0.063170, wd: 0.956417\n",
      "Epoch: [14] [ 338/ 633] time: 6560.4973, d_loss: -0.790167, d_loss_cls: 0.000653, g_loss: 0.261973, g_loss_cls: 0.087567, g_loss_recon: 0.060072, wd: 0.862826\n",
      "Epoch: [14] [ 438/ 633] time: 6631.8010, d_loss: -0.670143, d_loss_cls: 0.000512, g_loss: 0.695811, g_loss_cls: 0.038311, g_loss_recon: 0.058765, wd: 0.731721\n",
      "Epoch: [14] [ 538/ 633] time: 6703.1207, d_loss: -0.757187, d_loss_cls: 0.000436, g_loss: 0.594929, g_loss_cls: 0.010714, g_loss_recon: 0.059096, wd: 0.829054\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [15] [   5/ 633] time: 6774.8435, d_loss: -0.604061, d_loss_cls: 0.000287, g_loss: 0.152911, g_loss_cls: 0.027018, g_loss_recon: 0.058018, wd: 0.662102\n",
      "Epoch: [15] [ 105/ 633] time: 6846.1634, d_loss: -0.784154, d_loss_cls: 0.000866, g_loss: 0.373628, g_loss_cls: 0.037195, g_loss_recon: 0.059610, wd: 0.859846\n",
      "Epoch: [15] [ 205/ 633] time: 6917.4964, d_loss: -0.592853, d_loss_cls: 0.000292, g_loss: 0.348641, g_loss_cls: 0.005682, g_loss_recon: 0.059858, wd: 0.648816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15] [ 305/ 633] time: 6988.8046, d_loss: -0.720207, d_loss_cls: 0.000473, g_loss: 0.514406, g_loss_cls: 0.283872, g_loss_recon: 0.055150, wd: 0.794222\n",
      "Epoch: [15] [ 405/ 633] time: 7060.0945, d_loss: -0.651262, d_loss_cls: 0.000349, g_loss: 0.328554, g_loss_cls: 0.045126, g_loss_recon: 0.056447, wd: 0.700616\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [15] [ 505/ 633] time: 7131.7476, d_loss: -0.655299, d_loss_cls: 0.000094, g_loss: 0.482694, g_loss_cls: 0.020003, g_loss_recon: 0.059862, wd: 0.714029\n",
      "Epoch: [15] [ 605/ 633] time: 7203.0083, d_loss: -0.764139, d_loss_cls: 0.000436, g_loss: 0.298786, g_loss_cls: 0.027204, g_loss_recon: 0.066728, wd: 0.842988\n",
      "Epoch: [16] [  72/ 633] time: 7274.3245, d_loss: -0.818930, d_loss_cls: 0.000171, g_loss: 0.543716, g_loss_cls: 0.046466, g_loss_recon: 0.060684, wd: 0.899318\n",
      "Epoch: [16] [ 172/ 633] time: 7345.6415, d_loss: -0.726933, d_loss_cls: 0.000127, g_loss: 0.648175, g_loss_cls: 0.073371, g_loss_recon: 0.054539, wd: 0.784309\n",
      "Epoch: [16] [ 272/ 633] time: 7416.9424, d_loss: -0.718812, d_loss_cls: 0.000382, g_loss: 0.448519, g_loss_cls: 0.098235, g_loss_recon: 0.059706, wd: 0.788859\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [16] [ 372/ 633] time: 7488.6702, d_loss: -0.563699, d_loss_cls: 0.000403, g_loss: 0.522302, g_loss_cls: 0.003718, g_loss_recon: 0.055938, wd: 0.620406\n",
      "Epoch: [16] [ 472/ 633] time: 7559.9764, d_loss: -0.755674, d_loss_cls: 0.000302, g_loss: 0.472632, g_loss_cls: 0.020435, g_loss_recon: 0.060516, wd: 0.832462\n",
      "Epoch: [16] [ 572/ 633] time: 7631.2824, d_loss: -0.751704, d_loss_cls: 0.000472, g_loss: 0.254035, g_loss_cls: 0.066483, g_loss_recon: 0.056186, wd: 0.819916\n",
      "Epoch: [17] [  39/ 633] time: 7702.6282, d_loss: -0.693496, d_loss_cls: 0.000731, g_loss: 0.677182, g_loss_cls: 0.075026, g_loss_recon: 0.055899, wd: 0.753437\n",
      "Epoch: [17] [ 139/ 633] time: 7773.9371, d_loss: -0.895821, d_loss_cls: 0.001042, g_loss: 0.442618, g_loss_cls: 0.011364, g_loss_recon: 0.063162, wd: 1.003289\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [17] [ 239/ 633] time: 7845.6462, d_loss: -0.592260, d_loss_cls: 0.000125, g_loss: 0.394497, g_loss_cls: 0.054477, g_loss_recon: 0.054768, wd: 0.650580\n",
      "Epoch: [17] [ 339/ 633] time: 7916.8688, d_loss: -0.588948, d_loss_cls: 0.000250, g_loss: 0.381967, g_loss_cls: 0.009333, g_loss_recon: 0.051672, wd: 0.652147\n",
      "Epoch: [17] [ 439/ 633] time: 7988.2017, d_loss: -0.689997, d_loss_cls: 0.000216, g_loss: 0.389984, g_loss_cls: 0.063280, g_loss_recon: 0.052964, wd: 0.744867\n",
      "Epoch: [17] [ 539/ 633] time: 8059.5220, d_loss: -0.718813, d_loss_cls: 0.000941, g_loss: 0.732044, g_loss_cls: 0.036585, g_loss_recon: 0.066137, wd: 0.782990\n",
      "Epoch: [18] [   6/ 633] time: 8130.8169, d_loss: -0.506711, d_loss_cls: 0.000664, g_loss: 0.426094, g_loss_cls: 0.023965, g_loss_recon: 0.052899, wd: 0.575925\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [18] [ 106/ 633] time: 8202.5321, d_loss: -0.678583, d_loss_cls: 0.000459, g_loss: 0.618307, g_loss_cls: 0.005090, g_loss_recon: 0.056807, wd: 0.767081\n",
      "Epoch: [18] [ 206/ 633] time: 8273.8407, d_loss: -0.792752, d_loss_cls: 0.000103, g_loss: 0.623934, g_loss_cls: 0.069316, g_loss_recon: 0.062994, wd: 0.860131\n",
      "Epoch: [18] [ 306/ 633] time: 8345.1500, d_loss: -0.636662, d_loss_cls: 0.000171, g_loss: 0.530574, g_loss_cls: 0.010291, g_loss_recon: 0.055789, wd: 0.695479\n",
      "Epoch: [18] [ 406/ 633] time: 8416.4673, d_loss: -0.578638, d_loss_cls: 0.000344, g_loss: 0.321387, g_loss_cls: 0.012260, g_loss_recon: 0.052301, wd: 0.625853\n",
      "Epoch: [18] [ 506/ 633] time: 8487.7771, d_loss: -0.661641, d_loss_cls: 0.000228, g_loss: 0.673325, g_loss_cls: 0.008108, g_loss_recon: 0.055973, wd: 0.739883\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [18] [ 606/ 633] time: 8559.4911, d_loss: -0.666590, d_loss_cls: 0.000249, g_loss: 0.577675, g_loss_cls: 0.055684, g_loss_recon: 0.055387, wd: 0.731874\n",
      "Epoch: [19] [  73/ 633] time: 8630.7973, d_loss: -0.604120, d_loss_cls: 0.004223, g_loss: 0.667320, g_loss_cls: 0.336339, g_loss_recon: 0.052759, wd: 0.681598\n",
      "Epoch: [19] [ 173/ 633] time: 8702.1067, d_loss: -0.707854, d_loss_cls: 0.000198, g_loss: 0.303370, g_loss_cls: 0.073853, g_loss_recon: 0.052714, wd: 0.763528\n",
      "Epoch: [19] [ 273/ 633] time: 8773.4074, d_loss: -0.559690, d_loss_cls: 0.000181, g_loss: 0.692510, g_loss_cls: 0.030004, g_loss_recon: 0.054239, wd: 0.625815\n",
      "Epoch: [19] [ 373/ 633] time: 8844.7191, d_loss: -0.648194, d_loss_cls: 0.000519, g_loss: 0.397145, g_loss_cls: 0.172253, g_loss_recon: 0.059134, wd: 0.705582\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [19] [ 473/ 633] time: 8916.3800, d_loss: -0.570719, d_loss_cls: 0.000137, g_loss: 0.527130, g_loss_cls: 0.035428, g_loss_recon: 0.054479, wd: 0.628558\n",
      "Epoch: [19] [ 573/ 633] time: 8987.6925, d_loss: -0.693817, d_loss_cls: 0.000126, g_loss: 0.204960, g_loss_cls: 0.051316, g_loss_recon: 0.056078, wd: 0.791344\n",
      "Epoch: [20] [  40/ 633] time: 9059.0127, d_loss: -0.784670, d_loss_cls: 0.000468, g_loss: 0.698977, g_loss_cls: 0.015980, g_loss_recon: 0.058566, wd: 0.861681\n",
      "Epoch: [20] [ 140/ 633] time: 9130.3348, d_loss: -0.673698, d_loss_cls: 0.000336, g_loss: 0.607726, g_loss_cls: 0.039982, g_loss_recon: 0.051506, wd: 0.731929\n",
      "Epoch: [20] [ 240/ 633] time: 9201.6520, d_loss: -0.772792, d_loss_cls: 0.000432, g_loss: 0.407084, g_loss_cls: 0.062174, g_loss_recon: 0.060614, wd: 0.839775\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [20] [ 340/ 633] time: 9273.3558, d_loss: -0.737039, d_loss_cls: 0.000340, g_loss: 0.514611, g_loss_cls: 0.059807, g_loss_recon: 0.052902, wd: 0.812931\n",
      "Epoch: [20] [ 440/ 633] time: 9344.6570, d_loss: -0.634202, d_loss_cls: 0.000375, g_loss: 0.465217, g_loss_cls: 0.010598, g_loss_recon: 0.054295, wd: 0.709810\n",
      "Epoch: [20] [ 540/ 633] time: 9415.9625, d_loss: -0.594728, d_loss_cls: 0.000184, g_loss: 0.840191, g_loss_cls: 0.081865, g_loss_recon: 0.054989, wd: 0.689761\n",
      "Epoch: [21] [   7/ 633] time: 9487.2452, d_loss: -0.783082, d_loss_cls: 0.000676, g_loss: 0.569939, g_loss_cls: 0.014007, g_loss_recon: 0.052700, wd: 0.864467\n",
      "Epoch: [21] [ 107/ 633] time: 9558.5129, d_loss: -0.772124, d_loss_cls: 0.000139, g_loss: 0.508920, g_loss_cls: 0.151684, g_loss_recon: 0.067443, wd: 0.886378\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [21] [ 207/ 633] time: 9630.2130, d_loss: -0.751498, d_loss_cls: 0.000245, g_loss: 0.555237, g_loss_cls: 0.028232, g_loss_recon: 0.051437, wd: 0.815034\n",
      "Epoch: [21] [ 307/ 633] time: 9701.5019, d_loss: -0.679486, d_loss_cls: 0.000192, g_loss: 0.599659, g_loss_cls: 0.034794, g_loss_recon: 0.056278, wd: 0.741528\n",
      "Epoch: [21] [ 407/ 633] time: 9772.8062, d_loss: -0.816268, d_loss_cls: 0.000426, g_loss: 0.595600, g_loss_cls: 0.013824, g_loss_recon: 0.050345, wd: 0.870469\n",
      "Epoch: [21] [ 507/ 633] time: 9844.1139, d_loss: -0.928490, d_loss_cls: 0.000645, g_loss: 0.404791, g_loss_cls: 0.090437, g_loss_recon: 0.057804, wd: 1.025923\n",
      "Epoch: [21] [ 607/ 633] time: 9915.4047, d_loss: -0.736874, d_loss_cls: 0.000158, g_loss: 0.728741, g_loss_cls: 0.036704, g_loss_recon: 0.052460, wd: 0.801919\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [22] [  74/ 633] time: 9987.0908, d_loss: -0.642140, d_loss_cls: 0.000470, g_loss: 0.508063, g_loss_cls: 0.025455, g_loss_recon: 0.050208, wd: 0.713412\n",
      "Epoch: [22] [ 174/ 633] time: 10058.3688, d_loss: -0.490506, d_loss_cls: 0.000829, g_loss: 0.105249, g_loss_cls: 0.013311, g_loss_recon: 0.048564, wd: 0.535314\n",
      "Epoch: [22] [ 274/ 633] time: 10129.6429, d_loss: -0.688571, d_loss_cls: 0.000300, g_loss: 0.433370, g_loss_cls: 0.100965, g_loss_recon: 0.053651, wd: 0.757616\n",
      "Epoch: [22] [ 374/ 633] time: 10200.9319, d_loss: -0.706477, d_loss_cls: 0.000082, g_loss: 0.460910, g_loss_cls: 0.071342, g_loss_recon: 0.048682, wd: 0.768728\n",
      "Epoch: [22] [ 474/ 633] time: 10272.2227, d_loss: -0.554628, d_loss_cls: 0.000300, g_loss: 0.188731, g_loss_cls: 0.018557, g_loss_recon: 0.048944, wd: 0.619673\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [22] [ 574/ 633] time: 10343.9125, d_loss: -0.750780, d_loss_cls: 0.000149, g_loss: 0.474149, g_loss_cls: 0.121704, g_loss_recon: 0.050778, wd: 0.831143\n",
      "Epoch: [23] [  41/ 633] time: 10415.2088, d_loss: -0.813996, d_loss_cls: 0.000177, g_loss: 0.583094, g_loss_cls: 0.043065, g_loss_recon: 0.058935, wd: 0.890885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [23] [ 141/ 633] time: 10486.5069, d_loss: -0.554723, d_loss_cls: 0.000145, g_loss: 0.375178, g_loss_cls: 0.096520, g_loss_recon: 0.053114, wd: 0.620772\n",
      "Epoch: [23] [ 241/ 633] time: 10557.7906, d_loss: -0.691044, d_loss_cls: 0.000276, g_loss: 0.682766, g_loss_cls: 0.055527, g_loss_recon: 0.051551, wd: 0.768960\n",
      "Epoch: [23] [ 341/ 633] time: 10629.9346, d_loss: -0.704865, d_loss_cls: 0.000071, g_loss: 0.525024, g_loss_cls: 0.057202, g_loss_recon: 0.050633, wd: 0.775781\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [23] [ 441/ 633] time: 10702.3272, d_loss: -0.656609, d_loss_cls: 0.000154, g_loss: 0.964087, g_loss_cls: 0.009092, g_loss_recon: 0.049247, wd: 0.728097\n",
      "Epoch: [23] [ 541/ 633] time: 10773.5724, d_loss: -0.689732, d_loss_cls: 0.000704, g_loss: 0.630680, g_loss_cls: 0.088717, g_loss_recon: 0.050054, wd: 0.760127\n",
      "Epoch: [24] [   8/ 633] time: 10845.3375, d_loss: -0.690682, d_loss_cls: 0.000325, g_loss: 0.593533, g_loss_cls: 0.042072, g_loss_recon: 0.050886, wd: 0.753359\n",
      "Epoch: [24] [ 108/ 633] time: 10917.7883, d_loss: -0.817109, d_loss_cls: 0.000756, g_loss: 0.138173, g_loss_cls: 0.042778, g_loss_recon: 0.053877, wd: 0.899589\n",
      "Epoch: [24] [ 208/ 633] time: 10989.1365, d_loss: -0.711713, d_loss_cls: 0.000093, g_loss: 0.277010, g_loss_cls: 0.021591, g_loss_recon: 0.051848, wd: 0.779687\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [24] [ 308/ 633] time: 11060.8966, d_loss: -0.823593, d_loss_cls: 0.000732, g_loss: 1.371512, g_loss_cls: 0.782200, g_loss_recon: 0.055734, wd: 0.930955\n",
      "Epoch: [24] [ 408/ 633] time: 11132.2317, d_loss: -0.864202, d_loss_cls: 0.000250, g_loss: 0.594103, g_loss_cls: 0.070142, g_loss_recon: 0.051117, wd: 0.945568\n",
      "Epoch: [24] [ 508/ 633] time: 11203.5572, d_loss: -0.744912, d_loss_cls: 0.000149, g_loss: 0.375615, g_loss_cls: 0.022648, g_loss_recon: 0.048288, wd: 0.822640\n",
      "Epoch: [24] [ 608/ 633] time: 11274.9070, d_loss: -0.749649, d_loss_cls: 0.000223, g_loss: 0.484141, g_loss_cls: 0.017614, g_loss_recon: 0.051399, wd: 0.808212\n",
      "Epoch: [25] [  75/ 633] time: 11346.9844, d_loss: -0.736619, d_loss_cls: 0.000246, g_loss: 0.647654, g_loss_cls: 0.012453, g_loss_recon: 0.047876, wd: 0.790151\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [25] [ 175/ 633] time: 11419.5259, d_loss: -0.807878, d_loss_cls: 0.000293, g_loss: 0.764368, g_loss_cls: 0.020998, g_loss_recon: 0.051622, wd: 0.891704\n",
      "Epoch: [25] [ 275/ 633] time: 11490.8104, d_loss: -0.537454, d_loss_cls: 0.000170, g_loss: 0.717083, g_loss_cls: 0.022184, g_loss_recon: 0.050719, wd: 0.583666\n",
      "Epoch: [25] [ 375/ 633] time: 11562.1429, d_loss: -0.736006, d_loss_cls: 0.000127, g_loss: 0.507473, g_loss_cls: 0.203696, g_loss_recon: 0.047315, wd: 0.801029\n",
      "Epoch: [25] [ 475/ 633] time: 11633.4902, d_loss: -0.845108, d_loss_cls: 0.000134, g_loss: 0.094574, g_loss_cls: 0.048372, g_loss_recon: 0.054712, wd: 0.930341\n",
      "Epoch: [25] [ 575/ 633] time: 11704.8106, d_loss: -0.674416, d_loss_cls: 0.000149, g_loss: 0.790881, g_loss_cls: 0.020731, g_loss_recon: 0.054115, wd: 0.751505\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [26] [  42/ 633] time: 11776.5450, d_loss: -0.778544, d_loss_cls: 0.000053, g_loss: 0.788618, g_loss_cls: 0.034093, g_loss_recon: 0.054237, wd: 0.841155\n",
      "Epoch: [26] [ 142/ 633] time: 11847.8632, d_loss: -0.966425, d_loss_cls: 0.000224, g_loss: 0.787116, g_loss_cls: 0.106473, g_loss_recon: 0.054620, wd: 1.057029\n",
      "Epoch: [26] [ 242/ 633] time: 11919.1955, d_loss: -0.803651, d_loss_cls: 0.000311, g_loss: 0.756001, g_loss_cls: 0.038561, g_loss_recon: 0.055147, wd: 0.896428\n",
      "Epoch: [26] [ 342/ 633] time: 11990.5578, d_loss: -1.034923, d_loss_cls: 0.000129, g_loss: 0.723248, g_loss_cls: 0.011602, g_loss_recon: 0.053698, wd: 1.134234\n",
      "Epoch: [26] [ 442/ 633] time: 12061.8829, d_loss: -0.520401, d_loss_cls: 0.000070, g_loss: 0.434508, g_loss_cls: 0.029414, g_loss_recon: 0.049334, wd: 0.608599\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [26] [ 542/ 633] time: 12133.6297, d_loss: -0.799678, d_loss_cls: 0.000087, g_loss: 0.426862, g_loss_cls: 0.014291, g_loss_recon: 0.051470, wd: 0.886144\n",
      "Epoch: [27] [   9/ 633] time: 12204.9738, d_loss: -0.696312, d_loss_cls: 0.000144, g_loss: 0.192586, g_loss_cls: 0.042814, g_loss_recon: 0.049140, wd: 0.762231\n",
      "Epoch: [27] [ 109/ 633] time: 12276.3314, d_loss: -0.829139, d_loss_cls: 0.000036, g_loss: 0.714026, g_loss_cls: 0.043904, g_loss_recon: 0.051377, wd: 0.903489\n",
      "Epoch: [27] [ 209/ 633] time: 12347.6461, d_loss: -0.826581, d_loss_cls: 0.000076, g_loss: 0.426725, g_loss_cls: 0.049799, g_loss_recon: 0.065815, wd: 0.917512\n",
      "Epoch: [27] [ 309/ 633] time: 12418.9624, d_loss: -0.755594, d_loss_cls: 0.000205, g_loss: 0.558823, g_loss_cls: 0.037328, g_loss_recon: 0.048802, wd: 0.822863\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [27] [ 409/ 633] time: 12490.7292, d_loss: -0.785983, d_loss_cls: 0.000107, g_loss: 0.457167, g_loss_cls: 0.031879, g_loss_recon: 0.050755, wd: 0.856911\n",
      "Epoch: [27] [ 509/ 633] time: 12562.0579, d_loss: -0.831733, d_loss_cls: 0.000122, g_loss: 0.775386, g_loss_cls: 0.058558, g_loss_recon: 0.050741, wd: 0.906569\n",
      "Epoch: [27] [ 609/ 633] time: 12633.3888, d_loss: -0.556735, d_loss_cls: 0.000456, g_loss: 0.493978, g_loss_cls: 0.078453, g_loss_recon: 0.045475, wd: 0.634990\n",
      "Epoch: [28] [  76/ 633] time: 12704.6600, d_loss: -0.673005, d_loss_cls: 0.000230, g_loss: 0.584592, g_loss_cls: 0.208623, g_loss_recon: 0.047306, wd: 0.757293\n",
      "Epoch: [28] [ 176/ 633] time: 12775.9961, d_loss: -0.800513, d_loss_cls: 0.000255, g_loss: 0.963200, g_loss_cls: 0.133502, g_loss_recon: 0.046573, wd: 0.866797\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [28] [ 276/ 633] time: 12847.7166, d_loss: -0.751316, d_loss_cls: 0.000500, g_loss: 0.423640, g_loss_cls: 0.183516, g_loss_recon: 0.052121, wd: 0.821036\n",
      "Epoch: [28] [ 376/ 633] time: 12919.0557, d_loss: -0.689511, d_loss_cls: 0.000088, g_loss: 0.381169, g_loss_cls: 0.124077, g_loss_recon: 0.045404, wd: 0.748556\n",
      "Epoch: [28] [ 476/ 633] time: 12990.3714, d_loss: -0.785555, d_loss_cls: 0.000093, g_loss: 0.486189, g_loss_cls: 0.201031, g_loss_recon: 0.048271, wd: 0.881918\n",
      "Epoch: [28] [ 576/ 633] time: 13061.6739, d_loss: -0.869978, d_loss_cls: 0.000438, g_loss: 0.618429, g_loss_cls: 0.005764, g_loss_recon: 0.049802, wd: 0.955792\n",
      "Epoch: [29] [  43/ 633] time: 13133.0349, d_loss: -0.856108, d_loss_cls: 0.000111, g_loss: 0.934611, g_loss_cls: 0.063681, g_loss_recon: 0.047063, wd: 0.938836\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [29] [ 143/ 633] time: 13204.7825, d_loss: -0.850395, d_loss_cls: 0.000227, g_loss: 1.031352, g_loss_cls: 0.016255, g_loss_recon: 0.056179, wd: 0.935388\n",
      "Epoch: [29] [ 243/ 633] time: 13276.1160, d_loss: -0.821018, d_loss_cls: 0.000102, g_loss: 0.249080, g_loss_cls: 0.149454, g_loss_recon: 0.055284, wd: 0.916389\n",
      "Epoch: [29] [ 343/ 633] time: 13347.4511, d_loss: -0.825670, d_loss_cls: 0.000150, g_loss: 0.361424, g_loss_cls: 0.033509, g_loss_recon: 0.047340, wd: 0.903980\n",
      "Epoch: [29] [ 443/ 633] time: 13418.8255, d_loss: -0.695505, d_loss_cls: 0.000145, g_loss: 0.397727, g_loss_cls: 0.016149, g_loss_recon: 0.046420, wd: 0.768315\n",
      "Epoch: [29] [ 543/ 633] time: 13490.1462, d_loss: -0.666977, d_loss_cls: 0.000108, g_loss: 0.572185, g_loss_cls: 0.077655, g_loss_recon: 0.056586, wd: 0.727946\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [30] [  10/ 633] time: 13561.9134, d_loss: -0.727866, d_loss_cls: 0.000124, g_loss: 0.650092, g_loss_cls: 0.047992, g_loss_recon: 0.045755, wd: 0.800516\n",
      "Epoch: [30] [ 110/ 633] time: 13633.2481, d_loss: -0.738635, d_loss_cls: 0.000118, g_loss: -0.310282, g_loss_cls: 0.034044, g_loss_recon: 0.061818, wd: 0.826687\n",
      "Epoch: [30] [ 210/ 633] time: 13704.5726, d_loss: -0.608361, d_loss_cls: 0.000079, g_loss: 0.396078, g_loss_cls: 0.065588, g_loss_recon: 0.045315, wd: 0.677621\n",
      "Epoch: [30] [ 310/ 633] time: 13776.1443, d_loss: -0.826647, d_loss_cls: 0.000174, g_loss: 0.661969, g_loss_cls: 0.137821, g_loss_recon: 0.050862, wd: 0.906772\n",
      "Epoch: [30] [ 410/ 633] time: 13848.8121, d_loss: -0.583766, d_loss_cls: 0.000144, g_loss: 0.524525, g_loss_cls: 0.008412, g_loss_recon: 0.045373, wd: 0.662272\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30] [ 510/ 633] time: 13920.7691, d_loss: -0.818479, d_loss_cls: 0.000125, g_loss: 0.628560, g_loss_cls: 0.066706, g_loss_recon: 0.050236, wd: 0.888302\n",
      "Epoch: [30] [ 610/ 633] time: 13992.1096, d_loss: -0.640902, d_loss_cls: 0.000200, g_loss: 0.319688, g_loss_cls: 0.102770, g_loss_recon: 0.047963, wd: 0.704227\n",
      "Epoch: [31] [  77/ 633] time: 14063.4470, d_loss: -0.869649, d_loss_cls: 0.000138, g_loss: 0.570453, g_loss_cls: 0.071619, g_loss_recon: 0.053482, wd: 0.961826\n",
      "Epoch: [31] [ 177/ 633] time: 14135.4534, d_loss: -0.757420, d_loss_cls: 0.000170, g_loss: 0.695223, g_loss_cls: 0.022591, g_loss_recon: 0.046818, wd: 0.823958\n",
      "Epoch: [31] [ 277/ 633] time: 14208.0165, d_loss: -0.987414, d_loss_cls: 0.000103, g_loss: 0.569318, g_loss_cls: 0.073372, g_loss_recon: 0.056886, wd: 1.076936\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [31] [ 377/ 633] time: 14279.7202, d_loss: -0.704845, d_loss_cls: 0.000265, g_loss: 0.310036, g_loss_cls: 0.036286, g_loss_recon: 0.047459, wd: 0.767660\n",
      "Epoch: [31] [ 477/ 633] time: 14351.0759, d_loss: -0.850788, d_loss_cls: 0.000017, g_loss: 0.572345, g_loss_cls: 0.069096, g_loss_recon: 0.044437, wd: 0.913310\n",
      "Epoch: [31] [ 577/ 633] time: 14422.4156, d_loss: -0.867420, d_loss_cls: 0.000064, g_loss: 0.424812, g_loss_cls: 0.046436, g_loss_recon: 0.048738, wd: 0.944034\n",
      "Epoch: [32] [  44/ 633] time: 14493.7572, d_loss: -0.954799, d_loss_cls: 0.000203, g_loss: 0.426127, g_loss_cls: 0.038280, g_loss_recon: 0.050196, wd: 1.051670\n",
      "Epoch: [32] [ 144/ 633] time: 14565.1032, d_loss: -0.855133, d_loss_cls: 0.000100, g_loss: 0.354432, g_loss_cls: 0.014754, g_loss_recon: 0.045700, wd: 0.935859\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [32] [ 244/ 633] time: 14636.8459, d_loss: -0.664514, d_loss_cls: 0.000526, g_loss: 0.653773, g_loss_cls: 0.007223, g_loss_recon: 0.057877, wd: 0.752187\n",
      "Epoch: [32] [ 344/ 633] time: 14708.2191, d_loss: -0.769091, d_loss_cls: 0.000099, g_loss: 0.243469, g_loss_cls: 0.008834, g_loss_recon: 0.047686, wd: 0.840032\n",
      "Epoch: [32] [ 444/ 633] time: 14779.5674, d_loss: -0.874545, d_loss_cls: 0.000115, g_loss: 0.864258, g_loss_cls: 0.165401, g_loss_recon: 0.046079, wd: 0.969679\n",
      "Epoch: [32] [ 544/ 633] time: 14850.9317, d_loss: -0.871647, d_loss_cls: 0.000144, g_loss: 0.749255, g_loss_cls: 0.128249, g_loss_recon: 0.051125, wd: 0.956740\n",
      "Epoch: [33] [  11/ 633] time: 14922.2938, d_loss: -0.625946, d_loss_cls: 0.000120, g_loss: 0.602029, g_loss_cls: 0.031387, g_loss_recon: 0.045390, wd: 0.714622\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [33] [ 111/ 633] time: 14994.0458, d_loss: -0.597587, d_loss_cls: 0.000039, g_loss: 0.356352, g_loss_cls: 0.076268, g_loss_recon: 0.046130, wd: 0.646978\n",
      "Epoch: [33] [ 211/ 633] time: 15065.4250, d_loss: -0.732649, d_loss_cls: 0.000186, g_loss: 0.317689, g_loss_cls: 0.021257, g_loss_recon: 0.046353, wd: 0.799410\n",
      "Epoch: [33] [ 311/ 633] time: 15136.7740, d_loss: -0.741012, d_loss_cls: 0.000179, g_loss: 0.560189, g_loss_cls: 0.042869, g_loss_recon: 0.044593, wd: 0.812433\n",
      "Epoch: [33] [ 411/ 633] time: 15208.1451, d_loss: -0.742827, d_loss_cls: 0.000678, g_loss: 0.673324, g_loss_cls: 0.012367, g_loss_recon: 0.045133, wd: 0.810900\n",
      "Epoch: [33] [ 511/ 633] time: 15279.4758, d_loss: -0.840707, d_loss_cls: 0.000111, g_loss: 0.459259, g_loss_cls: 0.036252, g_loss_recon: 0.047563, wd: 0.911597\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [33] [ 611/ 633] time: 15351.1924, d_loss: -0.770066, d_loss_cls: 0.000079, g_loss: 0.599781, g_loss_cls: 0.132614, g_loss_recon: 0.045827, wd: 0.840811\n",
      "Epoch: [34] [  78/ 633] time: 15422.5471, d_loss: -1.072061, d_loss_cls: 0.000123, g_loss: 0.823402, g_loss_cls: 0.022072, g_loss_recon: 0.046080, wd: 1.175979\n",
      "Epoch: [34] [ 178/ 633] time: 15493.9274, d_loss: -0.834457, d_loss_cls: 0.000103, g_loss: 0.711285, g_loss_cls: 0.096034, g_loss_recon: 0.048029, wd: 0.928552\n",
      "Epoch: [34] [ 278/ 633] time: 15565.2828, d_loss: -0.775908, d_loss_cls: 0.000128, g_loss: 0.576410, g_loss_cls: 0.091639, g_loss_recon: 0.048770, wd: 0.847844\n",
      "Epoch: [34] [ 378/ 633] time: 15636.5578, d_loss: -0.650892, d_loss_cls: 0.000096, g_loss: 0.236480, g_loss_cls: 0.040563, g_loss_recon: 0.045410, wd: 0.700880\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [34] [ 478/ 633] time: 15708.2777, d_loss: -0.788329, d_loss_cls: 0.000265, g_loss: 0.487376, g_loss_cls: 0.029155, g_loss_recon: 0.047143, wd: 0.858698\n",
      "Epoch: [34] [ 578/ 633] time: 15779.5847, d_loss: -0.714838, d_loss_cls: 0.000033, g_loss: 0.641944, g_loss_cls: 0.082725, g_loss_recon: 0.049250, wd: 0.805449\n",
      "Epoch: [35] [  45/ 633] time: 15850.9247, d_loss: -0.579005, d_loss_cls: 0.000086, g_loss: 0.279849, g_loss_cls: 0.108512, g_loss_recon: 0.046085, wd: 0.656637\n",
      "Epoch: [35] [ 145/ 633] time: 15922.2466, d_loss: -0.767174, d_loss_cls: 0.000126, g_loss: 0.631551, g_loss_cls: 0.020550, g_loss_recon: 0.044496, wd: 0.854228\n",
      "Epoch: [35] [ 245/ 633] time: 15993.5880, d_loss: -0.616154, d_loss_cls: 0.000036, g_loss: 0.660709, g_loss_cls: 0.052069, g_loss_recon: 0.044344, wd: 0.677028\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [35] [ 345/ 633] time: 16065.3201, d_loss: -0.902833, d_loss_cls: 0.000036, g_loss: 0.694209, g_loss_cls: 0.168819, g_loss_recon: 0.049534, wd: 0.966479\n",
      "Epoch: [35] [ 445/ 633] time: 16136.6332, d_loss: -0.878477, d_loss_cls: 0.000028, g_loss: 1.199523, g_loss_cls: 0.017675, g_loss_recon: 0.049365, wd: 0.962973\n",
      "Epoch: [35] [ 545/ 633] time: 16207.9913, d_loss: -0.876220, d_loss_cls: 0.000074, g_loss: 0.712307, g_loss_cls: 0.014509, g_loss_recon: 0.049638, wd: 0.938648\n",
      "Epoch: [36] [  12/ 633] time: 16279.3331, d_loss: -0.660725, d_loss_cls: 0.000166, g_loss: 0.657636, g_loss_cls: 0.087529, g_loss_recon: 0.045558, wd: 0.754211\n",
      "Epoch: [36] [ 112/ 633] time: 16350.6860, d_loss: -0.777719, d_loss_cls: 0.000037, g_loss: 0.202350, g_loss_cls: 0.063878, g_loss_recon: 0.047911, wd: 0.845495\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [36] [ 212/ 633] time: 16422.4092, d_loss: -0.816224, d_loss_cls: 0.000025, g_loss: 0.294321, g_loss_cls: 0.046253, g_loss_recon: 0.046091, wd: 0.891246\n",
      "Epoch: [36] [ 312/ 633] time: 16493.7489, d_loss: -0.793764, d_loss_cls: 0.000114, g_loss: 0.499774, g_loss_cls: 0.046080, g_loss_recon: 0.046260, wd: 0.855587\n",
      "Epoch: [36] [ 412/ 633] time: 16565.0831, d_loss: -0.687358, d_loss_cls: 0.000212, g_loss: 0.788023, g_loss_cls: 0.117244, g_loss_recon: 0.046988, wd: 0.759341\n",
      "Epoch: [36] [ 512/ 633] time: 16636.4191, d_loss: -0.723095, d_loss_cls: 0.000070, g_loss: 0.226012, g_loss_cls: 0.018111, g_loss_recon: 0.043534, wd: 0.785371\n",
      "Epoch: [36] [ 612/ 633] time: 16707.7415, d_loss: -1.032347, d_loss_cls: 0.000041, g_loss: 0.822913, g_loss_cls: 0.093911, g_loss_recon: 0.048189, wd: 1.122453\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [37] [  79/ 633] time: 16779.4870, d_loss: -0.916849, d_loss_cls: 0.000061, g_loss: 0.355993, g_loss_cls: 0.065748, g_loss_recon: 0.050378, wd: 1.022919\n",
      "Epoch: [37] [ 179/ 633] time: 16850.8142, d_loss: -0.731128, d_loss_cls: 0.000050, g_loss: 0.478933, g_loss_cls: 0.073437, g_loss_recon: 0.046932, wd: 0.800251\n",
      "Epoch: [37] [ 279/ 633] time: 16922.1483, d_loss: -0.794317, d_loss_cls: 0.000145, g_loss: 0.652900, g_loss_cls: 0.112977, g_loss_recon: 0.042471, wd: 0.870135\n",
      "Epoch: [37] [ 379/ 633] time: 16993.4706, d_loss: -0.564299, d_loss_cls: 0.000162, g_loss: 0.818610, g_loss_cls: 0.016228, g_loss_recon: 0.045865, wd: 0.639226\n",
      "Epoch: [37] [ 479/ 633] time: 17064.8073, d_loss: -0.944042, d_loss_cls: 0.000355, g_loss: 0.512033, g_loss_cls: 0.050733, g_loss_recon: 0.050642, wd: 1.048467\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [37] [ 579/ 633] time: 17136.5382, d_loss: -0.630170, d_loss_cls: 0.000059, g_loss: 0.524314, g_loss_cls: 0.036651, g_loss_recon: 0.045265, wd: 0.707710\n",
      "Epoch: [38] [  46/ 633] time: 17207.8782, d_loss: -0.812306, d_loss_cls: 0.000006, g_loss: 0.643681, g_loss_cls: 0.032752, g_loss_recon: 0.046343, wd: 0.914716\n",
      "Epoch: [38] [ 146/ 633] time: 17279.1626, d_loss: -0.575772, d_loss_cls: 0.000177, g_loss: 0.107009, g_loss_cls: 0.036541, g_loss_recon: 0.043843, wd: 0.646942\n",
      "Epoch: [38] [ 246/ 633] time: 17350.5146, d_loss: -0.861351, d_loss_cls: 0.000075, g_loss: 0.466551, g_loss_cls: 0.012618, g_loss_recon: 0.045941, wd: 0.933888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [38] [ 346/ 633] time: 17421.8709, d_loss: -0.626896, d_loss_cls: 0.000165, g_loss: 0.348388, g_loss_cls: 0.002572, g_loss_recon: 0.047634, wd: 0.720900\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [38] [ 446/ 633] time: 17493.5335, d_loss: -0.851633, d_loss_cls: 0.000120, g_loss: 0.720895, g_loss_cls: 0.046895, g_loss_recon: 0.051607, wd: 0.939756\n",
      "Epoch: [38] [ 546/ 633] time: 17564.8712, d_loss: -0.811227, d_loss_cls: 0.000011, g_loss: 0.148065, g_loss_cls: 0.062119, g_loss_recon: 0.049571, wd: 0.901740\n",
      "Epoch: [39] [  13/ 633] time: 17636.2308, d_loss: -0.923748, d_loss_cls: 0.000282, g_loss: 0.745920, g_loss_cls: 0.099365, g_loss_recon: 0.047544, wd: 1.017704\n",
      "Epoch: [39] [ 113/ 633] time: 17707.5503, d_loss: -0.770019, d_loss_cls: 0.000090, g_loss: 0.128398, g_loss_cls: 0.051740, g_loss_recon: 0.047539, wd: 0.833054\n",
      "Epoch: [39] [ 213/ 633] time: 17778.8850, d_loss: -0.728955, d_loss_cls: 0.000099, g_loss: 0.470209, g_loss_cls: 0.051814, g_loss_recon: 0.044766, wd: 0.794249\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [39] [ 313/ 633] time: 17850.6522, d_loss: -0.883699, d_loss_cls: 0.000041, g_loss: 0.554994, g_loss_cls: 0.023289, g_loss_recon: 0.044964, wd: 0.979831\n",
      "Epoch: [39] [ 413/ 633] time: 17921.9769, d_loss: -0.801315, d_loss_cls: 0.000102, g_loss: 0.654743, g_loss_cls: 0.008155, g_loss_recon: 0.043236, wd: 0.900615\n",
      "Epoch: [39] [ 513/ 633] time: 17993.3252, d_loss: -0.832680, d_loss_cls: 0.000038, g_loss: 0.327887, g_loss_cls: 0.066539, g_loss_recon: 0.044650, wd: 0.886834\n",
      "Epoch: [39] [ 613/ 633] time: 18065.1127, d_loss: -0.839575, d_loss_cls: 0.000414, g_loss: 0.613329, g_loss_cls: 0.106179, g_loss_recon: 0.041806, wd: 0.911973\n",
      "Epoch: [40] [  80/ 633] time: 18137.7093, d_loss: -0.673238, d_loss_cls: 0.000095, g_loss: 0.336539, g_loss_cls: 0.132411, g_loss_recon: 0.046404, wd: 0.850843\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [40] [ 180/ 633] time: 18210.3075, d_loss: -0.856436, d_loss_cls: 0.000063, g_loss: 0.640840, g_loss_cls: 0.010880, g_loss_recon: 0.045050, wd: 0.939136\n",
      "Epoch: [40] [ 280/ 633] time: 18281.4653, d_loss: -0.696163, d_loss_cls: 0.000065, g_loss: 0.695920, g_loss_cls: 0.019824, g_loss_recon: 0.046119, wd: 0.764779\n",
      "Epoch: [40] [ 380/ 633] time: 18352.8126, d_loss: -0.786805, d_loss_cls: 0.000106, g_loss: 0.709052, g_loss_cls: 0.025118, g_loss_recon: 0.044109, wd: 0.865031\n",
      "Epoch: [40] [ 480/ 633] time: 18424.1337, d_loss: -1.078596, d_loss_cls: 0.000022, g_loss: 0.476308, g_loss_cls: 0.044633, g_loss_recon: 0.048160, wd: 1.176179\n",
      "Epoch: [40] [ 580/ 633] time: 18495.4664, d_loss: -0.738267, d_loss_cls: 0.000381, g_loss: 0.463929, g_loss_cls: 0.137875, g_loss_recon: 0.044161, wd: 0.825269\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [41] [  47/ 633] time: 18567.1917, d_loss: -0.777346, d_loss_cls: 0.000020, g_loss: 0.213555, g_loss_cls: 0.014596, g_loss_recon: 0.041653, wd: 0.848675\n",
      "Epoch: [41] [ 147/ 633] time: 18638.5063, d_loss: -1.100083, d_loss_cls: 0.000201, g_loss: 0.804233, g_loss_cls: 0.045892, g_loss_recon: 0.047363, wd: 1.194147\n",
      "Epoch: [41] [ 247/ 633] time: 18710.6031, d_loss: -0.992515, d_loss_cls: 0.000016, g_loss: 0.664864, g_loss_cls: 0.052725, g_loss_recon: 0.048546, wd: 1.096300\n",
      "Epoch: [41] [ 347/ 633] time: 18782.9726, d_loss: -0.847843, d_loss_cls: 0.000055, g_loss: 1.129902, g_loss_cls: 0.523178, g_loss_recon: 0.053418, wd: 0.951700\n",
      "Epoch: [41] [ 447/ 633] time: 18854.9210, d_loss: -0.837734, d_loss_cls: 0.000071, g_loss: 0.519391, g_loss_cls: 0.055040, g_loss_recon: 0.043634, wd: 0.931019\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [41] [ 547/ 633] time: 18927.0544, d_loss: -0.782478, d_loss_cls: 0.000120, g_loss: 0.203840, g_loss_cls: 0.094525, g_loss_recon: 0.042949, wd: 0.889501\n",
      "Epoch: [42] [  14/ 633] time: 18999.3749, d_loss: -0.886974, d_loss_cls: 0.000136, g_loss: 0.802903, g_loss_cls: 0.011909, g_loss_recon: 0.042930, wd: 0.969101\n",
      "Epoch: [42] [ 114/ 633] time: 19071.7360, d_loss: -0.813211, d_loss_cls: 0.000038, g_loss: 0.525469, g_loss_cls: 0.048828, g_loss_recon: 0.046095, wd: 0.880248\n",
      "Epoch: [42] [ 214/ 633] time: 19142.7913, d_loss: -0.967095, d_loss_cls: 0.000044, g_loss: 0.758222, g_loss_cls: 0.076839, g_loss_recon: 0.045169, wd: 1.041256\n",
      "Epoch: [42] [ 314/ 633] time: 19214.1399, d_loss: -0.783379, d_loss_cls: 0.000053, g_loss: 0.328019, g_loss_cls: 0.087224, g_loss_recon: 0.042459, wd: 0.852778\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [42] [ 414/ 633] time: 19285.8304, d_loss: -0.876966, d_loss_cls: 0.000193, g_loss: 0.739900, g_loss_cls: 0.213055, g_loss_recon: 0.050494, wd: 0.986680\n",
      "Epoch: [42] [ 514/ 633] time: 19357.1604, d_loss: -0.827546, d_loss_cls: 0.000029, g_loss: 0.644676, g_loss_cls: 0.138572, g_loss_recon: 0.041203, wd: 0.899795\n",
      "Epoch: [42] [ 614/ 633] time: 19428.4868, d_loss: -0.538226, d_loss_cls: 0.000074, g_loss: 0.442245, g_loss_cls: 0.030390, g_loss_recon: 0.043256, wd: 0.631231\n",
      "Epoch: [43] [  81/ 633] time: 19499.8089, d_loss: -1.005081, d_loss_cls: 0.000014, g_loss: 0.651196, g_loss_cls: 0.107443, g_loss_recon: 0.046216, wd: 1.082687\n",
      "Epoch: [43] [ 181/ 633] time: 19571.1150, d_loss: -0.723288, d_loss_cls: 0.000096, g_loss: 0.306773, g_loss_cls: 0.069274, g_loss_recon: 0.044105, wd: 0.801595\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [43] [ 281/ 633] time: 19642.8655, d_loss: -0.915277, d_loss_cls: 0.000059, g_loss: 0.559434, g_loss_cls: 0.058611, g_loss_recon: 0.042976, wd: 0.994887\n",
      "Epoch: [43] [ 381/ 633] time: 19714.2155, d_loss: -0.697311, d_loss_cls: 0.000066, g_loss: 0.210356, g_loss_cls: 0.061587, g_loss_recon: 0.047170, wd: 0.761721\n",
      "Epoch: [43] [ 481/ 633] time: 19785.5464, d_loss: -0.920609, d_loss_cls: 0.000175, g_loss: 1.507866, g_loss_cls: 1.176315, g_loss_recon: 0.052345, wd: 1.031442\n",
      "Epoch: [43] [ 581/ 633] time: 19856.8977, d_loss: -0.765395, d_loss_cls: 0.000006, g_loss: 0.759518, g_loss_cls: 0.175412, g_loss_recon: 0.046182, wd: 0.846075\n",
      "Epoch: [44] [  48/ 633] time: 19928.5386, d_loss: -0.909414, d_loss_cls: 0.000051, g_loss: 0.338872, g_loss_cls: 0.023836, g_loss_recon: 0.044276, wd: 0.991934\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [44] [ 148/ 633] time: 20001.3613, d_loss: -0.772392, d_loss_cls: 0.000029, g_loss: 0.230236, g_loss_cls: 0.011699, g_loss_recon: 0.045009, wd: 0.875190\n",
      "Epoch: [44] [ 248/ 633] time: 20073.8226, d_loss: -0.860433, d_loss_cls: 0.000017, g_loss: 0.718743, g_loss_cls: 0.173894, g_loss_recon: 0.045959, wd: 0.958535\n",
      "Epoch: [44] [ 348/ 633] time: 20144.9959, d_loss: -0.772937, d_loss_cls: 0.000074, g_loss: 0.577011, g_loss_cls: 0.037914, g_loss_recon: 0.041343, wd: 0.864080\n",
      "Epoch: [44] [ 448/ 633] time: 20216.2791, d_loss: -0.969089, d_loss_cls: 0.000020, g_loss: 0.777571, g_loss_cls: 0.014605, g_loss_recon: 0.048480, wd: 1.032804\n",
      "Epoch: [44] [ 548/ 633] time: 20287.5865, d_loss: -0.669814, d_loss_cls: 0.000084, g_loss: 0.036982, g_loss_cls: 0.025052, g_loss_recon: 0.042840, wd: 0.727423\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [45] [  15/ 633] time: 20359.3483, d_loss: -0.759257, d_loss_cls: 0.000029, g_loss: 0.229989, g_loss_cls: 0.035604, g_loss_recon: 0.043925, wd: 0.845161\n",
      "Epoch: [45] [ 115/ 633] time: 20430.6007, d_loss: -0.817824, d_loss_cls: 0.000054, g_loss: 0.155659, g_loss_cls: 0.030309, g_loss_recon: 0.046929, wd: 0.878540\n",
      "Epoch: [45] [ 215/ 633] time: 20501.9304, d_loss: -0.844343, d_loss_cls: 0.000166, g_loss: 0.993254, g_loss_cls: 0.182743, g_loss_recon: 0.045173, wd: 0.937621\n",
      "Epoch: [45] [ 315/ 633] time: 20573.2434, d_loss: -1.315334, d_loss_cls: 0.000201, g_loss: 2.755183, g_loss_cls: 0.233782, g_loss_recon: 0.164559, wd: 1.560628\n",
      "Epoch: [45] [ 415/ 633] time: 20644.5766, d_loss: -0.790595, d_loss_cls: 0.000072, g_loss: 0.419988, g_loss_cls: 0.044996, g_loss_recon: 0.047145, wd: 0.885249\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [45] [ 515/ 633] time: 20716.2489, d_loss: -0.735891, d_loss_cls: 0.000082, g_loss: 0.815222, g_loss_cls: 0.044894, g_loss_recon: 0.042527, wd: 0.799935\n",
      "Epoch: [45] [ 615/ 633] time: 20787.5681, d_loss: -0.721310, d_loss_cls: 0.000451, g_loss: 0.312697, g_loss_cls: 0.058159, g_loss_recon: 0.042417, wd: 0.789328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [46] [  82/ 633] time: 20858.9495, d_loss: -0.770226, d_loss_cls: 0.000050, g_loss: 0.475784, g_loss_cls: 0.071999, g_loss_recon: 0.043461, wd: 0.848914\n",
      "Epoch: [46] [ 182/ 633] time: 20930.3339, d_loss: -0.754061, d_loss_cls: 0.000011, g_loss: 0.436620, g_loss_cls: 0.053821, g_loss_recon: 0.040370, wd: 0.817325\n",
      "Epoch: [46] [ 282/ 633] time: 21001.6825, d_loss: -0.824370, d_loss_cls: 0.000464, g_loss: 0.834328, g_loss_cls: 0.277228, g_loss_recon: 0.047718, wd: 0.904985\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [46] [ 382/ 633] time: 21073.5030, d_loss: -0.799711, d_loss_cls: 0.000022, g_loss: 0.537857, g_loss_cls: 0.084002, g_loss_recon: 0.045254, wd: 0.904236\n",
      "Epoch: [46] [ 482/ 633] time: 21144.8601, d_loss: -0.978248, d_loss_cls: 0.000073, g_loss: 0.626482, g_loss_cls: 0.056482, g_loss_recon: 0.042248, wd: 1.072356\n",
      "Epoch: [46] [ 582/ 633] time: 21216.2235, d_loss: -0.517058, d_loss_cls: 0.000387, g_loss: 0.323595, g_loss_cls: 0.019206, g_loss_recon: 0.040982, wd: 0.571989\n",
      "Epoch: [47] [  49/ 633] time: 21287.6222, d_loss: -1.009173, d_loss_cls: 0.000099, g_loss: 0.609356, g_loss_cls: 0.010836, g_loss_recon: 0.042675, wd: 1.126281\n",
      "Epoch: [47] [ 149/ 633] time: 21359.0035, d_loss: -0.718727, d_loss_cls: 0.000173, g_loss: 0.451599, g_loss_cls: 0.040419, g_loss_recon: 0.043283, wd: 0.795441\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [47] [ 249/ 633] time: 21430.7340, d_loss: -0.809207, d_loss_cls: 0.000117, g_loss: 0.467598, g_loss_cls: 0.076675, g_loss_recon: 0.042211, wd: 0.887968\n",
      "Epoch: [47] [ 349/ 633] time: 21502.1375, d_loss: -0.651704, d_loss_cls: 0.000164, g_loss: 0.008489, g_loss_cls: 0.060540, g_loss_recon: 0.041712, wd: 0.711345\n",
      "Epoch: [47] [ 449/ 633] time: 21573.5150, d_loss: -0.806984, d_loss_cls: 0.000061, g_loss: 0.620468, g_loss_cls: 0.119798, g_loss_recon: 0.045705, wd: 0.908760\n",
      "Epoch: [47] [ 549/ 633] time: 21644.8410, d_loss: -1.030415, d_loss_cls: 0.000022, g_loss: 0.503733, g_loss_cls: 0.017849, g_loss_recon: 0.043509, wd: 1.114247\n",
      "Epoch: [48] [  16/ 633] time: 21716.2029, d_loss: -0.914107, d_loss_cls: 0.000007, g_loss: 0.351584, g_loss_cls: 0.037794, g_loss_recon: 0.043553, wd: 1.010098\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [48] [ 116/ 633] time: 21787.9600, d_loss: -1.016764, d_loss_cls: 0.000018, g_loss: 0.327231, g_loss_cls: 0.020156, g_loss_recon: 0.043780, wd: 1.097597\n",
      "Epoch: [48] [ 216/ 633] time: 21859.3314, d_loss: -0.830609, d_loss_cls: 0.000087, g_loss: 0.811450, g_loss_cls: 0.293180, g_loss_recon: 0.043914, wd: 0.908544\n",
      "Epoch: [48] [ 316/ 633] time: 21930.6766, d_loss: -0.821442, d_loss_cls: 0.000063, g_loss: 0.479418, g_loss_cls: 0.035272, g_loss_recon: 0.042880, wd: 0.912045\n",
      "Epoch: [48] [ 416/ 633] time: 22002.0162, d_loss: -0.817555, d_loss_cls: 0.000074, g_loss: 0.496159, g_loss_cls: 0.012984, g_loss_recon: 0.041973, wd: 0.876690\n",
      "Epoch: [48] [ 516/ 633] time: 22073.3738, d_loss: -0.852011, d_loss_cls: 0.000072, g_loss: 0.679980, g_loss_cls: 0.084488, g_loss_recon: 0.045641, wd: 0.922538\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [48] [ 616/ 633] time: 22145.1581, d_loss: -0.668857, d_loss_cls: 0.000076, g_loss: 0.433825, g_loss_cls: 0.016679, g_loss_recon: 0.043225, wd: 0.764999\n",
      "Epoch: [49] [  83/ 633] time: 22216.5525, d_loss: -0.779844, d_loss_cls: 0.000051, g_loss: 0.409801, g_loss_cls: 0.027782, g_loss_recon: 0.040070, wd: 0.866262\n",
      "Epoch: [49] [ 183/ 633] time: 22287.7726, d_loss: -0.753346, d_loss_cls: 0.000025, g_loss: 0.564161, g_loss_cls: 0.018970, g_loss_recon: 0.044358, wd: 0.834257\n",
      "Epoch: [49] [ 283/ 633] time: 22359.1354, d_loss: -0.743754, d_loss_cls: 0.000299, g_loss: 0.604445, g_loss_cls: 0.136079, g_loss_recon: 0.040956, wd: 0.810030\n",
      "Epoch: [49] [ 383/ 633] time: 22430.5309, d_loss: -0.960180, d_loss_cls: 0.000061, g_loss: 0.782968, g_loss_cls: 0.063193, g_loss_recon: 0.042369, wd: 1.068931\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [49] [ 483/ 633] time: 22502.2917, d_loss: -0.757039, d_loss_cls: 0.000079, g_loss: 0.365083, g_loss_cls: 0.007666, g_loss_recon: 0.042015, wd: 0.843003\n",
      "Epoch: [49] [ 583/ 633] time: 22573.6517, d_loss: -0.966681, d_loss_cls: 0.000055, g_loss: 0.616061, g_loss_cls: 0.072308, g_loss_recon: 0.040706, wd: 1.048267\n",
      "Epoch: [50] [  50/ 633] time: 22645.0321, d_loss: -0.643085, d_loss_cls: 0.000068, g_loss: 0.231791, g_loss_cls: 0.055410, g_loss_recon: 0.040264, wd: 0.713161\n",
      "Epoch: [50] [ 150/ 633] time: 22716.4359, d_loss: -0.639660, d_loss_cls: 0.000042, g_loss: 0.219614, g_loss_cls: 0.045582, g_loss_recon: 0.041207, wd: 0.712406\n",
      "Epoch: [50] [ 250/ 633] time: 22787.7898, d_loss: -1.024795, d_loss_cls: 0.000041, g_loss: 0.674997, g_loss_cls: 0.013589, g_loss_recon: 0.045664, wd: 1.112818\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [50] [ 350/ 633] time: 22859.5508, d_loss: -0.742343, d_loss_cls: 0.000326, g_loss: 1.010072, g_loss_cls: 0.399287, g_loss_recon: 0.047458, wd: 0.826556\n",
      "Epoch: [50] [ 450/ 633] time: 22930.9188, d_loss: -0.671489, d_loss_cls: 0.000165, g_loss: 0.556013, g_loss_cls: 0.011594, g_loss_recon: 0.042118, wd: 0.743998\n",
      "Epoch: [50] [ 550/ 633] time: 23002.2924, d_loss: -0.822646, d_loss_cls: 0.000181, g_loss: 0.106718, g_loss_cls: 0.039841, g_loss_recon: 0.041746, wd: 0.900810\n",
      "Epoch: [51] [  17/ 633] time: 23073.6544, d_loss: -0.766309, d_loss_cls: 0.000092, g_loss: 0.462785, g_loss_cls: 0.025451, g_loss_recon: 0.044797, wd: 0.847453\n",
      "Epoch: [51] [ 117/ 633] time: 23144.9853, d_loss: -0.795511, d_loss_cls: 0.000078, g_loss: 0.446366, g_loss_cls: 0.009619, g_loss_recon: 0.039818, wd: 0.872714\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [51] [ 217/ 633] time: 23216.7222, d_loss: -0.777167, d_loss_cls: 0.000045, g_loss: 1.235737, g_loss_cls: 0.557121, g_loss_recon: 0.043397, wd: 0.887999\n",
      "Epoch: [51] [ 317/ 633] time: 23288.0947, d_loss: -0.824055, d_loss_cls: 0.000155, g_loss: 0.536574, g_loss_cls: 0.081895, g_loss_recon: 0.041897, wd: 0.936789\n",
      "Epoch: [51] [ 417/ 633] time: 23359.4816, d_loss: -0.704631, d_loss_cls: 0.000272, g_loss: 0.651195, g_loss_cls: 0.157184, g_loss_recon: 0.042206, wd: 0.772802\n",
      "Epoch: [51] [ 517/ 633] time: 23430.8506, d_loss: -0.828438, d_loss_cls: 0.000009, g_loss: 0.426335, g_loss_cls: 0.028328, g_loss_recon: 0.040049, wd: 0.902229\n",
      "Epoch: [51] [ 617/ 633] time: 23502.2180, d_loss: -0.782290, d_loss_cls: 0.000014, g_loss: 0.159036, g_loss_cls: 0.029346, g_loss_recon: 0.040135, wd: 0.858569\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [52] [  84/ 633] time: 23573.9555, d_loss: -0.820948, d_loss_cls: 0.000048, g_loss: 0.355788, g_loss_cls: 0.115348, g_loss_recon: 0.045322, wd: 0.898428\n",
      "Epoch: [52] [ 184/ 633] time: 23645.3222, d_loss: -0.711651, d_loss_cls: 0.000181, g_loss: 0.314725, g_loss_cls: 0.030164, g_loss_recon: 0.043501, wd: 0.785220\n",
      "Epoch: [52] [ 284/ 633] time: 23716.6918, d_loss: -0.877844, d_loss_cls: 0.000001, g_loss: 0.116195, g_loss_cls: 0.044615, g_loss_recon: 0.043069, wd: 0.967345\n",
      "Epoch: [52] [ 384/ 633] time: 23788.0720, d_loss: -0.870923, d_loss_cls: 0.000023, g_loss: 0.929890, g_loss_cls: 0.239430, g_loss_recon: 0.040371, wd: 0.967064\n",
      "Epoch: [52] [ 484/ 633] time: 23859.4317, d_loss: -0.893271, d_loss_cls: 0.000027, g_loss: 0.693796, g_loss_cls: 0.110792, g_loss_recon: 0.043302, wd: 0.999073\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [52] [ 584/ 633] time: 23931.1976, d_loss: -0.864161, d_loss_cls: 0.000011, g_loss: 0.665809, g_loss_cls: 0.085409, g_loss_recon: 0.046841, wd: 0.947491\n",
      "Epoch: [53] [  51/ 633] time: 24002.5606, d_loss: -0.639306, d_loss_cls: 0.000065, g_loss: 0.517713, g_loss_cls: 0.050718, g_loss_recon: 0.046521, wd: 0.720702\n",
      "Epoch: [53] [ 151/ 633] time: 24073.9350, d_loss: -0.871912, d_loss_cls: 0.000005, g_loss: 0.269344, g_loss_cls: 0.037280, g_loss_recon: 0.044001, wd: 0.983239\n",
      "Epoch: [53] [ 251/ 633] time: 24145.2873, d_loss: -0.798030, d_loss_cls: 0.000004, g_loss: 0.560448, g_loss_cls: 0.055038, g_loss_recon: 0.043637, wd: 0.883041\n",
      "Epoch: [53] [ 351/ 633] time: 24216.6437, d_loss: -0.907738, d_loss_cls: 0.000023, g_loss: 0.571391, g_loss_cls: 0.044575, g_loss_recon: 0.044560, wd: 0.991829\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [53] [ 451/ 633] time: 24288.4186, d_loss: -0.728331, d_loss_cls: 0.000161, g_loss: 0.574320, g_loss_cls: 0.112131, g_loss_recon: 0.041865, wd: 0.795331\n",
      "Epoch: [53] [ 551/ 633] time: 24359.7994, d_loss: -0.923648, d_loss_cls: 0.000029, g_loss: 0.557865, g_loss_cls: 0.014273, g_loss_recon: 0.042842, wd: 0.998853\n",
      "Epoch: [54] [  18/ 633] time: 24431.1928, d_loss: -0.983073, d_loss_cls: 0.000147, g_loss: 0.334923, g_loss_cls: 0.122911, g_loss_recon: 0.045313, wd: 1.079759\n",
      "Epoch: [54] [ 118/ 633] time: 24502.5785, d_loss: -0.931143, d_loss_cls: 0.000073, g_loss: 0.285690, g_loss_cls: 0.014162, g_loss_recon: 0.046369, wd: 1.020899\n",
      "Epoch: [54] [ 218/ 633] time: 24573.9358, d_loss: -0.789939, d_loss_cls: 0.000052, g_loss: 0.563665, g_loss_cls: 0.096254, g_loss_recon: 0.043552, wd: 0.875429\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [54] [ 318/ 633] time: 24645.7182, d_loss: -0.742700, d_loss_cls: 0.000052, g_loss: 0.515248, g_loss_cls: 0.044211, g_loss_recon: 0.043502, wd: 0.821359\n",
      "Epoch: [54] [ 418/ 633] time: 24717.0575, d_loss: -0.994451, d_loss_cls: 0.000078, g_loss: 0.702104, g_loss_cls: 0.032108, g_loss_recon: 0.039485, wd: 1.101585\n",
      "Epoch: [54] [ 518/ 633] time: 24788.4175, d_loss: -0.951625, d_loss_cls: 0.000194, g_loss: 0.284824, g_loss_cls: 0.071171, g_loss_recon: 0.039654, wd: 1.045012\n",
      "Epoch: [54] [ 618/ 633] time: 24859.7805, d_loss: -0.871085, d_loss_cls: 0.000054, g_loss: 0.567162, g_loss_cls: 0.029782, g_loss_recon: 0.041714, wd: 0.956283\n",
      "Epoch: [55] [  85/ 633] time: 24931.1283, d_loss: -0.626441, d_loss_cls: 0.000037, g_loss: 0.538406, g_loss_cls: 0.031230, g_loss_recon: 0.042317, wd: 0.715986\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [55] [ 185/ 633] time: 25002.8510, d_loss: -0.692549, d_loss_cls: 0.000079, g_loss: 0.271279, g_loss_cls: 0.019221, g_loss_recon: 0.039171, wd: 0.774090\n",
      "Epoch: [55] [ 285/ 633] time: 25074.2312, d_loss: -0.780176, d_loss_cls: 0.000009, g_loss: 0.580358, g_loss_cls: 0.082279, g_loss_recon: 0.041036, wd: 0.841272\n",
      "Epoch: [55] [ 385/ 633] time: 25145.5766, d_loss: -1.049512, d_loss_cls: 0.000131, g_loss: 0.927688, g_loss_cls: 0.132646, g_loss_recon: 0.042008, wd: 1.146765\n",
      "Epoch: [55] [ 485/ 633] time: 25216.8897, d_loss: -0.844471, d_loss_cls: 0.000018, g_loss: 0.622962, g_loss_cls: 0.060451, g_loss_recon: 0.040135, wd: 0.919630\n",
      "Epoch: [55] [ 585/ 633] time: 25288.2444, d_loss: -0.829630, d_loss_cls: 0.000144, g_loss: 0.011689, g_loss_cls: 0.047168, g_loss_recon: 0.045339, wd: 0.917211\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [56] [  52/ 633] time: 25359.9512, d_loss: -0.853187, d_loss_cls: 0.000018, g_loss: 0.670137, g_loss_cls: 0.128628, g_loss_recon: 0.042210, wd: 0.926128\n",
      "Epoch: [56] [ 152/ 633] time: 25431.3066, d_loss: -0.976786, d_loss_cls: 0.000001, g_loss: 0.598602, g_loss_cls: 0.128254, g_loss_recon: 0.041656, wd: 1.058671\n",
      "Epoch: [56] [ 252/ 633] time: 25502.6860, d_loss: -0.716069, d_loss_cls: 0.000051, g_loss: 0.570243, g_loss_cls: 0.005332, g_loss_recon: 0.045483, wd: 0.802097\n",
      "Epoch: [56] [ 352/ 633] time: 25574.0421, d_loss: -1.054478, d_loss_cls: 0.000028, g_loss: 0.525187, g_loss_cls: 0.047207, g_loss_recon: 0.049593, wd: 1.152747\n",
      "Epoch: [56] [ 452/ 633] time: 25645.3943, d_loss: -0.968430, d_loss_cls: 0.000024, g_loss: 0.811983, g_loss_cls: 0.049070, g_loss_recon: 0.041440, wd: 1.038864\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [56] [ 552/ 633] time: 25717.1422, d_loss: -0.793820, d_loss_cls: 0.000051, g_loss: 0.343688, g_loss_cls: 0.070554, g_loss_recon: 0.042375, wd: 0.892093\n",
      "Epoch: [57] [  19/ 633] time: 25788.5364, d_loss: -0.908141, d_loss_cls: 0.000193, g_loss: 0.612258, g_loss_cls: 0.012439, g_loss_recon: 0.043090, wd: 0.995313\n",
      "Epoch: [57] [ 119/ 633] time: 25859.9133, d_loss: -0.805355, d_loss_cls: 0.000087, g_loss: 0.409661, g_loss_cls: 0.057934, g_loss_recon: 0.041561, wd: 0.872505\n",
      "Epoch: [57] [ 219/ 633] time: 25931.2783, d_loss: -0.727237, d_loss_cls: 0.000086, g_loss: 0.467881, g_loss_cls: 0.133952, g_loss_recon: 0.040793, wd: 0.800814\n",
      "Epoch: [57] [ 319/ 633] time: 26002.6462, d_loss: -0.942246, d_loss_cls: 0.000001, g_loss: 0.466820, g_loss_cls: 0.085374, g_loss_recon: 0.047213, wd: 1.049169\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [57] [ 419/ 633] time: 26074.3966, d_loss: -0.716675, d_loss_cls: 0.000059, g_loss: 0.485895, g_loss_cls: 0.024878, g_loss_recon: 0.042455, wd: 0.794452\n",
      "Epoch: [57] [ 519/ 633] time: 26145.7547, d_loss: -0.769378, d_loss_cls: 0.000035, g_loss: -0.080386, g_loss_cls: 0.041964, g_loss_recon: 0.039936, wd: 0.867175\n",
      "Epoch: [57] [ 619/ 633] time: 26217.1230, d_loss: -0.891434, d_loss_cls: 0.000184, g_loss: 0.672472, g_loss_cls: 0.051075, g_loss_recon: 0.040208, wd: 0.979251\n",
      "Epoch: [58] [  86/ 633] time: 26288.4502, d_loss: -0.931976, d_loss_cls: 0.000010, g_loss: 0.542279, g_loss_cls: 0.015468, g_loss_recon: 0.041092, wd: 1.034800\n",
      "Epoch: [58] [ 186/ 633] time: 26359.8106, d_loss: -0.781055, d_loss_cls: 0.000024, g_loss: 0.414025, g_loss_cls: 0.028730, g_loss_recon: 0.041048, wd: 0.848492\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [58] [ 286/ 633] time: 26431.5370, d_loss: -0.695921, d_loss_cls: 0.000029, g_loss: 0.469413, g_loss_cls: 0.037977, g_loss_recon: 0.044840, wd: 0.765693\n",
      "Epoch: [58] [ 386/ 633] time: 26502.8968, d_loss: -0.949549, d_loss_cls: 0.000020, g_loss: 0.448122, g_loss_cls: 0.059827, g_loss_recon: 0.040354, wd: 1.047066\n",
      "Epoch: [58] [ 486/ 633] time: 26574.2411, d_loss: -1.098658, d_loss_cls: 0.000129, g_loss: 0.515699, g_loss_cls: 0.018144, g_loss_recon: 0.042075, wd: 1.226652\n",
      "Epoch: [58] [ 586/ 633] time: 26645.6024, d_loss: -0.856377, d_loss_cls: 0.000182, g_loss: 0.555237, g_loss_cls: 0.060671, g_loss_recon: 0.038800, wd: 0.927047\n",
      "Epoch: [59] [  53/ 633] time: 26716.9534, d_loss: -0.799899, d_loss_cls: 0.000273, g_loss: 0.600464, g_loss_cls: 0.046155, g_loss_recon: 0.040884, wd: 0.874866\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [59] [ 153/ 633] time: 26788.7172, d_loss: -0.767207, d_loss_cls: 0.000001, g_loss: 0.113937, g_loss_cls: 0.075677, g_loss_recon: 0.038977, wd: 0.849747\n",
      "Epoch: [59] [ 253/ 633] time: 26860.0880, d_loss: -0.793301, d_loss_cls: 0.000042, g_loss: 0.278099, g_loss_cls: 0.166487, g_loss_recon: 0.042382, wd: 0.873270\n",
      "Epoch: [59] [ 353/ 633] time: 26931.4181, d_loss: -0.948781, d_loss_cls: 0.000067, g_loss: 0.335342, g_loss_cls: 0.085775, g_loss_recon: 0.041135, wd: 1.040135\n",
      "Epoch: [59] [ 453/ 633] time: 27002.7530, d_loss: -0.759168, d_loss_cls: 0.000016, g_loss: 0.991507, g_loss_cls: 0.053035, g_loss_recon: 0.042822, wd: 0.824788\n",
      "Epoch: [59] [ 553/ 633] time: 27074.1216, d_loss: -0.886395, d_loss_cls: 0.000088, g_loss: 0.353643, g_loss_cls: 0.030553, g_loss_recon: 0.042085, wd: 0.992617\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [60] [  20/ 633] time: 27145.8469, d_loss: -0.780843, d_loss_cls: 0.000050, g_loss: 0.328240, g_loss_cls: 0.022093, g_loss_recon: 0.041648, wd: 0.878064\n",
      "Epoch: [60] [ 120/ 633] time: 27217.1619, d_loss: -0.669615, d_loss_cls: 0.000001, g_loss: 0.387742, g_loss_cls: 0.028892, g_loss_recon: 0.042021, wd: 0.745933\n",
      "Epoch: [60] [ 220/ 633] time: 27288.5159, d_loss: -1.010783, d_loss_cls: 0.000344, g_loss: 0.723922, g_loss_cls: 0.113238, g_loss_recon: 0.039649, wd: 1.107346\n",
      "Epoch: [60] [ 320/ 633] time: 27359.8483, d_loss: -0.879229, d_loss_cls: 0.000088, g_loss: 0.480242, g_loss_cls: 0.193044, g_loss_recon: 0.042640, wd: 0.974149\n",
      "Epoch: [60] [ 420/ 633] time: 27431.1799, d_loss: -0.658537, d_loss_cls: 0.000021, g_loss: 0.155425, g_loss_cls: 0.029684, g_loss_recon: 0.040224, wd: 0.741230\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [60] [ 520/ 633] time: 27502.9447, d_loss: -0.856246, d_loss_cls: 0.000015, g_loss: 0.194413, g_loss_cls: 0.034596, g_loss_recon: 0.040224, wd: 0.943133\n",
      "Epoch: [60] [ 620/ 633] time: 27574.2353, d_loss: -0.815519, d_loss_cls: 0.000079, g_loss: 0.393472, g_loss_cls: 0.013241, g_loss_recon: 0.040639, wd: 0.916929\n",
      "Epoch: [61] [  87/ 633] time: 27645.5793, d_loss: -0.671327, d_loss_cls: 0.000023, g_loss: 0.612936, g_loss_cls: 0.023442, g_loss_recon: 0.041201, wd: 0.775558\n",
      "Epoch: [61] [ 187/ 633] time: 27716.8854, d_loss: -0.924806, d_loss_cls: 0.000040, g_loss: 0.596934, g_loss_cls: 0.044898, g_loss_recon: 0.039123, wd: 1.014007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [61] [ 287/ 633] time: 27788.2260, d_loss: -1.130033, d_loss_cls: 0.000036, g_loss: 0.624738, g_loss_cls: 0.110813, g_loss_recon: 0.043272, wd: 1.252769\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [61] [ 387/ 633] time: 27859.9750, d_loss: -0.895096, d_loss_cls: 0.000008, g_loss: 0.506385, g_loss_cls: 0.039572, g_loss_recon: 0.040389, wd: 0.966631\n",
      "Epoch: [61] [ 487/ 633] time: 27931.3375, d_loss: -1.025282, d_loss_cls: 0.000197, g_loss: 0.579680, g_loss_cls: 0.091016, g_loss_recon: 0.040790, wd: 1.131027\n",
      "Epoch: [61] [ 587/ 633] time: 28002.6532, d_loss: -0.972321, d_loss_cls: 0.000033, g_loss: 0.540400, g_loss_cls: 0.073192, g_loss_recon: 0.043304, wd: 1.084727\n",
      "Epoch: [62] [  54/ 633] time: 28074.0011, d_loss: -0.806711, d_loss_cls: 0.000114, g_loss: 0.367350, g_loss_cls: 0.073544, g_loss_recon: 0.040835, wd: 0.893516\n",
      "Epoch: [62] [ 154/ 633] time: 28145.2786, d_loss: -0.897952, d_loss_cls: 0.000154, g_loss: 0.466573, g_loss_cls: 0.073727, g_loss_recon: 0.039097, wd: 0.984547\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [62] [ 254/ 633] time: 28217.0486, d_loss: -0.784549, d_loss_cls: 0.000098, g_loss: 0.122211, g_loss_cls: 0.028195, g_loss_recon: 0.042255, wd: 0.872881\n",
      "Epoch: [62] [ 354/ 633] time: 28288.3171, d_loss: -0.935066, d_loss_cls: 0.000009, g_loss: 0.138643, g_loss_cls: 0.009367, g_loss_recon: 0.040632, wd: 1.017783\n",
      "Epoch: [62] [ 454/ 633] time: 28359.6268, d_loss: -1.128636, d_loss_cls: 0.000004, g_loss: 0.490170, g_loss_cls: 0.045220, g_loss_recon: 0.046810, wd: 1.231417\n",
      "Epoch: [62] [ 554/ 633] time: 28430.9168, d_loss: -0.710485, d_loss_cls: 0.000033, g_loss: 0.221371, g_loss_cls: 0.112156, g_loss_recon: 0.037893, wd: 0.775292\n",
      "Epoch: [63] [  21/ 633] time: 28502.2564, d_loss: -0.968186, d_loss_cls: 0.000067, g_loss: 0.423623, g_loss_cls: 0.045544, g_loss_recon: 0.039368, wd: 1.071243\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [63] [ 121/ 633] time: 28574.0041, d_loss: -0.759222, d_loss_cls: 0.000013, g_loss: 0.499837, g_loss_cls: 0.013530, g_loss_recon: 0.041126, wd: 0.841824\n",
      "Epoch: [63] [ 221/ 633] time: 28645.3524, d_loss: -1.185163, d_loss_cls: 0.000027, g_loss: 0.649074, g_loss_cls: 0.043659, g_loss_recon: 0.040194, wd: 1.282061\n",
      "Epoch: [63] [ 321/ 633] time: 28716.6860, d_loss: -0.808516, d_loss_cls: 0.000078, g_loss: 0.289437, g_loss_cls: 0.023799, g_loss_recon: 0.040861, wd: 0.904770\n",
      "Epoch: [63] [ 421/ 633] time: 28788.0373, d_loss: -1.029582, d_loss_cls: 0.000071, g_loss: 0.247074, g_loss_cls: 0.085100, g_loss_recon: 0.045404, wd: 1.141530\n",
      "Epoch: [63] [ 521/ 633] time: 28859.3686, d_loss: -0.733801, d_loss_cls: 0.000499, g_loss: 1.123946, g_loss_cls: 0.145688, g_loss_recon: 0.042230, wd: 0.844523\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [63] [ 621/ 633] time: 28931.0627, d_loss: -0.876311, d_loss_cls: 0.000061, g_loss: 0.477196, g_loss_cls: 0.011242, g_loss_recon: 0.040611, wd: 0.983454\n",
      "Epoch: [64] [  88/ 633] time: 29002.3716, d_loss: -0.998727, d_loss_cls: 0.000044, g_loss: 0.503231, g_loss_cls: 0.033832, g_loss_recon: 0.043299, wd: 1.096390\n",
      "Epoch: [64] [ 188/ 633] time: 29073.7105, d_loss: -0.957803, d_loss_cls: 0.000165, g_loss: 0.626547, g_loss_cls: 0.028063, g_loss_recon: 0.040207, wd: 1.058564\n",
      "Epoch: [64] [ 288/ 633] time: 29145.0528, d_loss: -0.896007, d_loss_cls: 0.000178, g_loss: 0.851739, g_loss_cls: 0.456892, g_loss_recon: 0.042570, wd: 0.997385\n",
      "Epoch: [64] [ 388/ 633] time: 29216.3919, d_loss: -0.814079, d_loss_cls: 0.000091, g_loss: 0.583939, g_loss_cls: 0.061014, g_loss_recon: 0.039349, wd: 0.898923\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [64] [ 488/ 633] time: 29288.0786, d_loss: -0.898447, d_loss_cls: 0.000036, g_loss: 0.395224, g_loss_cls: 0.015511, g_loss_recon: 0.044383, wd: 0.993136\n",
      "Epoch: [64] [ 588/ 633] time: 29359.4111, d_loss: -0.758736, d_loss_cls: 0.000038, g_loss: 0.645395, g_loss_cls: 0.049868, g_loss_recon: 0.039688, wd: 0.852707\n",
      "Epoch: [65] [  55/ 633] time: 29430.7360, d_loss: -0.646488, d_loss_cls: 0.000021, g_loss: 0.464561, g_loss_cls: 0.048312, g_loss_recon: 0.044067, wd: 0.726639\n",
      "Epoch: [65] [ 155/ 633] time: 29502.0981, d_loss: -0.872537, d_loss_cls: 0.000149, g_loss: 0.103091, g_loss_cls: 0.040903, g_loss_recon: 0.041612, wd: 0.952586\n",
      "Epoch: [65] [ 255/ 633] time: 29573.4501, d_loss: -0.639216, d_loss_cls: 0.000096, g_loss: 0.345544, g_loss_cls: 0.092532, g_loss_recon: 0.039257, wd: 0.702758\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [65] [ 355/ 633] time: 29645.1685, d_loss: -0.880966, d_loss_cls: 0.000066, g_loss: 0.856120, g_loss_cls: 0.011330, g_loss_recon: 0.040952, wd: 0.971587\n",
      "Epoch: [65] [ 455/ 633] time: 29716.5408, d_loss: -0.836973, d_loss_cls: 0.000160, g_loss: 0.089991, g_loss_cls: 0.189631, g_loss_recon: 0.041453, wd: 0.916558\n",
      "Epoch: [65] [ 555/ 633] time: 29787.8521, d_loss: -0.898431, d_loss_cls: 0.000066, g_loss: 0.648629, g_loss_cls: 0.043186, g_loss_recon: 0.040251, wd: 1.001687\n",
      "Epoch: [66] [  22/ 633] time: 29859.2160, d_loss: -0.780558, d_loss_cls: 0.000035, g_loss: 0.204772, g_loss_cls: 0.070835, g_loss_recon: 0.040226, wd: 0.870294\n",
      "Epoch: [66] [ 122/ 633] time: 29930.5442, d_loss: -0.831545, d_loss_cls: 0.000060, g_loss: 0.647901, g_loss_cls: 0.106000, g_loss_recon: 0.041921, wd: 0.918385\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [66] [ 222/ 633] time: 30002.2515, d_loss: -0.864562, d_loss_cls: 0.000017, g_loss: 0.683600, g_loss_cls: 0.047910, g_loss_recon: 0.041208, wd: 0.964624\n",
      "Epoch: [66] [ 322/ 633] time: 30073.5861, d_loss: -0.888523, d_loss_cls: 0.000099, g_loss: 0.243035, g_loss_cls: 0.048089, g_loss_recon: 0.039762, wd: 0.971182\n",
      "Epoch: [66] [ 422/ 633] time: 30144.9311, d_loss: -0.925531, d_loss_cls: 0.000001, g_loss: 0.465298, g_loss_cls: 0.085492, g_loss_recon: 0.038712, wd: 1.010989\n",
      "Epoch: [66] [ 522/ 633] time: 30216.2841, d_loss: -1.122390, d_loss_cls: 0.000016, g_loss: 0.575540, g_loss_cls: 0.028019, g_loss_recon: 0.039451, wd: 1.236325\n",
      "Epoch: [66] [ 622/ 633] time: 30287.6316, d_loss: -0.770035, d_loss_cls: 0.000144, g_loss: 0.419107, g_loss_cls: 0.051996, g_loss_recon: 0.039732, wd: 0.863385\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [67] [  89/ 633] time: 30359.3199, d_loss: -0.852520, d_loss_cls: 0.000103, g_loss: 0.736320, g_loss_cls: 0.041252, g_loss_recon: 0.039833, wd: 0.927608\n",
      "Epoch: [67] [ 189/ 633] time: 30430.6744, d_loss: -1.123234, d_loss_cls: 0.000042, g_loss: 0.574622, g_loss_cls: 0.130358, g_loss_recon: 0.043009, wd: 1.225408\n",
      "Epoch: [67] [ 289/ 633] time: 30502.0563, d_loss: -0.729645, d_loss_cls: 0.000040, g_loss: 0.416651, g_loss_cls: 0.132351, g_loss_recon: 0.039497, wd: 0.811168\n",
      "Epoch: [67] [ 389/ 633] time: 30573.4406, d_loss: -0.980479, d_loss_cls: 0.000033, g_loss: 0.368130, g_loss_cls: 0.114814, g_loss_recon: 0.042812, wd: 1.071834\n",
      "Epoch: [67] [ 489/ 633] time: 30644.8360, d_loss: -0.845289, d_loss_cls: 0.000022, g_loss: 0.583185, g_loss_cls: 0.070111, g_loss_recon: 0.039857, wd: 0.920428\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [67] [ 589/ 633] time: 30716.6148, d_loss: -0.898278, d_loss_cls: 0.000041, g_loss: 0.454182, g_loss_cls: 0.106242, g_loss_recon: 0.043948, wd: 1.021121\n",
      "Epoch: [68] [  56/ 633] time: 30787.9962, d_loss: -0.762888, d_loss_cls: 0.000057, g_loss: 0.303123, g_loss_cls: 0.015330, g_loss_recon: 0.040597, wd: 0.841317\n",
      "Epoch: [68] [ 156/ 633] time: 30859.3731, d_loss: -0.720143, d_loss_cls: 0.000194, g_loss: 0.290799, g_loss_cls: 0.083333, g_loss_recon: 0.038828, wd: 0.810202\n",
      "Epoch: [68] [ 256/ 633] time: 30930.7324, d_loss: -0.824899, d_loss_cls: 0.000232, g_loss: 0.149730, g_loss_cls: 0.130345, g_loss_recon: 0.039765, wd: 0.922199\n",
      "Epoch: [68] [ 356/ 633] time: 31002.0872, d_loss: -0.909097, d_loss_cls: 0.000067, g_loss: 1.055703, g_loss_cls: 0.022248, g_loss_recon: 0.044791, wd: 1.014514\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [68] [ 456/ 633] time: 31073.8456, d_loss: -0.766240, d_loss_cls: 0.000039, g_loss: 0.735341, g_loss_cls: 0.046672, g_loss_recon: 0.038708, wd: 0.840550\n",
      "Epoch: [68] [ 556/ 633] time: 31145.2138, d_loss: -0.819537, d_loss_cls: 0.000013, g_loss: 0.534411, g_loss_cls: 0.062396, g_loss_recon: 0.036634, wd: 0.900515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [69] [  23/ 633] time: 31216.5481, d_loss: -0.803981, d_loss_cls: 0.000032, g_loss: 0.074169, g_loss_cls: 0.022433, g_loss_recon: 0.039234, wd: 0.897376\n",
      "Epoch: [69] [ 123/ 633] time: 31287.9186, d_loss: -0.948729, d_loss_cls: 0.000017, g_loss: 0.599565, g_loss_cls: 0.255035, g_loss_recon: 0.038983, wd: 1.049280\n",
      "Epoch: [69] [ 223/ 633] time: 31359.2898, d_loss: -0.829658, d_loss_cls: 0.000164, g_loss: 0.732537, g_loss_cls: 0.042386, g_loss_recon: 0.041742, wd: 0.908970\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [69] [ 323/ 633] time: 31431.0681, d_loss: -1.009181, d_loss_cls: 0.000227, g_loss: 0.526793, g_loss_cls: 0.059766, g_loss_recon: 0.037868, wd: 1.091723\n",
      "Epoch: [69] [ 423/ 633] time: 31502.4073, d_loss: -0.922647, d_loss_cls: 0.000047, g_loss: 0.628157, g_loss_cls: 0.015512, g_loss_recon: 0.039374, wd: 1.006349\n",
      "Epoch: [69] [ 523/ 633] time: 31573.7735, d_loss: -0.735066, d_loss_cls: 0.000264, g_loss: 0.406183, g_loss_cls: 0.066363, g_loss_recon: 0.037849, wd: 0.800926\n",
      "Epoch: [69] [ 623/ 633] time: 31645.1324, d_loss: -0.848115, d_loss_cls: 0.000018, g_loss: 0.094422, g_loss_cls: 0.193709, g_loss_recon: 0.042449, wd: 0.940114\n",
      "Epoch: [70] [  90/ 633] time: 31716.4956, d_loss: -0.881444, d_loss_cls: 0.000250, g_loss: 0.574238, g_loss_cls: 0.102750, g_loss_recon: 0.040254, wd: 0.966236\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [70] [ 190/ 633] time: 31788.2636, d_loss: -0.652255, d_loss_cls: 0.000030, g_loss: 0.023174, g_loss_cls: 0.054187, g_loss_recon: 0.039073, wd: 0.723577\n",
      "Epoch: [70] [ 290/ 633] time: 31859.6065, d_loss: -0.982999, d_loss_cls: 0.000021, g_loss: 0.967021, g_loss_cls: 0.532539, g_loss_recon: 0.042416, wd: 1.074866\n",
      "Epoch: [70] [ 390/ 633] time: 31930.9861, d_loss: -0.951713, d_loss_cls: 0.000113, g_loss: 0.320634, g_loss_cls: 0.043465, g_loss_recon: 0.044671, wd: 1.053001\n",
      "Epoch: [70] [ 490/ 633] time: 32002.3293, d_loss: -0.924965, d_loss_cls: 0.000071, g_loss: 0.494100, g_loss_cls: 0.037221, g_loss_recon: 0.039302, wd: 1.005939\n",
      "Epoch: [70] [ 590/ 633] time: 32073.6610, d_loss: -0.858647, d_loss_cls: 0.000007, g_loss: 0.303570, g_loss_cls: 0.040083, g_loss_recon: 0.040617, wd: 0.937900\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [71] [  57/ 633] time: 32145.4105, d_loss: -0.834997, d_loss_cls: 0.000053, g_loss: 0.295321, g_loss_cls: 0.025140, g_loss_recon: 0.037336, wd: 0.926045\n",
      "Epoch: [71] [ 157/ 633] time: 32216.7785, d_loss: -0.976545, d_loss_cls: 0.000005, g_loss: 1.035972, g_loss_cls: 0.047311, g_loss_recon: 0.042601, wd: 1.090029\n",
      "Epoch: [71] [ 257/ 633] time: 32288.1397, d_loss: -0.831063, d_loss_cls: 0.000005, g_loss: 0.047115, g_loss_cls: 0.026233, g_loss_recon: 0.040815, wd: 0.901036\n",
      "Epoch: [71] [ 357/ 633] time: 32359.5282, d_loss: -0.866970, d_loss_cls: 0.000024, g_loss: 0.788848, g_loss_cls: 0.100833, g_loss_recon: 0.038911, wd: 0.953788\n",
      "Epoch: [71] [ 457/ 633] time: 32430.8766, d_loss: -0.679420, d_loss_cls: 0.000148, g_loss: 0.523925, g_loss_cls: 0.065227, g_loss_recon: 0.037422, wd: 0.757520\n",
      "Train Sample Generation...\n",
      "Test Sample Generation...\n",
      "Epoch: [71] [ 557/ 633] time: 32502.6753, d_loss: -0.762858, d_loss_cls: 0.000046, g_loss: 0.326573, g_loss_cls: 0.037997, g_loss_recon: 0.041427, wd: 0.846661\n",
      "Epoch: [72] [  24/ 633] time: 32574.0221, d_loss: -0.852205, d_loss_cls: 0.000003, g_loss: 0.665367, g_loss_cls: 0.030180, g_loss_recon: 0.037241, wd: 0.925696\n",
      "Epoch: [72] [ 124/ 633] time: 32645.4077, d_loss: -0.732248, d_loss_cls: 0.000056, g_loss: 0.409386, g_loss_cls: 0.138598, g_loss_recon: 0.036110, wd: 0.825876\n"
     ]
    }
   ],
   "source": [
    "import distutils.util\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "''' config settings '''\n",
    "\n",
    "project_name = \"StarGAN_Face_2_\"\n",
    "train_flag = True\n",
    "\n",
    "'''-----------------'''\n",
    "\n",
    "gpu_number = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #args.gpu_number\n",
    "\n",
    "with tf.device('/gpu:{0}'.format(gpu_number)):\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.90)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options)\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        model = StarGAN(sess, project_name)\n",
    "\n",
    "        # TRAIN / TEST\n",
    "        if train_flag:\n",
    "            model.train(train_flag)\n",
    "        else:\n",
    "            model.test(train_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
