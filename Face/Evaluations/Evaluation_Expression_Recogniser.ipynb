{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A large portion of this code comes from the tf-learn example page:\n",
    "# https://github.com/tflearn/tflearn/blob/master/examples/images/residual_network_cifar10.py\n",
    "#https://github.com/safreita1/Resnet-Emotion-Recognition/blob/master/emotion_recognition.py\n",
    "\n",
    "import tflearn\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import scipy.misc as scm\n",
    "from tflearn.data_preprocessing import ImagePreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path, size):\n",
    "    label = int(path[-5])\n",
    "    one_hot = np.zeros(size)\n",
    "    one_hot[ label ] = 1.0\n",
    "    one_hot[ one_hot==0 ] = 0.0\n",
    "    return one_hot\n",
    "\n",
    "def get_image(img_path): # [0,255] to [-1,1]\n",
    "    try:\n",
    "        img = scm.imread(img_path)\n",
    "    except:\n",
    "        return None\n",
    "    img = img * 2. /255. - 1.\n",
    "    img = img[..., ::-1]  # rgb to bgr\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data test\n",
    "# labelled_data_path = \"../Face_data/Faces_with_expression_label/dataset_128x128\"\n",
    "# labelled_data = sorted(glob.glob(os.path.join(labelled_data_path, \"*.*\")))\n",
    "\n",
    "# n_data = len(labelled_data)\n",
    "# n_train = int(n_data * 0.8)\n",
    "# n_val = int(n_data * 0.1)\n",
    "# n_test = n_data - n_train - n_val\n",
    "\n",
    "# # Shuffle\n",
    "# random_order = np.random.permutation(n_data)\n",
    "# labelled_data = [labelled_data[i] for i in random_order[:]]\n",
    "\n",
    "# X = labelled_data[:n_train]\n",
    "# X_val = labelled_data[n_train:n_train+n_val]\n",
    "# X_test = labelled_data[-n_test:]\n",
    "\n",
    "# Y = [get_label(x, 7) for x in X]\n",
    "# Y_val = [get_label(x_val, 7) for x_val in X_val]\n",
    "# Y_test = [get_label(x_test, 7) for x_test in X_test]\n",
    "\n",
    "# X = [get_image(x) for x in X]\n",
    "# X_val = [get_image(x_val) for x_val in X_val]\n",
    "# X_test = [get_image(x_test) for x_test in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time image preprocessing\n",
    "img_prep = tflearn.ImagePreprocessing()\n",
    "# Zero Center (With mean computed over the whole dataset)\n",
    "img_prep.add_featurewise_zero_center()\n",
    "# STD Normalization (With std computed over the whole dataset)\n",
    "img_prep.add_featurewise_stdnorm()\n",
    "\n",
    "# Real-time data augmentation\n",
    "img_aug = tflearn.ImageAugmentation()\n",
    "# Random flip an image\n",
    "img_aug.add_random_flip_leftright()\n",
    "\n",
    "n = 5\n",
    "# Building Residual Network\n",
    "net = tflearn.input_data(shape=[None, 128, 128, 3], data_preprocessing=img_prep, data_augmentation=img_aug)\n",
    "net = tflearn.conv_2d(net, nb_filter=16, filter_size=3, regularizer='L2', weight_decay=0.0001)\n",
    "net = tflearn.residual_block(net, n, 16)\n",
    "net = tflearn.residual_block(net, 1, 32, downsample=True)\n",
    "net = tflearn.residual_block(net, n-1, 32)\n",
    "net = tflearn.residual_block(net, 1, 64, downsample=True)\n",
    "net = tflearn.residual_block(net, n-1, 64)\n",
    "net = tflearn.batch_normalization(net)\n",
    "net = tflearn.activation(net, 'relu')\n",
    "net = tflearn.global_avg_pool(net)\n",
    "\n",
    "# Regression\n",
    "net = tflearn.fully_connected(net, 7, activation='softmax')\n",
    "mom = tflearn.Momentum(learning_rate=0.1, lr_decay=0.0001, decay_step=32000, staircase=True, momentum=0.9)\n",
    "net = tflearn.regression(net, optimizer=mom,\n",
    "                         loss='categorical_crossentropy')\n",
    "# Training\n",
    "model = tflearn.DNN(net, checkpoint_path='./models/model_resnet_emotion_3',\n",
    "                    max_checkpoints=20, tensorboard_verbose=0,\n",
    "                    clip_gradients=0.)\n",
    "\n",
    "#model.load('model_resnet_emotion_1-42000')\n",
    "\n",
    "#model.fit(X, Y, n_epoch=500, snapshot_epoch=False, snapshot_step=500, validation_set=(X_val, Y_val),\n",
    "#          show_metric=True, batch_size=64, shuffle=True, run_id='resnet_emotion_3')\n",
    "\n",
    "# score = model.evaluate(X_test, Y_test)\n",
    "# print('Test accuarcy: ', score)\n",
    "\n",
    "# model.save('model_3.tfl')\n",
    "#prediction = model.predict(predict_value)\n",
    "#print prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load('model_3.tfl')\n",
    "# score = model.evaluate(np.array(X_test), np.array(Y_test))\n",
    "# print('Test accuarcy: ', score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.array(X_test).shape, np.array(Y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.predict([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/tim/Workspace/ML/GANs/Face/Evaluations/models/model_3.tfl\n",
      "Test accuarcy:  [0.92857146263122559]\n"
     ]
    }
   ],
   "source": [
    "# load data test\n",
    "celeba_gen_path = \"./survey_image\"\n",
    "eval_data = sorted(glob.glob(os.path.join(celeba_gen_path, \"*.*\")))\n",
    "\n",
    "X_eval = [get_image(x) for x in eval_data]\n",
    "Y_eval = [get_label(x, 7) for x in eval_data]\n",
    "\n",
    "model.load('./models/model_3.tfl')\n",
    "score = model.evaluate(np.array(X_eval), np.array(Y_eval), batch_size=16)\n",
    "print('Test accuarcy: ', score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0]\n",
      " [0 0 0 2 0 0 0]\n",
      " [0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 2 0]\n",
      " [0 0 0 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "_y=model.predict(np.array(X_eval))  # predictions\n",
    "y = np.array(Y_eval) # i think this is actual labels data\n",
    "\n",
    "confusion = tf.confusion_matrix(y.argmax(axis=1), _y.argmax(axis=1), num_classes=7)\n",
    "sess = tf.Session() \n",
    "with sess.as_default(): \n",
    "    print(confusion.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./survey_image/ce_0.png', './survey_image/ce_1.png', './survey_image/ce_2.png', './survey_image/ce_3.png', './survey_image/ce_4.png', './survey_image/ce_5.png', './survey_image/ce_6.png', './survey_image/sj_0.png', './survey_image/sj_1.png', './survey_image/sj_2.png', './survey_image/sj_3.png', './survey_image/sj_4.png', './survey_image/sj_5.png', './survey_image/sj_6.png']\n",
      "[0 1 2 3 4 5 6 0 1 2 3 4 5 3]\n"
     ]
    }
   ],
   "source": [
    "print(eval_data)\n",
    "print(_y.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000']\n",
      "['0.000', '1.000', '0.000', '0.000', '0.000', '0.000', '0.000']\n",
      "['0.000', '0.000', '0.999', '0.000', '0.000', '0.000', '0.000']\n",
      "['0.003', '0.000', '0.000', '0.995', '0.000', '0.000', '0.001']\n",
      "['0.000', '0.000', '0.000', '0.000', '0.978', '0.022', '0.000']\n",
      "['0.000', '0.000', '0.000', '0.000', '0.000', '1.000', '0.000']\n",
      "['0.008', '0.007', '0.001', '0.033', '0.001', '0.005', '0.944']\n"
     ]
    }
   ],
   "source": [
    "print([\"{0:0.3f}\".format(i) for i in _y[0]])\n",
    "print([\"{0:0.3f}\".format(i) for i in _y[1]])\n",
    "print([\"{0:0.3f}\".format(i) for i in _y[2]])\n",
    "print([\"{0:0.3f}\".format(i) for i in _y[3]])\n",
    "print([\"{0:0.3f}\".format(i) for i in _y[4]])\n",
    "print([\"{0:0.3f}\".format(i) for i in _y[5]])\n",
    "print([\"{0:0.3f}\".format(i) for i in _y[6]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Celeba attribute\n",
    "celeba_txt_path = \"../Face_data/Celeba/list_attr_celeba.txt\"\n",
    "\n",
    "attributes = []\n",
    "with open(celeba_txt_path, 'r') as f:\n",
    "    f.readline()\n",
    "    attribute_names = f.readline().strip().split(' ')\n",
    "    for i, line in enumerate(f):\n",
    "        fields = line.strip().replace('  ', ' ').split(' ')\n",
    "        img_name = fields[0]\n",
    "        if int(img_name[:6]) != i + 1:\n",
    "            raise ValueError('Parse error.')\n",
    "        attr_vec = np.array([int(x) for x in fields[1:]])\n",
    "        attributes.append(attr_vec)\n",
    "attributes = np.array(attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n"
     ]
    }
   ],
   "source": [
    "print(attribute_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./gen_celeba/000003_0.jpg', './gen_celeba/000003_1.jpg', './gen_celeba/000003_2.jpg', './gen_celeba/000003_3.jpg', './gen_celeba/000003_4.jpg', './gen_celeba/000003_5.jpg', './gen_celeba/000003_6.jpg', './gen_celeba/000007_0.jpg', './gen_celeba/000007_1.jpg', './gen_celeba/000007_2.jpg']\n"
     ]
    }
   ],
   "source": [
    "selected_attributes = ['Male']\n",
    "attr_idxs = [attribute_names.index(attr) for attr in selected_attributes]\n",
    "\n",
    "target_images = []\n",
    "for i in range(len(attributes)):\n",
    "    img_attr = attributes[i]\n",
    "#     if img_attr[attr_idxs] = 1:\n",
    "    if img_attr[attr_idxs] == 1:\n",
    "        for j in range(7):\n",
    "            target_images.append('./gen_celeba/{0:06d}_{1}.jpg'.format(i+1, j))\n",
    "        \n",
    "        \n",
    "        \n",
    "print(target_images[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874\n",
      "INFO:tensorflow:Restoring parameters from /home/tim/Workspace/ML/GANs/Face/Evaluations/models/model_3.tfl\n",
      "Test accuarcy:  [0.52288329546729817]\n",
      "[[ 64   0   0   2   0  58   1]\n",
      " [  1  86   0   0   0  38   0]\n",
      " [  7   5  53   0   1  58   1]\n",
      " [ 13  13   2  50   0  43   4]\n",
      " [  1   2   0   0  38  84   0]\n",
      " [  0   0   0   0   0 125   0]\n",
      " [  8  14   7   6   0  48  41]]\n"
     ]
    }
   ],
   "source": [
    "# load data test\n",
    "import tensorflow as tf\n",
    "\n",
    "X_eval = []\n",
    "Y_eval = []\n",
    "\n",
    "num_exist = 0\n",
    "for x in target_images[:1000]:\n",
    "    img = get_image(x)\n",
    "    if img is not None:\n",
    "        X_eval.append(img)\n",
    "        Y_eval.append(get_label(x, 7))\n",
    "        num_exist += 1\n",
    "    \n",
    "# X_eval = [get_image(x) for x in target_images[:10000]]\n",
    "# Y_eval = [get_label(x, 7) for x in target_images[:10000]]\n",
    "\n",
    "print(num_exist)\n",
    "\n",
    "model.load('./models/model_3.tfl')\n",
    "score = model.evaluate(np.array(X_eval), np.array(Y_eval), batch_size=16)\n",
    "print('Test accuarcy: ', score)\n",
    "\n",
    "\n",
    "_y=model.predict(np.array(X_eval))  # predictions\n",
    "y = np.array(Y_eval) # i think this is actual labels data\n",
    "\n",
    "\n",
    "cm = None\n",
    "confusion = tf.confusion_matrix(y.argmax(axis=1), _y.argmax(axis=1), num_classes=7)\n",
    "sess = tf.Session() \n",
    "with sess.as_default(): \n",
    "    cm = confusion.eval()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.385628 1\n",
      "0.413329 4\n",
      "0.377358 2\n",
      "0.373349 2\n",
      "0.39877 6\n",
      "0.308541 5\n",
      "0.483653 6\n",
      "0.404785 0\n",
      "0.470733 2\n",
      "0.464441 5\n",
      "0.488168 0\n",
      "0.297861 0\n",
      "0.444193 1\n",
      "0.483892 0\n",
      "0.364209 1\n",
      "0.477801 1\n",
      "0.362948 0\n",
      "0.391077 2\n",
      "0.461696 2\n",
      "0.336327 3\n",
      "0.43668 1\n",
      "0.490398 5\n",
      "0.467698 0\n",
      "0.429879 3\n",
      "0.413001 6\n",
      "0.335297 3\n",
      "0.356414 1\n",
      "0.465064 2\n",
      "0.43027 3\n",
      "0.4909 0\n",
      "0.49832 3\n",
      "0.492518 1\n",
      "0.488265 3\n",
      "0.426736 6\n",
      "0.407255 6\n",
      "0.435047 1\n",
      "0.441148 5\n",
      "0.473779 5\n",
      "0.472963 6\n",
      "0.480445 3\n",
      "0.356281 6\n",
      "0.492422 5\n",
      "0.339946 0\n",
      "0.442005 1\n",
      "0.433826 2\n",
      "0.484023 5\n",
      "0.406391 1\n",
      "0.475152 5\n"
     ]
    }
   ],
   "source": [
    "confidence = []\n",
    "_y_max_idx = _y.argmax(axis=1)\n",
    "for i in range(len(_y)):\n",
    "    one_y = _y[i]\n",
    "    if one_y[_y_max_idx[i]] < 0.5:\n",
    "        print(one_y[_y_max_idx[i]], _y_max_idx[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 64   0   0   2   0  58   1]\n",
      " [  1  86   0   0   0  38   0]\n",
      " [  7   5  53   0   1  58   1]\n",
      " [ 13  13   2  50   0  43   4]\n",
      " [  1   2   0   0  38  84   0]\n",
      " [  0   0   0   0   0 125   0]\n",
      " [  8  14   7   6   0  48  41]]\n"
     ]
    }
   ],
   "source": [
    "cm = None\n",
    "with sess.as_default(): \n",
    "    cm = confusion.eval()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/tim/Workspace/ML/GANs/Face/Evaluations/models/model_3.tfl\n",
      "Test accuarcy:  [0.98636363636363633]\n",
      "[[61  0  0  0  0  0  0]\n",
      " [ 0 66  0  0  1  0  0]\n",
      " [ 0  0 69  0  1  0  0]\n",
      " [ 0  0  0 30  0  0  0]\n",
      " [ 0  0  0  0 72  2  0]\n",
      " [ 0  1  0  0  0 63  0]\n",
      " [ 0  0  0  1  0  0 73]]\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "model.load('./models/model_3.tfl')\n",
    "score = model.evaluate(np.array(X_test), np.array(Y_test))\n",
    "print('Test accuarcy: ', score)\n",
    "\n",
    "\n",
    "_y=model.predict(np.array(X_test))  # predictions\n",
    "y = np.array(Y_test) # i think this is actual labels data\n",
    "\n",
    "\n",
    "\n",
    "confusion = tf.confusion_matrix(y.argmax(axis=1), _y.argmax(axis=1), num_classes=7)\n",
    "sess = tf.Session() \n",
    "with sess.as_default(): \n",
    "    print(confusion.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data in survey\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
